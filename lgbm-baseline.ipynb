{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5c9a205",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T08:35:18.864732Z",
     "iopub.status.busy": "2024-05-23T08:35:18.864099Z",
     "iopub.status.idle": "2024-05-23T08:35:18.868820Z",
     "shell.execute_reply": "2024-05-23T08:35:18.867915Z"
    },
    "papermill": {
     "duration": 0.017394,
     "end_time": "2024-05-23T08:35:18.870702",
     "exception": false,
     "start_time": "2024-05-23T08:35:18.853308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "# from transformers import (\n",
    "#     AutoTokenizer, \n",
    "#     AutoModelForSequenceClassification, \n",
    "#     Trainer, \n",
    "#     TrainingArguments, \n",
    "#     DataCollatorWithPadding\n",
    "# )\n",
    "# from datasets import Dataset\n",
    "# from glob import glob\n",
    "# import gc\n",
    "# import torch\n",
    "# from scipy.special import softmax\n",
    "\n",
    "# MAX_LENGTH = 1024\n",
    "# TEST_DATA_PATH = \"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv\"\n",
    "# MODEL_PATH = '/kaggle/input/aes2-400-20240419134941/*/*'\n",
    "# EVAL_BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b54c7e7",
   "metadata": {
    "papermill": {
     "duration": 0.009515,
     "end_time": "2024-05-23T08:35:18.890048",
     "exception": false,
     "start_time": "2024-05-23T08:35:18.880533",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Deberta Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b1702e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T08:35:18.910475Z",
     "iopub.status.busy": "2024-05-23T08:35:18.910205Z",
     "iopub.status.idle": "2024-05-23T08:35:18.914931Z",
     "shell.execute_reply": "2024-05-23T08:35:18.914141Z"
    },
    "papermill": {
     "duration": 0.017506,
     "end_time": "2024-05-23T08:35:18.917334",
     "exception": false,
     "start_time": "2024-05-23T08:35:18.899828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# models = glob(MODEL_PATH)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(models[0])\n",
    "\n",
    "# def tokenize(sample):\n",
    "#     return tokenizer(sample['full_text'], max_length=MAX_LENGTH, truncation=True)\n",
    "\n",
    "# df_test = pd.read_csv(TEST_DATA_PATH)\n",
    "# ds = Dataset.from_pandas(df_test).map(tokenize).remove_columns(['essay_id', 'full_text'])\n",
    "\n",
    "# args = TrainingArguments(\n",
    "#     \".\", \n",
    "#     per_device_eval_batch_size=EVAL_BATCH_SIZE, \n",
    "#     report_to=\"none\"\n",
    "# )\n",
    "\n",
    "# predictions = []\n",
    "# for model in models:\n",
    "#     model = AutoModelForSequenceClassification.from_pretrained(model)\n",
    "#     trainer = Trainer(\n",
    "#         model=model, \n",
    "#         args=args, \n",
    "#         data_collator=DataCollatorWithPadding(tokenizer), \n",
    "#         tokenizer=tokenizer\n",
    "#     )\n",
    "    \n",
    "#     preds = trainer.predict(ds).predictions\n",
    "#     predictions.append(softmax(preds, axis=-1))  \n",
    "#     del model, trainer\n",
    "#     torch.cuda.empty_cache()\n",
    "#     gc.collect()\n",
    "    \n",
    "# predicted_score = 0.\n",
    "\n",
    "# for p in predictions:\n",
    "#     predicted_score += p\n",
    "    \n",
    "# predicted_score /= len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "001a2b5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T08:35:18.939663Z",
     "iopub.status.busy": "2024-05-23T08:35:18.939006Z",
     "iopub.status.idle": "2024-05-23T08:35:18.942558Z",
     "shell.execute_reply": "2024-05-23T08:35:18.941756Z"
    },
    "papermill": {
     "duration": 0.015934,
     "end_time": "2024-05-23T08:35:18.944400",
     "exception": false,
     "start_time": "2024-05-23T08:35:18.928466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_test['score'] = predicted_score.argmax(-1) + 1\n",
    "# df_test.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c897604d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T08:35:18.964466Z",
     "iopub.status.busy": "2024-05-23T08:35:18.964226Z",
     "iopub.status.idle": "2024-05-23T08:35:18.967820Z",
     "shell.execute_reply": "2024-05-23T08:35:18.967076Z"
    },
    "papermill": {
     "duration": 0.015604,
     "end_time": "2024-05-23T08:35:18.969593",
     "exception": false,
     "start_time": "2024-05-23T08:35:18.953989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_test[['essay_id', 'score']].to_csv('submission_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb6c2d6",
   "metadata": {
    "papermill": {
     "duration": 0.009659,
     "end_time": "2024-05-23T08:35:18.989005",
     "exception": false,
     "start_time": "2024-05-23T08:35:18.979346",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"color:white;display:fill;border-radius:5px;background-color:seaGreen;text-align:center;letter-spacing:0.1px;overflow:hidden;padding:20px;color:white;overflow:hidden;margin:0;font-size:100%\">▶️ 15 fold LGBM ◀️</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "255bcb72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T08:35:19.009410Z",
     "iopub.status.busy": "2024-05-23T08:35:19.009149Z",
     "iopub.status.idle": "2024-05-23T08:35:29.940199Z",
     "shell.execute_reply": "2024-05-23T08:35:29.939371Z"
    },
    "papermill": {
     "duration": 10.943967,
     "end_time": "2024-05-23T08:35:29.942604",
     "exception": false,
     "start_time": "2024-05-23T08:35:18.998637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re\n",
    "import spacy\n",
    "import string\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier,BaggingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from lightgbm import log_evaluation, early_stopping\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import polars as pl\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5c27c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "285ef958",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T08:35:29.965882Z",
     "iopub.status.busy": "2024-05-23T08:35:29.964955Z",
     "iopub.status.idle": "2024-05-23T08:35:32.041817Z",
     "shell.execute_reply": "2024-05-23T08:35:32.040909Z"
    },
    "papermill": {
     "duration": 2.09113,
     "end_time": "2024-05-23T08:35:32.044005",
     "exception": false,
     "start_time": "2024-05-23T08:35:29.952875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>essay_id</th><th>full_text</th><th>score</th><th>paragraph</th></tr><tr><td>str</td><td>str</td><td>i64</td><td>list[str]</td></tr></thead><tbody><tr><td>&quot;000d118&quot;</td><td>&quot;Many people have car where the…</td><td>3</td><td>[&quot;Many people have car where they live. The thing they don&#x27;t know is that when you use a car alot of thing can happen like you can get in accidet or the smoke that the car has is bad to breath on if someone is walk but in VAUBAN,Germany they dont have that proble because 70 percent of vauban&#x27;s families do not own cars,and 57 percent sold a car to move there. Street parkig ,driveways and home garages are forbidden on the outskirts of freiburd that near the French and Swiss borders. You probaly won&#x27;t see a car in Vauban&#x27;s streets because they are completely &quot;car free&quot; but If some that lives in VAUBAN that owns a car ownership is allowed,but there are only two places that you can park a large garages at the edge of the development,where a car owner buys a space but it not cheap to buy one they sell the space for you car for $40,000 along with a home. The vauban people completed this in 2006 ,they said that this an example of a growing trend in Europe,The untile states and some where else are suburban life from auto use this is called &quot;smart planning&quot;. The current efforts to drastically reduce greenhouse gas emissions from tailes the passengee cars are responsible for 12 percent of greenhouse gas emissions in Europe and up to 50 percent in some car intensive in the United States. I honeslty think that good idea that they did that is Vaudan because that makes cities denser and better for walking and in VAUBAN there are 5,500 residents within a rectangular square mile. In the artical David Gold berg said that &quot;All of our development since World war 2 has been centered on the cars,and that will have to change&quot; and i think that was very true what David Gold said because alot thing we need cars to do we can go anyway were with out cars beacuse some people are a very lazy to walk to place thats why they alot of people use car and i think that it was a good idea that that they did that in VAUBAN so people can see how we really don&#x27;t need car to go to place from place because we can walk from were we need to go or we can ride bycles with out the use of a car. It good that they are doing that if you thik about your help the earth in way and thats a very good thing to. In the United states ,the Environmental protection Agency is promoting what is called &quot;car reduced&quot;communtunties,and the legislators are starting to act,if cautiously. Maany experts expect pubic transport serving suburbs to play a much larger role in a new six years federal transportation bill to approved this year. In previous bill,80 percent of appropriations have by law gone to highways and only 20 percent to other transports. There many good reason why they should do this.    &quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 4)\n",
       "┌──────────┬─────────────────────────────────┬───────┬─────────────────────────────────┐\n",
       "│ essay_id ┆ full_text                       ┆ score ┆ paragraph                       │\n",
       "│ ---      ┆ ---                             ┆ ---   ┆ ---                             │\n",
       "│ str      ┆ str                             ┆ i64   ┆ list[str]                       │\n",
       "╞══════════╪═════════════════════════════════╪═══════╪═════════════════════════════════╡\n",
       "│ 000d118  ┆ Many people have car where the… ┆ 3     ┆ [\"Many people have car where t… │\n",
       "└──────────┴─────────────────────────────────┴───────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [  \n",
    "    (\n",
    "        pl.col(\"full_text\").str.split(by=\"\\n\\n\").alias(\"paragraph\")\n",
    "    ),\n",
    "]\n",
    "PATH = \"kaggle/input/learning-agency-lab-automated-essay-scoring-2/\"\n",
    "\n",
    "# Load training and testing sets, while using \\ n \\ n character segmentation to list and renaming to paragraph for full_text data\n",
    "train = pl.read_csv(PATH + \"train.csv\").with_columns(columns)\n",
    "test = pl.read_csv(PATH + \"test.csv\").with_columns(columns)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "with open('kaggle/input/english-word-hx/words.txt', 'r') as file:\n",
    "    english_vocab = set(word.strip().lower() for word in file)\n",
    "\n",
    "# Display the first sample data in the training set\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7baa36c",
   "metadata": {
    "papermill": {
     "duration": 0.009933,
     "end_time": "2024-05-23T08:35:32.064464",
     "exception": false,
     "start_time": "2024-05-23T08:35:32.054531",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Features engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc8a73c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T08:35:32.085920Z",
     "iopub.status.busy": "2024-05-23T08:35:32.085558Z",
     "iopub.status.idle": "2024-05-23T08:35:32.093702Z",
     "shell.execute_reply": "2024-05-23T08:35:32.092847Z"
    },
    "papermill": {
     "duration": 0.021425,
     "end_time": "2024-05-23T08:35:32.095799",
     "exception": false,
     "start_time": "2024-05-23T08:35:32.074374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_spelling_errors(text):\n",
    "    doc = nlp(text)\n",
    "    lemmatized_tokens = [token.lemma_.lower() for token in doc]\n",
    "    spelling_errors = sum(1 for token in lemmatized_tokens if token not in english_vocab)\n",
    "    return spelling_errors\n",
    "\n",
    "def removeHTML(x):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',x)\n",
    "def dataPreprocessing(x):\n",
    "    # Convert words to lowercase\n",
    "    x = x.lower()\n",
    "    # Remove HTML\n",
    "    x = removeHTML(x)\n",
    "    # Delete strings starting with @\n",
    "    x = re.sub(\"@\\w+\", '',x)\n",
    "    # Delete Numbers\n",
    "    x = re.sub(\"'\\d+\", '',x)\n",
    "    x = re.sub(\"\\d+\", '',x)\n",
    "    # Delete URL\n",
    "    x = re.sub(\"http\\w+\", '',x)\n",
    "    # Replace consecutive empty spaces with a single space character\n",
    "    x = re.sub(r\"\\s+\", \" \", x)\n",
    "    # Replace consecutive commas and periods with one comma and period character\n",
    "    x = re.sub(r\"\\.+\", \".\", x)\n",
    "    x = re.sub(r\"\\,+\", \",\", x)\n",
    "    # Remove empty characters at the beginning and end\n",
    "    x = x.strip()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b71267",
   "metadata": {
    "papermill": {
     "duration": 0.009954,
     "end_time": "2024-05-23T08:35:32.115987",
     "exception": false,
     "start_time": "2024-05-23T08:35:32.106033",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Paragraph Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff9f14bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T08:35:32.137971Z",
     "iopub.status.busy": "2024-05-23T08:35:32.137162Z",
     "iopub.status.idle": "2024-05-23T08:56:11.141457Z",
     "shell.execute_reply": "2024-05-23T08:56:11.140555Z"
    },
    "papermill": {
     "duration": 1239.028026,
     "end_time": "2024-05-23T08:56:11.154134",
     "exception": false,
     "start_time": "2024-05-23T08:35:32.126108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1910033/4210097897.py:20: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  tmp = tmp.with_columns(pl.col('paragraph').map_elements(dataPreprocessing))\n",
      "/tmp/ipykernel_1910033/4210097897.py:21: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  tmp = tmp.with_columns(pl.col('paragraph').map_elements(remove_punctuation).alias('paragraph_no_pinctuation'))\n",
      "/tmp/ipykernel_1910033/4210097897.py:22: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  tmp = tmp.with_columns(pl.col('paragraph_no_pinctuation').map_elements(count_spelling_errors).alias(\"paragraph_error_num\"))\n",
      "/tmp/ipykernel_1910033/4210097897.py:24: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  tmp = tmp.with_columns(pl.col('paragraph').map_elements(lambda x: len(x)).alias(\"paragraph_len\"))\n",
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Number:  53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>paragraph_0_cnt</th>\n",
       "      <th>paragraph_50_cnt</th>\n",
       "      <th>paragraph_75_cnt</th>\n",
       "      <th>paragraph_100_cnt</th>\n",
       "      <th>paragraph_125_cnt</th>\n",
       "      <th>paragraph_150_cnt</th>\n",
       "      <th>paragraph_175_cnt</th>\n",
       "      <th>paragraph_200_cnt</th>\n",
       "      <th>paragraph_250_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>paragraph_word_cnt_kurtosis</th>\n",
       "      <th>paragraph_error_num_q1</th>\n",
       "      <th>paragraph_len_q1</th>\n",
       "      <th>paragraph_sentence_cnt_q1</th>\n",
       "      <th>paragraph_word_cnt_q1</th>\n",
       "      <th>paragraph_error_num_q3</th>\n",
       "      <th>paragraph_len_q3</th>\n",
       "      <th>paragraph_sentence_cnt_q3</th>\n",
       "      <th>paragraph_word_cnt_q3</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2640.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2640.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.388460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.696723</td>\n",
       "      <td>1.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>927.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id  paragraph_0_cnt  paragraph_50_cnt  paragraph_75_cnt  \\\n",
       "0  000d118                1                 1                 1   \n",
       "1  000fe60                5                 5                 5   \n",
       "2  001ab80                4                 4                 4   \n",
       "\n",
       "   paragraph_100_cnt  paragraph_125_cnt  paragraph_150_cnt  paragraph_175_cnt  \\\n",
       "0                  1                  1                  1                  1   \n",
       "1                  5                  5                  5                  5   \n",
       "2                  4                  4                  4                  4   \n",
       "\n",
       "   paragraph_200_cnt  paragraph_250_cnt  ...  paragraph_word_cnt_kurtosis  \\\n",
       "0                  1                  1  ...                          NaN   \n",
       "1                  4                  3  ...                    -1.388460   \n",
       "2                  4                  4  ...                    -1.696723   \n",
       "\n",
       "   paragraph_error_num_q1  paragraph_len_q1  paragraph_sentence_cnt_q1  \\\n",
       "0                    27.0            2640.0                       14.0   \n",
       "1                     1.0             235.0                        4.0   \n",
       "2                     1.0             576.0                        5.0   \n",
       "\n",
       "   paragraph_word_cnt_q1  paragraph_error_num_q3  paragraph_len_q3  \\\n",
       "0                  491.0                    27.0            2640.0   \n",
       "1                   46.0                     1.0             398.0   \n",
       "2                  101.0                     2.0             927.0   \n",
       "\n",
       "   paragraph_sentence_cnt_q3  paragraph_word_cnt_q3  score  \n",
       "0                       14.0                  491.0      3  \n",
       "1                        5.0                   77.0      3  \n",
       "2                        8.0                  165.0      4  \n",
       "\n",
       "[3 rows x 55 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# paragraph features\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"\n",
    "    Remove all punctuation from the input text.\n",
    "    \n",
    "    Args:\n",
    "    - text (str): The input text.\n",
    "    \n",
    "    Returns:\n",
    "    - str: The text with punctuation removed.\n",
    "    \"\"\"\n",
    "    # string.punctuation\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)\n",
    "\n",
    "def Paragraph_Preprocess(tmp):\n",
    "    # Expand the paragraph list into several lines of data\n",
    "    tmp = tmp.explode('paragraph')\n",
    "    # Paragraph preprocessing\n",
    "    tmp = tmp.with_columns(pl.col('paragraph').map_elements(dataPreprocessing))\n",
    "    tmp = tmp.with_columns(pl.col('paragraph').map_elements(remove_punctuation).alias('paragraph_no_pinctuation'))\n",
    "    tmp = tmp.with_columns(pl.col('paragraph_no_pinctuation').map_elements(count_spelling_errors).alias(\"paragraph_error_num\"))\n",
    "    # Calculate the length of each paragraph\n",
    "    tmp = tmp.with_columns(pl.col('paragraph').map_elements(lambda x: len(x)).alias(\"paragraph_len\"))\n",
    "    # Calculate the number of sentences and words in each paragraph\n",
    "    tmp = tmp.with_columns(pl.col('paragraph').map_elements(lambda x: len(x.split('.'))).alias(\"paragraph_sentence_cnt\"),\n",
    "                    pl.col('paragraph').map_elements(lambda x: len(x.split(' '))).alias(\"paragraph_word_cnt\"),)\n",
    "    return tmp\n",
    "# feature_eng\n",
    "paragraph_fea = ['paragraph_len','paragraph_sentence_cnt','paragraph_word_cnt']\n",
    "paragraph_fea2 = ['paragraph_error_num'] + paragraph_fea\n",
    "def Paragraph_Eng(train_tmp):\n",
    "    num_list = [0, 50,75,100,125,150,175,200,250,300,350,400,500,600]\n",
    "    num_list2 = [0, 50,75,100,125,150,175,200,250,300,350,400,500,600,700]\n",
    "    aggs = [\n",
    "        # Count the number of paragraph lengths greater than and less than the i-value\n",
    "        *[pl.col('paragraph').filter(pl.col('paragraph_len') >= i).count().alias(f\"paragraph_{i}_cnt\") for i in [0, 50,75,100,125,150,175,200,250,300,350,400,500,600,700] ], \n",
    "        *[pl.col('paragraph').filter(pl.col('paragraph_len') <= i).count().alias(f\"paragraph_{i}_cnt\") for i in [25,49]], \n",
    "        # other\n",
    "        *[pl.col(fea).max().alias(f\"{fea}_max\") for fea in paragraph_fea2],\n",
    "        *[pl.col(fea).mean().alias(f\"{fea}_mean\") for fea in paragraph_fea2],\n",
    "        *[pl.col(fea).min().alias(f\"{fea}_min\") for fea in paragraph_fea2],\n",
    "        *[pl.col(fea).sum().alias(f\"{fea}_sum\") for fea in paragraph_fea2],\n",
    "        *[pl.col(fea).first().alias(f\"{fea}_first\") for fea in paragraph_fea2],\n",
    "        *[pl.col(fea).last().alias(f\"{fea}_last\") for fea in paragraph_fea2],\n",
    "        *[pl.col(fea).kurtosis().alias(f\"{fea}_kurtosis\") for fea in paragraph_fea2],\n",
    "        *[pl.col(fea).quantile(0.25).alias(f\"{fea}_q1\") for fea in paragraph_fea2],  \n",
    "        *[pl.col(fea).quantile(0.75).alias(f\"{fea}_q3\") for fea in paragraph_fea2],  \n",
    "        ]\n",
    "    \n",
    "    df = train_tmp.group_by(['essay_id'], maintain_order=True).agg(aggs).sort(\"essay_id\")\n",
    "    df = df.to_pandas()\n",
    "    return df\n",
    "tmp = Paragraph_Preprocess(train)\n",
    "train_feats = Paragraph_Eng(tmp)\n",
    "train_feats['score'] = train['score']\n",
    "# Obtain feature names\n",
    "feature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\n",
    "print('Features Number: ',len(feature_names))\n",
    "train_feats.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f067c8b",
   "metadata": {
    "papermill": {
     "duration": 0.009977,
     "end_time": "2024-05-23T08:56:11.174351",
     "exception": false,
     "start_time": "2024-05-23T08:56:11.164374",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sentence Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "862ada60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T08:56:11.196272Z",
     "iopub.status.busy": "2024-05-23T08:56:11.196001Z",
     "iopub.status.idle": "2024-05-23T08:56:18.102544Z",
     "shell.execute_reply": "2024-05-23T08:56:18.101593Z"
    },
    "papermill": {
     "duration": 6.920069,
     "end_time": "2024-05-23T08:56:18.104639",
     "exception": false,
     "start_time": "2024-05-23T08:56:11.184570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "/tmp/ipykernel_1910033/2029322157.py:7: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  tmp = tmp.with_columns(pl.col('sentence').map_elements(lambda x: len(x)).alias(\"sentence_len\"))\n",
      "/tmp/ipykernel_1910033/2029322157.py:11: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  tmp = tmp.with_columns(pl.col('sentence').map_elements(lambda x: len(x.split(' '))).alias(\"sentence_word_cnt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Number:  81\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>paragraph_0_cnt</th>\n",
       "      <th>paragraph_50_cnt</th>\n",
       "      <th>paragraph_75_cnt</th>\n",
       "      <th>paragraph_100_cnt</th>\n",
       "      <th>paragraph_125_cnt</th>\n",
       "      <th>paragraph_150_cnt</th>\n",
       "      <th>paragraph_175_cnt</th>\n",
       "      <th>paragraph_200_cnt</th>\n",
       "      <th>paragraph_250_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>sentence_len_first</th>\n",
       "      <th>sentence_word_cnt_first</th>\n",
       "      <th>sentence_len_last</th>\n",
       "      <th>sentence_word_cnt_last</th>\n",
       "      <th>sentence_len_kurtosis</th>\n",
       "      <th>sentence_word_cnt_kurtosis</th>\n",
       "      <th>sentence_len_q1</th>\n",
       "      <th>sentence_word_cnt_q1</th>\n",
       "      <th>sentence_len_q3</th>\n",
       "      <th>sentence_word_cnt_q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "      <td>10</td>\n",
       "      <td>1.514267</td>\n",
       "      <td>2.111700</td>\n",
       "      <td>110.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>13</td>\n",
       "      <td>124</td>\n",
       "      <td>25</td>\n",
       "      <td>1.126323</td>\n",
       "      <td>0.642912</td>\n",
       "      <td>53.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>27</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.423362</td>\n",
       "      <td>0.129704</td>\n",
       "      <td>90.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id  paragraph_0_cnt  paragraph_50_cnt  paragraph_75_cnt  \\\n",
       "0  000d118                1                 1                 1   \n",
       "1  000fe60                5                 5                 5   \n",
       "2  001ab80                4                 4                 4   \n",
       "\n",
       "   paragraph_100_cnt  paragraph_125_cnt  paragraph_150_cnt  paragraph_175_cnt  \\\n",
       "0                  1                  1                  1                  1   \n",
       "1                  5                  5                  5                  5   \n",
       "2                  4                  4                  4                  4   \n",
       "\n",
       "   paragraph_200_cnt  paragraph_250_cnt  ...  sentence_len_first  \\\n",
       "0                  1                  1  ...                  36   \n",
       "1                  4                  3  ...                  62   \n",
       "2                  4                  4  ...                 144   \n",
       "\n",
       "   sentence_word_cnt_first  sentence_len_last  sentence_word_cnt_last  \\\n",
       "0                        7                 47                      10   \n",
       "1                       13                124                      25   \n",
       "2                       27                 58                      10   \n",
       "\n",
       "   sentence_len_kurtosis  sentence_word_cnt_kurtosis  sentence_len_q1  \\\n",
       "0               1.514267                    2.111700            110.0   \n",
       "1               1.126323                    0.642912             53.0   \n",
       "2              -0.423362                    0.129704             90.0   \n",
       "\n",
       "   sentence_word_cnt_q1  sentence_len_q3  sentence_word_cnt_q3  \n",
       "0                  21.0            225.0                  37.0  \n",
       "1                  13.0            124.0                  25.0  \n",
       "2                  17.0            151.0                  29.0  \n",
       "\n",
       "[3 rows x 83 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence feature\n",
    "def Sentence_Preprocess(tmp):\n",
    "    # Preprocess full_text and use periods to segment sentences in the text\n",
    "    tmp = tmp.with_columns(pl.col('full_text').map_elements(dataPreprocessing).str.split(by=\".\").alias(\"sentence\"))\n",
    "    tmp = tmp.explode('sentence')\n",
    "    # Calculate the length of a sentence\n",
    "    tmp = tmp.with_columns(pl.col('sentence').map_elements(lambda x: len(x)).alias(\"sentence_len\"))\n",
    "    # Filter out the portion of data with a sentence length greater than 15\n",
    "    tmp = tmp.filter(pl.col('sentence_len')>=15)\n",
    "    # Count the number of words in each sentence\n",
    "    tmp = tmp.with_columns(pl.col('sentence').map_elements(lambda x: len(x.split(' '))).alias(\"sentence_word_cnt\"))\n",
    "    \n",
    "    return tmp\n",
    "# feature_eng\n",
    "sentence_fea = ['sentence_len','sentence_word_cnt']\n",
    "def Sentence_Eng(train_tmp):\n",
    "    aggs = [\n",
    "        # Count the number of sentences with a length greater than i\n",
    "        *[pl.col('sentence').filter(pl.col('sentence_len') >= i).count().alias(f\"sentence_{i}_cnt\") for i in [0,15,50,100,150,200,250,300] ], \n",
    "        *[pl.col('sentence').filter(pl.col('sentence_len') <= i).count().alias(f\"sentence_<{i}_cnt\") for i in [15,50] ], \n",
    "        # other\n",
    "        *[pl.col(fea).max().alias(f\"{fea}_max\") for fea in sentence_fea],\n",
    "        *[pl.col(fea).mean().alias(f\"{fea}_mean\") for fea in sentence_fea],\n",
    "        *[pl.col(fea).min().alias(f\"{fea}_min\") for fea in sentence_fea],\n",
    "        *[pl.col(fea).sum().alias(f\"{fea}_sum\") for fea in sentence_fea],\n",
    "        *[pl.col(fea).first().alias(f\"{fea}_first\") for fea in sentence_fea],\n",
    "        *[pl.col(fea).last().alias(f\"{fea}_last\") for fea in sentence_fea],\n",
    "        *[pl.col(fea).kurtosis().alias(f\"{fea}_kurtosis\") for fea in sentence_fea],\n",
    "        *[pl.col(fea).quantile(0.25).alias(f\"{fea}_q1\") for fea in sentence_fea], \n",
    "        *[pl.col(fea).quantile(0.75).alias(f\"{fea}_q3\") for fea in sentence_fea], \n",
    "        ]\n",
    "    df = train_tmp.group_by(['essay_id'], maintain_order=True).agg(aggs).sort(\"essay_id\")\n",
    "    df = df.to_pandas()\n",
    "    return df\n",
    "\n",
    "tmp = Sentence_Preprocess(train)\n",
    "# Merge the newly generated feature data with the previously generated feature data\n",
    "train_feats = train_feats.merge(Sentence_Eng(tmp), on='essay_id', how='left')\n",
    "\n",
    "feature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\n",
    "print('Features Number: ',len(feature_names))\n",
    "train_feats.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27269833",
   "metadata": {
    "papermill": {
     "duration": 0.010544,
     "end_time": "2024-05-23T08:56:18.126212",
     "exception": false,
     "start_time": "2024-05-23T08:56:18.115668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Word Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "939362db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T08:56:18.149115Z",
     "iopub.status.busy": "2024-05-23T08:56:18.148836Z",
     "iopub.status.idle": "2024-05-23T08:56:30.968915Z",
     "shell.execute_reply": "2024-05-23T08:56:30.967991Z"
    },
    "papermill": {
     "duration": 12.83432,
     "end_time": "2024-05-23T08:56:30.971224",
     "exception": false,
     "start_time": "2024-05-23T08:56:18.136904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "/tmp/ipykernel_1910033/4034772087.py:7: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  tmp = tmp.with_columns(pl.col('word').map_elements(lambda x: len(x)).alias(\"word_len\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Number:  102\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>paragraph_0_cnt</th>\n",
       "      <th>paragraph_50_cnt</th>\n",
       "      <th>paragraph_75_cnt</th>\n",
       "      <th>paragraph_100_cnt</th>\n",
       "      <th>paragraph_125_cnt</th>\n",
       "      <th>paragraph_150_cnt</th>\n",
       "      <th>paragraph_175_cnt</th>\n",
       "      <th>paragraph_200_cnt</th>\n",
       "      <th>paragraph_250_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>word_12_cnt</th>\n",
       "      <th>word_13_cnt</th>\n",
       "      <th>word_14_cnt</th>\n",
       "      <th>word_15_cnt</th>\n",
       "      <th>word_len_max</th>\n",
       "      <th>word_len_mean</th>\n",
       "      <th>word_len_std</th>\n",
       "      <th>word_len_q1</th>\n",
       "      <th>word_len_q2</th>\n",
       "      <th>word_len_q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>4.378819</td>\n",
       "      <td>2.538495</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4.012048</td>\n",
       "      <td>2.060968</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>4.574545</td>\n",
       "      <td>2.604621</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id  paragraph_0_cnt  paragraph_50_cnt  paragraph_75_cnt  \\\n",
       "0  000d118                1                 1                 1   \n",
       "1  000fe60                5                 5                 5   \n",
       "2  001ab80                4                 4                 4   \n",
       "\n",
       "   paragraph_100_cnt  paragraph_125_cnt  paragraph_150_cnt  paragraph_175_cnt  \\\n",
       "0                  1                  1                  1                  1   \n",
       "1                  5                  5                  5                  5   \n",
       "2                  4                  4                  4                  4   \n",
       "\n",
       "   paragraph_200_cnt  paragraph_250_cnt  ...  word_12_cnt  word_13_cnt  \\\n",
       "0                  1                  1  ...            6            6   \n",
       "1                  4                  3  ...            0            0   \n",
       "2                  4                  4  ...           14           10   \n",
       "\n",
       "   word_14_cnt  word_15_cnt  word_len_max  word_len_mean  word_len_std  \\\n",
       "0            5            2            25       4.378819      2.538495   \n",
       "1            0            0            11       4.012048      2.060968   \n",
       "2            5            2            15       4.574545      2.604621   \n",
       "\n",
       "   word_len_q1  word_len_q2  word_len_q3  \n",
       "0          3.0          4.0          5.0  \n",
       "1          2.0          4.0          5.0  \n",
       "2          3.0          4.0          5.0  \n",
       "\n",
       "[3 rows x 104 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word feature\n",
    "def Word_Preprocess(tmp):\n",
    "    # Preprocess full_text and use spaces to separate words from the text\n",
    "    tmp = tmp.with_columns(pl.col('full_text').map_elements(dataPreprocessing).str.split(by=\" \").alias(\"word\"))\n",
    "    tmp = tmp.explode('word')\n",
    "    # Calculate the length of each word\n",
    "    tmp = tmp.with_columns(pl.col('word').map_elements(lambda x: len(x)).alias(\"word_len\"))\n",
    "    # Delete data with a word length of 0\n",
    "    tmp = tmp.filter(pl.col('word_len')!=0)\n",
    "    \n",
    "    return tmp\n",
    "# feature_eng\n",
    "def Word_Eng(train_tmp):\n",
    "    aggs = [\n",
    "        # Count the number of words with a length greater than i+1\n",
    "        *[pl.col('word').filter(pl.col('word_len') >= i+1).count().alias(f\"word_{i+1}_cnt\") for i in range(15) ], \n",
    "        # other\n",
    "        pl.col('word_len').max().alias(f\"word_len_max\"),\n",
    "        pl.col('word_len').mean().alias(f\"word_len_mean\"),\n",
    "        pl.col('word_len').std().alias(f\"word_len_std\"),\n",
    "        pl.col('word_len').quantile(0.25).alias(f\"word_len_q1\"),\n",
    "        pl.col('word_len').quantile(0.50).alias(f\"word_len_q2\"),\n",
    "        pl.col('word_len').quantile(0.75).alias(f\"word_len_q3\"),\n",
    "        ]\n",
    "    df = train_tmp.group_by(['essay_id'], maintain_order=True).agg(aggs).sort(\"essay_id\")\n",
    "    df = df.to_pandas()\n",
    "    return df\n",
    "\n",
    "tmp = Word_Preprocess(train)\n",
    "# Merge the newly generated feature data with the previously generated feature data\n",
    "train_feats = train_feats.merge(Word_Eng(tmp), on='essay_id', how='left')\n",
    "\n",
    "feature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\n",
    "print('Features Number: ',len(feature_names))\n",
    "train_feats.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1def2efa",
   "metadata": {
    "papermill": {
     "duration": 0.011191,
     "end_time": "2024-05-23T08:56:30.993855",
     "exception": false,
     "start_time": "2024-05-23T08:56:30.982664",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46a96ed7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T08:56:31.016961Z",
     "iopub.status.busy": "2024-05-23T08:56:31.016637Z",
     "iopub.status.idle": "2024-05-23T08:59:41.654376Z",
     "shell.execute_reply": "2024-05-23T08:59:41.653437Z"
    },
    "papermill": {
     "duration": 190.662687,
     "end_time": "2024-05-23T08:59:41.667490",
     "exception": false,
     "start_time": "2024-05-23T08:56:31.004803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Number:  19729\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>paragraph_0_cnt</th>\n",
       "      <th>paragraph_50_cnt</th>\n",
       "      <th>paragraph_75_cnt</th>\n",
       "      <th>paragraph_100_cnt</th>\n",
       "      <th>paragraph_125_cnt</th>\n",
       "      <th>paragraph_150_cnt</th>\n",
       "      <th>paragraph_175_cnt</th>\n",
       "      <th>paragraph_200_cnt</th>\n",
       "      <th>paragraph_250_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>tfid_19617</th>\n",
       "      <th>tfid_19618</th>\n",
       "      <th>tfid_19619</th>\n",
       "      <th>tfid_19620</th>\n",
       "      <th>tfid_19621</th>\n",
       "      <th>tfid_19622</th>\n",
       "      <th>tfid_19623</th>\n",
       "      <th>tfid_19624</th>\n",
       "      <th>tfid_19625</th>\n",
       "      <th>tfid_19626</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 19731 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id  paragraph_0_cnt  paragraph_50_cnt  paragraph_75_cnt  \\\n",
       "0  000d118                1                 1                 1   \n",
       "1  000fe60                5                 5                 5   \n",
       "2  001ab80                4                 4                 4   \n",
       "\n",
       "   paragraph_100_cnt  paragraph_125_cnt  paragraph_150_cnt  paragraph_175_cnt  \\\n",
       "0                  1                  1                  1                  1   \n",
       "1                  5                  5                  5                  5   \n",
       "2                  4                  4                  4                  4   \n",
       "\n",
       "   paragraph_200_cnt  paragraph_250_cnt  ...  tfid_19617  tfid_19618  \\\n",
       "0                  1                  1  ...         0.0         0.0   \n",
       "1                  4                  3  ...         0.0         0.0   \n",
       "2                  4                  4  ...         0.0         0.0   \n",
       "\n",
       "   tfid_19619  tfid_19620  tfid_19621  tfid_19622  tfid_19623  tfid_19624  \\\n",
       "0         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   tfid_19625  tfid_19626  \n",
       "0         0.0         0.0  \n",
       "1         0.0         0.0  \n",
       "2         0.0         0.0  \n",
       "\n",
       "[3 rows x 19731 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TfidfVectorizer parameter\n",
    "vectorizer = TfidfVectorizer(\n",
    "            tokenizer=lambda x: x,\n",
    "            preprocessor=lambda x: x,\n",
    "            token_pattern=None,\n",
    "            strip_accents='unicode',\n",
    "            analyzer = 'word',\n",
    "            ngram_range=(3,6),\n",
    "            min_df=0.05,\n",
    "            max_df=0.95,\n",
    "            sublinear_tf=True,\n",
    ")\n",
    "# Fit all datasets into TfidfVector,this may cause leakage and overly optimistic CV scores\n",
    "train_tfid = vectorizer.fit_transform([i for i in train['full_text']])\n",
    "# Convert to array\n",
    "dense_matrix = train_tfid.toarray()\n",
    "# Convert to dataframe\n",
    "df = pd.DataFrame(dense_matrix)\n",
    "# rename features\n",
    "tfid_columns = [ f'tfid_{i}' for i in range(len(df.columns))]\n",
    "df.columns = tfid_columns\n",
    "df['essay_id'] = train_feats['essay_id']\n",
    "# Merge the newly generated feature data with the previously generated feature data\n",
    "train_feats = train_feats.merge(df, on='essay_id', how='left')\n",
    "\n",
    "feature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\n",
    "print('Features Number: ',len(feature_names))\n",
    "train_feats.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a9e8e8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T08:59:41.692073Z",
     "iopub.status.busy": "2024-05-23T08:59:41.691719Z",
     "iopub.status.idle": "2024-05-23T09:00:55.456742Z",
     "shell.execute_reply": "2024-05-23T09:00:55.455803Z"
    },
    "papermill": {
     "duration": 73.791642,
     "end_time": "2024-05-23T09:00:55.470929",
     "exception": false,
     "start_time": "2024-05-23T08:59:41.679287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Number:  21899\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>paragraph_0_cnt</th>\n",
       "      <th>paragraph_50_cnt</th>\n",
       "      <th>paragraph_75_cnt</th>\n",
       "      <th>paragraph_100_cnt</th>\n",
       "      <th>paragraph_125_cnt</th>\n",
       "      <th>paragraph_150_cnt</th>\n",
       "      <th>paragraph_175_cnt</th>\n",
       "      <th>paragraph_200_cnt</th>\n",
       "      <th>paragraph_250_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>tfid_cnt_2160</th>\n",
       "      <th>tfid_cnt_2161</th>\n",
       "      <th>tfid_cnt_2162</th>\n",
       "      <th>tfid_cnt_2163</th>\n",
       "      <th>tfid_cnt_2164</th>\n",
       "      <th>tfid_cnt_2165</th>\n",
       "      <th>tfid_cnt_2166</th>\n",
       "      <th>tfid_cnt_2167</th>\n",
       "      <th>tfid_cnt_2168</th>\n",
       "      <th>tfid_cnt_2169</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21901 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id  paragraph_0_cnt  paragraph_50_cnt  paragraph_75_cnt  \\\n",
       "0  000d118                1                 1                 1   \n",
       "1  000fe60                5                 5                 5   \n",
       "2  001ab80                4                 4                 4   \n",
       "\n",
       "   paragraph_100_cnt  paragraph_125_cnt  paragraph_150_cnt  paragraph_175_cnt  \\\n",
       "0                  1                  1                  1                  1   \n",
       "1                  5                  5                  5                  5   \n",
       "2                  4                  4                  4                  4   \n",
       "\n",
       "   paragraph_200_cnt  paragraph_250_cnt  ...  tfid_cnt_2160  tfid_cnt_2161  \\\n",
       "0                  1                  1  ...              3              0   \n",
       "1                  4                  3  ...              2              0   \n",
       "2                  4                  4  ...              1              0   \n",
       "\n",
       "   tfid_cnt_2162  tfid_cnt_2163  tfid_cnt_2164  tfid_cnt_2165  tfid_cnt_2166  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              1              1              0              0   \n",
       "2              2              0              0              0              0   \n",
       "\n",
       "   tfid_cnt_2167  tfid_cnt_2168  tfid_cnt_2169  \n",
       "0              0              0              0  \n",
       "1              0              0              0  \n",
       "2              0              0              0  \n",
       "\n",
       "[3 rows x 21901 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_cnt = CountVectorizer(\n",
    "            tokenizer=lambda x: x,\n",
    "            preprocessor=lambda x: x,\n",
    "            token_pattern=None,\n",
    "            strip_accents='unicode',\n",
    "            analyzer = 'word',\n",
    "            ngram_range=(2,3),\n",
    "            min_df=0.10,\n",
    "            max_df=0.85,\n",
    ")\n",
    "train_tfid = vectorizer_cnt.fit_transform([i for i in train['full_text']])\n",
    "dense_matrix = train_tfid.toarray()\n",
    "df = pd.DataFrame(dense_matrix)\n",
    "tfid_columns = [ f'tfid_cnt_{i}' for i in range(len(df.columns))]\n",
    "df.columns = tfid_columns\n",
    "df['essay_id'] = train_feats['essay_id']\n",
    "train_feats = train_feats.merge(df, on='essay_id', how='left')\n",
    "\n",
    "feature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\n",
    "print('Features Number: ',len(feature_names))\n",
    "train_feats.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdaff44",
   "metadata": {
    "papermill": {
     "duration": 0.011731,
     "end_time": "2024-05-23T09:00:55.494422",
     "exception": false,
     "start_time": "2024-05-23T09:00:55.482691",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Deberta predictions to LGBM as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a4d129f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T09:00:55.519437Z",
     "iopub.status.busy": "2024-05-23T09:00:55.519138Z",
     "iopub.status.idle": "2024-05-23T09:00:55.532132Z",
     "shell.execute_reply": "2024-05-23T09:00:55.531271Z"
    },
    "papermill": {
     "duration": 0.027713,
     "end_time": "2024-05-23T09:00:55.533924",
     "exception": false,
     "start_time": "2024-05-23T09:00:55.506211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Number:  21899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17307, 21901)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add Deberta predictions to LGBM as features\n",
    "deberta_oof = joblib.load('/kaggle/input/aes2-400-20240419134941/oof.pkl')\n",
    "print(deberta_oof.shape, train_feats.shape)\n",
    "\n",
    "for i in range(6):\n",
    "    train_feats[f'deberta_oof_{i}'] = deberta_oof[:, i]\n",
    "##f'deberta_oof_{i}': 动态字符串 This expression uses an f-string (formatted string literal) to dynamically create a string. The value of i (which is presumably defined earlier in the code, possibly as part of a loop) is inserted into the string, resulting in a column name such as deberta_oof_0, deberta_oof_1, etc., depending on the current value of i.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "feature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\n",
    "print('Features Number: ', len(feature_names))    \n",
    "\n",
    "train_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7248d66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T09:00:55.559302Z",
     "iopub.status.busy": "2024-05-23T09:00:55.559032Z",
     "iopub.status.idle": "2024-05-23T09:00:55.566378Z",
     "shell.execute_reply": "2024-05-23T09:00:55.565617Z"
    },
    "papermill": {
     "duration": 0.022347,
     "end_time": "2024-05-23T09:00:55.568182",
     "exception": false,
     "start_time": "2024-05-23T09:00:55.545835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# idea from https://www.kaggle.com/code/rsakata/optimize-qwk-by-lgb/notebook#QWK-objective\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    y_true = y_true + a\n",
    "    y_pred = (y_pred + a).clip(1, 6).round()\n",
    "    qwk = cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n",
    "    return 'QWK', qwk, True\n",
    "def qwk_obj(y_true, y_pred):\n",
    "    labels = y_true + a\n",
    "    preds = y_pred + a\n",
    "    preds = preds.clip(1, 6)\n",
    "    f = 1/2*np.sum((preds-labels)**2)\n",
    "    g = 1/2*np.sum((preds-a)**2+b) ###g 是预测值与调整常数 a 的差的平方和的一半加上常数 b，可能用于引入正则化\n",
    "    df = preds - labels\n",
    "    dg = preds - a\n",
    "    grad = (df/g - f*dg/g**2)*len(labels)\n",
    "    hess = np.ones(len(labels)) ##hess（海森矩阵）是全1向量，简化了二阶导数的计算，这在使用基于树的算法优化时是典型的做法。\n",
    "    return grad, hess\n",
    "#a = 2.998\n",
    "a = 3.498\n",
    "b = 1.092"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89487bdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T09:00:55.593168Z",
     "iopub.status.busy": "2024-05-23T09:00:55.592924Z",
     "iopub.status.idle": "2024-05-23T09:00:57.506249Z",
     "shell.execute_reply": "2024-05-23T09:00:57.505185Z"
    },
    "papermill": {
     "duration": 1.929157,
     "end_time": "2024-05-23T09:00:57.509228",
     "exception": false,
     "start_time": "2024-05-23T09:00:55.580071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converting the 'text' column to string type and assigning to X\n",
    "X = train_feats[feature_names].astype(np.float32).values\n",
    "\n",
    "# Converting the 'score' column to integer type and assigning to y\n",
    "y_split = train_feats['score'].astype(int).values\n",
    "y = train_feats['score'].astype(np.float32).values-a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1257ed17",
   "metadata": {
    "papermill": {
     "duration": 0.012157,
     "end_time": "2024-05-23T09:00:57.537587",
     "exception": false,
     "start_time": "2024-05-23T09:00:57.525430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4888991c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T09:00:57.608448Z",
     "iopub.status.busy": "2024-05-23T09:00:57.607612Z",
     "iopub.status.idle": "2024-05-23T09:00:57.619832Z",
     "shell.execute_reply": "2024-05-23T09:00:57.618964Z"
    },
    "papermill": {
     "duration": 0.07216,
     "end_time": "2024-05-23T09:00:57.621620",
     "exception": false,
     "start_time": "2024-05-23T09:00:57.549460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_select_wrapper():\n",
    "    \"\"\"\n",
    "    lgm\n",
    "    :param train\n",
    "    :param test\n",
    "    :return\n",
    "    \"\"\"\n",
    "    # Part 1.\n",
    "    print('feature_select_wrapper...')\n",
    "    features = feature_names\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    fse = pd.Series(0, index=features)\n",
    "         \n",
    "    for train_index, test_index in skf.split(X, y_split):\n",
    "\n",
    "        X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
    "        y_train_fold, y_test_fold, y_test_fold_int = y[train_index], y[test_index], y_split[test_index]\n",
    "\n",
    "        model = lgb.LGBMRegressor(\n",
    "                    objective = qwk_obj,\n",
    "                    metrics = 'None',\n",
    "                    learning_rate = 0.05,\n",
    "                    max_depth = 5,\n",
    "                    num_leaves = 10,\n",
    "                    colsample_bytree=0.3,\n",
    "                    reg_alpha = 0.7,\n",
    "                    reg_lambda = 0.1,\n",
    "                    n_estimators=700,\n",
    "                    random_state=412,\n",
    "                    extra_trees=True,\n",
    "                    class_weight='balanced',\n",
    "                    verbosity = - 1)\n",
    "\n",
    "        predictor = model.fit(X_train_fold,\n",
    "                              y_train_fold,\n",
    "                              eval_names=['train', 'valid'],\n",
    "                              eval_set=[(X_train_fold, y_train_fold), (X_test_fold, y_test_fold)],\n",
    "                              eval_metric=quadratic_weighted_kappa,\n",
    "                              callbacks=callbacks)\n",
    "        models.append(predictor)\n",
    "        predictions_fold = predictor.predict(X_test_fold)\n",
    "        predictions_fold = predictions_fold + a\n",
    "        predictions_fold = predictions_fold.clip(1, 6).round()\n",
    "        predictions.append(predictions_fold)\n",
    "        f1_fold = f1_score(y_test_fold_int, predictions_fold, average='weighted')\n",
    "        f1_scores.append(f1_fold)\n",
    "\n",
    "        kappa_fold = cohen_kappa_score(y_test_fold_int, predictions_fold, weights='quadratic')\n",
    "        kappa_scores.append(kappa_fold)\n",
    "\n",
    "#         cm = confusion_matrix(y_test_fold_int, predictions_fold, labels=[x for x in range(1,7)])\n",
    "\n",
    "#         disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "#                                       display_labels=[x for x in range(1,7)])\n",
    "#         disp.plot()\n",
    "#         plt.show()\n",
    "        print(f'F1 score across fold: {f1_fold}')\n",
    "        print(f'Cohen kappa score across fold: {kappa_fold}')\n",
    "\n",
    "        fse += pd.Series(predictor.feature_importances_, features)  \n",
    "    \n",
    "    # Part 4.\n",
    "    feature_select = fse.sort_values(ascending=False).index.tolist()[:13000]\n",
    "    print('done')\n",
    "    return feature_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12d7711b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T09:00:57.647471Z",
     "iopub.status.busy": "2024-05-23T09:00:57.647194Z",
     "iopub.status.idle": "2024-05-23T09:23:23.585729Z",
     "shell.execute_reply": "2024-05-23T09:23:23.584773Z"
    },
    "papermill": {
     "duration": 1345.953904,
     "end_time": "2024-05-23T09:23:23.587969",
     "exception": false,
     "start_time": "2024-05-23T09:00:57.634065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_select_wrapper...\n",
      "[LightGBM] [Info] Using self-defined objective function\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "[25]\ttrain's QWK: 0.695384\tvalid's QWK: 0.676414\n",
      "[50]\ttrain's QWK: 0.732402\tvalid's QWK: 0.711074\n",
      "[75]\ttrain's QWK: 0.760367\tvalid's QWK: 0.733842\n",
      "[100]\ttrain's QWK: 0.775645\tvalid's QWK: 0.748823\n",
      "[125]\ttrain's QWK: 0.788042\tvalid's QWK: 0.757456\n",
      "[150]\ttrain's QWK: 0.797033\tvalid's QWK: 0.766514\n",
      "[175]\ttrain's QWK: 0.803783\tvalid's QWK: 0.770763\n",
      "[200]\ttrain's QWK: 0.809159\tvalid's QWK: 0.777213\n",
      "[225]\ttrain's QWK: 0.815096\tvalid's QWK: 0.780047\n",
      "[250]\ttrain's QWK: 0.819957\tvalid's QWK: 0.782027\n",
      "[275]\ttrain's QWK: 0.823794\tvalid's QWK: 0.786134\n",
      "[300]\ttrain's QWK: 0.828644\tvalid's QWK: 0.788039\n",
      "[325]\ttrain's QWK: 0.83268\tvalid's QWK: 0.791096\n",
      "[350]\ttrain's QWK: 0.836666\tvalid's QWK: 0.791873\n",
      "[375]\ttrain's QWK: 0.839207\tvalid's QWK: 0.794682\n",
      "[400]\ttrain's QWK: 0.842117\tvalid's QWK: 0.795642\n",
      "[425]\ttrain's QWK: 0.844513\tvalid's QWK: 0.795026\n",
      "[450]\ttrain's QWK: 0.846744\tvalid's QWK: 0.796545\n",
      "[475]\ttrain's QWK: 0.849228\tvalid's QWK: 0.798751\n",
      "[500]\ttrain's QWK: 0.851274\tvalid's QWK: 0.799078\n",
      "[525]\ttrain's QWK: 0.853124\tvalid's QWK: 0.799695\n",
      "[550]\ttrain's QWK: 0.855586\tvalid's QWK: 0.799821\n",
      "[575]\ttrain's QWK: 0.858184\tvalid's QWK: 0.799666\n",
      "[600]\ttrain's QWK: 0.860426\tvalid's QWK: 0.800794\n",
      "[625]\ttrain's QWK: 0.862558\tvalid's QWK: 0.800754\n",
      "[650]\ttrain's QWK: 0.864692\tvalid's QWK: 0.800296\n",
      "[675]\ttrain's QWK: 0.866299\tvalid's QWK: 0.800349\n",
      "[700]\ttrain's QWK: 0.868567\tvalid's QWK: 0.800477\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[636]\ttrain's QWK: 0.863768\tvalid's QWK: 0.80124\n",
      "Evaluated only: QWK\n",
      "F1 score across fold: 0.624126777350865\n",
      "Cohen kappa score across fold: 0.801240287300738\n",
      "[LightGBM] [Info] Using self-defined objective function\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "[25]\ttrain's QWK: 0.690698\tvalid's QWK: 0.691297\n",
      "[50]\ttrain's QWK: 0.730142\tvalid's QWK: 0.731901\n",
      "[75]\ttrain's QWK: 0.758177\tvalid's QWK: 0.747241\n",
      "[100]\ttrain's QWK: 0.774888\tvalid's QWK: 0.763458\n",
      "[125]\ttrain's QWK: 0.786698\tvalid's QWK: 0.772795\n",
      "[150]\ttrain's QWK: 0.797219\tvalid's QWK: 0.780028\n",
      "[175]\ttrain's QWK: 0.804428\tvalid's QWK: 0.786056\n",
      "[200]\ttrain's QWK: 0.811205\tvalid's QWK: 0.787959\n",
      "[225]\ttrain's QWK: 0.815664\tvalid's QWK: 0.79088\n",
      "[250]\ttrain's QWK: 0.820555\tvalid's QWK: 0.791007\n",
      "[275]\ttrain's QWK: 0.823867\tvalid's QWK: 0.793892\n",
      "[300]\ttrain's QWK: 0.828163\tvalid's QWK: 0.794512\n",
      "[325]\ttrain's QWK: 0.831355\tvalid's QWK: 0.797154\n",
      "[350]\ttrain's QWK: 0.83382\tvalid's QWK: 0.79887\n",
      "[375]\ttrain's QWK: 0.836883\tvalid's QWK: 0.798891\n",
      "[400]\ttrain's QWK: 0.83982\tvalid's QWK: 0.800128\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[425]\ttrain's QWK: 0.843189\tvalid's QWK: 0.801096\n",
      "[450]\ttrain's QWK: 0.84556\tvalid's QWK: 0.801977\n",
      "[475]\ttrain's QWK: 0.848194\tvalid's QWK: 0.802724\n",
      "[500]\ttrain's QWK: 0.851125\tvalid's QWK: 0.801966\n",
      "[525]\ttrain's QWK: 0.852865\tvalid's QWK: 0.803217\n",
      "[550]\ttrain's QWK: 0.8558\tvalid's QWK: 0.803118\n",
      "[575]\ttrain's QWK: 0.857614\tvalid's QWK: 0.80252\n",
      "[600]\ttrain's QWK: 0.860215\tvalid's QWK: 0.802224\n",
      "Early stopping, best iteration is:\n",
      "[535]\ttrain's QWK: 0.854001\tvalid's QWK: 0.803937\n",
      "Evaluated only: QWK\n",
      "F1 score across fold: 0.6314402955711317\n",
      "Cohen kappa score across fold: 0.8039373651183003\n",
      "[LightGBM] [Info] Using self-defined objective function\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "[25]\ttrain's QWK: 0.690613\tvalid's QWK: 0.680911\n",
      "[50]\ttrain's QWK: 0.734123\tvalid's QWK: 0.716053\n",
      "[75]\ttrain's QWK: 0.760014\tvalid's QWK: 0.736031\n",
      "[100]\ttrain's QWK: 0.776289\tvalid's QWK: 0.753556\n",
      "[125]\ttrain's QWK: 0.788292\tvalid's QWK: 0.763667\n",
      "[150]\ttrain's QWK: 0.79723\tvalid's QWK: 0.769678\n",
      "[175]\ttrain's QWK: 0.804432\tvalid's QWK: 0.777471\n",
      "[200]\ttrain's QWK: 0.809817\tvalid's QWK: 0.781536\n",
      "[225]\ttrain's QWK: 0.815823\tvalid's QWK: 0.78715\n",
      "[250]\ttrain's QWK: 0.820077\tvalid's QWK: 0.787914\n",
      "[275]\ttrain's QWK: 0.824687\tvalid's QWK: 0.791151\n",
      "[300]\ttrain's QWK: 0.828438\tvalid's QWK: 0.792148\n",
      "[325]\ttrain's QWK: 0.831969\tvalid's QWK: 0.797216\n",
      "[350]\ttrain's QWK: 0.834442\tvalid's QWK: 0.797913\n",
      "[375]\ttrain's QWK: 0.837397\tvalid's QWK: 0.798849\n",
      "[400]\ttrain's QWK: 0.840296\tvalid's QWK: 0.800838\n",
      "[425]\ttrain's QWK: 0.843018\tvalid's QWK: 0.802781\n",
      "[450]\ttrain's QWK: 0.845738\tvalid's QWK: 0.802931\n",
      "[475]\ttrain's QWK: 0.849176\tvalid's QWK: 0.80426\n",
      "[500]\ttrain's QWK: 0.85134\tvalid's QWK: 0.803163\n",
      "[525]\ttrain's QWK: 0.854061\tvalid's QWK: 0.802958\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[474]\ttrain's QWK: 0.848952\tvalid's QWK: 0.804374\n",
      "Evaluated only: QWK\n",
      "F1 score across fold: 0.6371054919794285\n",
      "Cohen kappa score across fold: 0.8043736508801327\n",
      "[LightGBM] [Info] Using self-defined objective function\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "[25]\ttrain's QWK: 0.691237\tvalid's QWK: 0.685588\n",
      "[50]\ttrain's QWK: 0.732646\tvalid's QWK: 0.72022\n",
      "[75]\ttrain's QWK: 0.760867\tvalid's QWK: 0.748452\n",
      "[100]\ttrain's QWK: 0.775461\tvalid's QWK: 0.761275\n",
      "[125]\ttrain's QWK: 0.787451\tvalid's QWK: 0.770366\n",
      "[150]\ttrain's QWK: 0.795963\tvalid's QWK: 0.779414\n",
      "[175]\ttrain's QWK: 0.804944\tvalid's QWK: 0.78339\n",
      "[200]\ttrain's QWK: 0.811856\tvalid's QWK: 0.78783\n",
      "[225]\ttrain's QWK: 0.815972\tvalid's QWK: 0.789507\n",
      "[250]\ttrain's QWK: 0.81997\tvalid's QWK: 0.791644\n",
      "[275]\ttrain's QWK: 0.82405\tvalid's QWK: 0.795453\n",
      "[300]\ttrain's QWK: 0.827739\tvalid's QWK: 0.796581\n",
      "[325]\ttrain's QWK: 0.831026\tvalid's QWK: 0.799571\n",
      "[350]\ttrain's QWK: 0.834477\tvalid's QWK: 0.800933\n",
      "[375]\ttrain's QWK: 0.837809\tvalid's QWK: 0.802372\n",
      "[400]\ttrain's QWK: 0.840995\tvalid's QWK: 0.802489\n",
      "[425]\ttrain's QWK: 0.843335\tvalid's QWK: 0.803659\n",
      "[450]\ttrain's QWK: 0.845225\tvalid's QWK: 0.80322\n",
      "[475]\ttrain's QWK: 0.848262\tvalid's QWK: 0.805377\n",
      "[500]\ttrain's QWK: 0.850751\tvalid's QWK: 0.805053\n",
      "[525]\ttrain's QWK: 0.852629\tvalid's QWK: 0.80626\n",
      "[550]\ttrain's QWK: 0.854723\tvalid's QWK: 0.805544\n",
      "[575]\ttrain's QWK: 0.856818\tvalid's QWK: 0.805549\n",
      "[600]\ttrain's QWK: 0.858982\tvalid's QWK: 0.805566\n",
      "Early stopping, best iteration is:\n",
      "[527]\ttrain's QWK: 0.852717\tvalid's QWK: 0.806418\n",
      "Evaluated only: QWK\n",
      "F1 score across fold: 0.6285243120348364\n",
      "Cohen kappa score across fold: 0.8064180144607891\n",
      "[LightGBM] [Info] Using self-defined objective function\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "[25]\ttrain's QWK: 0.689178\tvalid's QWK: 0.706811\n",
      "[50]\ttrain's QWK: 0.726072\tvalid's QWK: 0.727938\n",
      "[75]\ttrain's QWK: 0.755091\tvalid's QWK: 0.753019\n",
      "[100]\ttrain's QWK: 0.771253\tvalid's QWK: 0.767068\n",
      "[125]\ttrain's QWK: 0.784046\tvalid's QWK: 0.775666\n",
      "[150]\ttrain's QWK: 0.792692\tvalid's QWK: 0.78624\n",
      "[175]\ttrain's QWK: 0.802674\tvalid's QWK: 0.788535\n",
      "[200]\ttrain's QWK: 0.809538\tvalid's QWK: 0.792251\n",
      "[225]\ttrain's QWK: 0.814378\tvalid's QWK: 0.795312\n",
      "[250]\ttrain's QWK: 0.818348\tvalid's QWK: 0.798098\n",
      "[275]\ttrain's QWK: 0.822581\tvalid's QWK: 0.797834\n",
      "[300]\ttrain's QWK: 0.825272\tvalid's QWK: 0.800211\n",
      "[325]\ttrain's QWK: 0.829262\tvalid's QWK: 0.801625\n",
      "[350]\ttrain's QWK: 0.832368\tvalid's QWK: 0.803755\n",
      "[375]\ttrain's QWK: 0.835088\tvalid's QWK: 0.804494\n",
      "[400]\ttrain's QWK: 0.837471\tvalid's QWK: 0.805939\n",
      "[425]\ttrain's QWK: 0.840556\tvalid's QWK: 0.806524\n",
      "[450]\ttrain's QWK: 0.843418\tvalid's QWK: 0.806326\n",
      "[475]\ttrain's QWK: 0.846668\tvalid's QWK: 0.805472\n",
      "[500]\ttrain's QWK: 0.849367\tvalid's QWK: 0.804315\n",
      "Early stopping, best iteration is:\n",
      "[435]\ttrain's QWK: 0.84218\tvalid's QWK: 0.807126\n",
      "Evaluated only: QWK\n",
      "F1 score across fold: 0.6272743939224616\n",
      "Cohen kappa score across fold: 0.8071262884716498\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "f1_scores = []\n",
    "kappa_scores = []\n",
    "models = []\n",
    "predictions = []\n",
    "callbacks = [log_evaluation(period=25), early_stopping(stopping_rounds=75,first_metric_only=True)]\n",
    "feature_select = feature_select_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fada7ec4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T09:23:23.632729Z",
     "iopub.status.busy": "2024-05-23T09:23:23.632198Z",
     "iopub.status.idle": "2024-05-23T09:23:24.738878Z",
     "shell.execute_reply": "2024-05-23T09:23:24.737903Z"
    },
    "papermill": {
     "duration": 1.130776,
     "end_time": "2024-05-23T09:23:24.740869",
     "exception": false,
     "start_time": "2024-05-23T09:23:23.610093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Select Number:  13000\n"
     ]
    }
   ],
   "source": [
    "X = train_feats[feature_select].astype(np.float32).values\n",
    "print('Features Select Number: ', len(feature_select))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf8d739",
   "metadata": {
    "papermill": {
     "duration": 0.021093,
     "end_time": "2024-05-23T09:23:24.783752",
     "exception": false,
     "start_time": "2024-05-23T09:23:24.762659",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94b1b4d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T09:23:24.827356Z",
     "iopub.status.busy": "2024-05-23T09:23:24.827030Z",
     "iopub.status.idle": "2024-05-23T10:06:48.754830Z",
     "shell.execute_reply": "2024-05-23T10:06:48.753889Z"
    },
    "papermill": {
     "duration": 2603.952053,
     "end_time": "2024-05-23T10:06:48.756858",
     "exception": false,
     "start_time": "2024-05-23T09:23:24.804805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "No OpenCL device found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 43\u001b[0m\n\u001b[1;32m     26\u001b[0m model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMRegressor(\n\u001b[1;32m     27\u001b[0m             objective \u001b[38;5;241m=\u001b[39m qwk_obj,\n\u001b[1;32m     28\u001b[0m             metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m             device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     40\u001b[0m             verbosity \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Fit the model on the training data for this fold  \u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                      \u001b[49m\u001b[43my_train_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m                      \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m                      \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_fold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_fold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m                      \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquadratic_weighted_kappa\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                     \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m models\u001b[38;5;241m.\u001b[39mappend(predictor)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Make predictions on the test data for this fold\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/aes/lib/python3.10/site-packages/lightgbm/sklearn.py:1092\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1077\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1089\u001b[0m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLGBMRegressor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1092\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/aes/lib/python3.10/site-packages/lightgbm/sklearn.py:885\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    882\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    883\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 885\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mbest_iteration\n",
      "File \u001b[0;32m~/anaconda3/envs/aes/lib/python3.10/site-packages/lightgbm/engine.py:255\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 255\u001b[0m     booster \u001b[38;5;241m=\u001b[39m \u001b[43mBooster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[1;32m    257\u001b[0m         booster\u001b[38;5;241m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/aes/lib/python3.10/site-packages/lightgbm/basic.py:3437\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[0;34m(self, params, train_set, model_file, model_str)\u001b[0m\n\u001b[1;32m   3435\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(train_set\u001b[38;5;241m.\u001b[39mget_params())\n\u001b[1;32m   3436\u001b[0m params_str \u001b[38;5;241m=\u001b[39m _param_dict_to_str(params)\n\u001b[0;32m-> 3437\u001b[0m \u001b[43m_safe_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterCreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3438\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3439\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_c_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_str\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3441\u001b[0m \u001b[38;5;66;03m# save reference to data\u001b[39;00m\n\u001b[1;32m   3442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_set \u001b[38;5;241m=\u001b[39m train_set\n",
      "File \u001b[0;32m~/anaconda3/envs/aes/lib/python3.10/site-packages/lightgbm/basic.py:263\u001b[0m, in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \n\u001b[1;32m    257\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03m    The return value from C API calls.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 263\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(_LIB\u001b[38;5;241m.\u001b[39mLGBM_GetLastError()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mLightGBMError\u001b[0m: No OpenCL device found"
     ]
    }
   ],
   "source": [
    "LOAD = True # re-train\n",
    "# Define the number of splits for cross-validation\n",
    "n_splits = 15\n",
    "models = []\n",
    "\n",
    "if not LOAD:\n",
    "    for i in range(n_splits):\n",
    "        models.append(lgb.Booster(model_file=f'kaggle/input/aes-lgbm/fold_{i+1}.txt'))\n",
    "else:\n",
    "    # Initialize StratifiedKFold with the specified number of splits\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "    # Lists to store scores\n",
    "    f1_scores = []\n",
    "    kappa_scores = []\n",
    "    models = []\n",
    "    predictions = []\n",
    "    callbacks = [log_evaluation(period=25), early_stopping(stopping_rounds=75,first_metric_only=True)]\n",
    "    # Loop through each fold of the cross-validation\n",
    "    i=1\n",
    "    for train_index, test_index in skf.split(X, y_split):\n",
    "        # Split the data into training and testing sets for this fold\n",
    "        print('fold',i)\n",
    "        X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
    "        y_train_fold, y_test_fold, y_test_fold_int = y[train_index], y[test_index], y_split[test_index]\n",
    "\n",
    "        model = lgb.LGBMRegressor(\n",
    "                    objective = qwk_obj,\n",
    "                    metrics = 'None',\n",
    "                    learning_rate = 0.05,\n",
    "                    max_depth = 5,\n",
    "                    num_leaves = 10,\n",
    "                    colsample_bytree=0.3,\n",
    "                    reg_alpha = 0.7,\n",
    "                    reg_lambda = 0.1,\n",
    "                    n_estimators=700,\n",
    "                    random_state=42,\n",
    "                    extra_trees=True,\n",
    "                    class_weight='balanced',\n",
    "                    device='gpu',\n",
    "                    verbosity = - 1)\n",
    "\n",
    "        # Fit the model on the training data for this fold  \n",
    "        predictor = model.fit(X_train_fold,\n",
    "                              y_train_fold,\n",
    "                              eval_names=['train', 'valid'],\n",
    "                              eval_set=[(X_train_fold, y_train_fold), (X_test_fold, y_test_fold)],\n",
    "                              eval_metric=quadratic_weighted_kappa,\n",
    "                              callbacks=callbacks\n",
    "                             )\n",
    "\n",
    "        models.append(predictor)\n",
    "        # Make predictions on the test data for this fold\n",
    "        predictions_fold = predictor.predict(X_test_fold)\n",
    "        predictions_fold = predictions_fold + a\n",
    "        predictions_fold = predictions_fold.clip(1, 6).round()\n",
    "        predictions.append(predictions_fold)\n",
    "        # Calculate and store the F1 score for this fold\n",
    "        f1_fold = f1_score(y_test_fold_int, predictions_fold, average='weighted')\n",
    "        f1_scores.append(f1_fold)\n",
    "\n",
    "        # Calculate and store the Cohen's kappa score for this fold\n",
    "        kappa_fold = cohen_kappa_score(y_test_fold_int, predictions_fold, weights='quadratic')\n",
    "        kappa_scores.append(kappa_fold)\n",
    "        predictor.booster_.save_model(f'kaggle/out/aes-lgbm/fold_{i}.txt')\n",
    "\n",
    "        print(f'F1 score across fold: {f1_fold}')\n",
    "        print(f'Cohen kappa score across fold: {kappa_fold}')\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c7e844",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T10:06:48.861485Z",
     "iopub.status.busy": "2024-05-23T10:06:48.861176Z",
     "iopub.status.idle": "2024-05-23T10:06:48.867121Z",
     "shell.execute_reply": "2024-05-23T10:06:48.866257Z"
    },
    "papermill": {
     "duration": 0.059656,
     "end_time": "2024-05-23T10:06:48.869069",
     "exception": false,
     "start_time": "2024-05-23T10:06:48.809413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 score across 15 folds: 0.6367833614993369\n",
      "Mean Cohen kappa score across 15 folds: 0.8109574965444472\n"
     ]
    }
   ],
   "source": [
    "if not LOAD:\n",
    "    print(f'Mean F1 score across {n_splits} folds: 0.6694070084827064')\n",
    "    print(f'Mean Cohen kappa score across {n_splits} folds: 0.835342584985933')\n",
    "else:\n",
    "    # Calculate the mean scores across all folds\n",
    "    mean_f1_score = np.mean(f1_scores)\n",
    "    mean_kappa_score = np.mean(kappa_scores)\n",
    "    # Print the mean scores\n",
    "    print(f'Mean F1 score across {n_splits} folds: {mean_f1_score}')\n",
    "    print(f'Mean Cohen kappa score across {n_splits} folds: {mean_kappa_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41a7a60",
   "metadata": {
    "papermill": {
     "duration": 0.098396,
     "end_time": "2024-05-23T10:06:49.018092",
     "exception": false,
     "start_time": "2024-05-23T10:06:48.919696",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d9908e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T10:06:49.121130Z",
     "iopub.status.busy": "2024-05-23T10:06:49.120769Z",
     "iopub.status.idle": "2024-05-23T10:06:49.659235Z",
     "shell.execute_reply": "2024-05-23T10:06:49.657608Z"
    },
    "papermill": {
     "duration": 0.593162,
     "end_time": "2024-05-23T10:06:49.661984",
     "exception": false,
     "start_time": "2024-05-23T10:06:49.068822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features number:  21899\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>paragraph_0_cnt</th>\n",
       "      <th>paragraph_50_cnt</th>\n",
       "      <th>paragraph_75_cnt</th>\n",
       "      <th>paragraph_100_cnt</th>\n",
       "      <th>paragraph_125_cnt</th>\n",
       "      <th>paragraph_150_cnt</th>\n",
       "      <th>paragraph_175_cnt</th>\n",
       "      <th>paragraph_200_cnt</th>\n",
       "      <th>paragraph_250_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>tfid_cnt_2160</th>\n",
       "      <th>tfid_cnt_2161</th>\n",
       "      <th>tfid_cnt_2162</th>\n",
       "      <th>tfid_cnt_2163</th>\n",
       "      <th>tfid_cnt_2164</th>\n",
       "      <th>tfid_cnt_2165</th>\n",
       "      <th>tfid_cnt_2166</th>\n",
       "      <th>tfid_cnt_2167</th>\n",
       "      <th>tfid_cnt_2168</th>\n",
       "      <th>tfid_cnt_2169</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21900 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id  paragraph_0_cnt  paragraph_50_cnt  paragraph_75_cnt  \\\n",
       "0  000d118                1                 1                 1   \n",
       "1  000fe60                5                 5                 5   \n",
       "2  001ab80                4                 4                 4   \n",
       "\n",
       "   paragraph_100_cnt  paragraph_125_cnt  paragraph_150_cnt  paragraph_175_cnt  \\\n",
       "0                  1                  1                  1                  1   \n",
       "1                  5                  5                  5                  5   \n",
       "2                  4                  4                  4                  4   \n",
       "\n",
       "   paragraph_200_cnt  paragraph_250_cnt  ...  tfid_cnt_2160  tfid_cnt_2161  \\\n",
       "0                  1                  1  ...              3              0   \n",
       "1                  4                  3  ...              2              0   \n",
       "2                  4                  4  ...              1              0   \n",
       "\n",
       "   tfid_cnt_2162  tfid_cnt_2163  tfid_cnt_2164  tfid_cnt_2165  tfid_cnt_2166  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              1              1              0              0   \n",
       "2              2              0              0              0              0   \n",
       "\n",
       "   tfid_cnt_2167  tfid_cnt_2168  tfid_cnt_2169  \n",
       "0              0              0              0  \n",
       "1              0              0              0  \n",
       "2              0              0              0  \n",
       "\n",
       "[3 rows x 21900 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paragraph\n",
    "tmp = Paragraph_Preprocess(test)\n",
    "test_feats = Paragraph_Eng(tmp)\n",
    "# Sentence\n",
    "tmp = Sentence_Preprocess(test)\n",
    "test_feats = test_feats.merge(Sentence_Eng(tmp), on='essay_id', how='left')\n",
    "# Word\n",
    "tmp = Word_Preprocess(test)\n",
    "test_feats = test_feats.merge(Word_Eng(tmp), on='essay_id', how='left')\n",
    "\n",
    "# TfidfVectorizer\n",
    "test_tfid = vectorizer.transform([i for i in test['full_text']])\n",
    "dense_matrix = test_tfid.toarray()\n",
    "df = pd.DataFrame(dense_matrix)\n",
    "tfid_columns = [ f'tfid_{i}' for i in range(len(df.columns))]\n",
    "df.columns = tfid_columns\n",
    "df['essay_id'] = test_feats['essay_id']\n",
    "test_feats = test_feats.merge(df, on='essay_id', how='left')\n",
    "\n",
    "# CountVectorizer\n",
    "test_tfid = vectorizer_cnt.transform([i for i in test['full_text']])\n",
    "dense_matrix = test_tfid.toarray()\n",
    "df = pd.DataFrame(dense_matrix)\n",
    "tfid_columns = [ f'tfid_cnt_{i}' for i in range(len(df.columns))]\n",
    "df.columns = tfid_columns\n",
    "df['essay_id'] = test_feats['essay_id']\n",
    "test_feats = test_feats.merge(df, on='essay_id', how='left')\n",
    "\n",
    "# for i in range(6):\n",
    "#     test_feats[f'deberta_oof_{i}'] = predicted_score[:, i]\n",
    "\n",
    "# Features number\n",
    "feature_names = list(filter(lambda x: x not in ['essay_id','score'], test_feats.columns))\n",
    "print('Features number: ',len(feature_names))\n",
    "test_feats.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7323812f",
   "metadata": {
    "papermill": {
     "duration": 0.051485,
     "end_time": "2024-05-23T10:06:49.767931",
     "exception": false,
     "start_time": "2024-05-23T10:06:49.716446",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3326e4ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T10:06:49.874745Z",
     "iopub.status.busy": "2024-05-23T10:06:49.874328Z",
     "iopub.status.idle": "2024-05-23T10:06:50.698170Z",
     "shell.execute_reply": "2024-05-23T10:06:50.697073Z"
    },
    "papermill": {
     "duration": 0.880733,
     "end_time": "2024-05-23T10:06:50.700846",
     "exception": false,
     "start_time": "2024-05-23T10:06:49.820113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 3. 5.]\n"
     ]
    }
   ],
   "source": [
    "probabilities = []\n",
    "for model in models:\n",
    "    proba = model.predict(test_feats[feature_select]) + a\n",
    "    probabilities.append(proba)\n",
    "    \n",
    "# Compute the average probabilities across all models\n",
    "predictions = np.mean(probabilities, axis=0)\n",
    "predictions = np.round(predictions.clip(1, 6))\n",
    "\n",
    "# Print the predictions\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0354517",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T10:06:50.822995Z",
     "iopub.status.busy": "2024-05-23T10:06:50.822584Z",
     "iopub.status.idle": "2024-05-23T10:06:50.843901Z",
     "shell.execute_reply": "2024-05-23T10:06:50.842820Z"
    },
    "papermill": {
     "duration": 0.08344,
     "end_time": "2024-05-23T10:06:50.846250",
     "exception": false,
     "start_time": "2024-05-23T10:06:50.762810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id  score\n",
       "0  000d118      2\n",
       "1  000fe60      3\n",
       "2  001ab80      5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission = pd.read_csv(\"kaggle/input/learning-agency-lab-automated-essay-scoring-2/sample_submission.csv\")\n",
    "submission['score'] = predictions\n",
    "submission['score'] = submission['score'].astype(int)\n",
    "submission.to_csv(\"submission.csv\", index=None)\n",
    "display(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058af075",
   "metadata": {
    "papermill": {
     "duration": 0.055446,
     "end_time": "2024-05-23T10:06:50.964180",
     "exception": false,
     "start_time": "2024-05-23T10:06:50.908734",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"color:white;display:fill;border-radius:5px;background-color:seaGreen;text-align:center;letter-spacing:0.1px;overflow:hidden;padding:20px;color:white;overflow:hidden;margin:0;font-size:100%\">▶️ Ensemble ◀️</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653bcfb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T10:06:51.075299Z",
     "iopub.status.busy": "2024-05-23T10:06:51.074584Z",
     "iopub.status.idle": "2024-05-23T10:06:51.079242Z",
     "shell.execute_reply": "2024-05-23T10:06:51.078288Z"
    },
    "papermill": {
     "duration": 0.061076,
     "end_time": "2024-05-23T10:06:51.081331",
     "exception": false,
     "start_time": "2024-05-23T10:06:51.020255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Load the data\n",
    "# df1 = pd.read_csv('/kaggle/working/submission_1.csv')\n",
    "# df2 = pd.read_csv('/kaggle/working/submission_2.csv')\n",
    "\n",
    "# # Merging the dataframes on 'essay_id'\n",
    "# df = pd.merge(left=df1, right=df2, on='essay_id', suffixes=('_1', '_2'))\n",
    "\n",
    "# # Calculating the average score directly without apply()\n",
    "# df['score'] = ((df['score_1'] + df['score_2']) / 2).round().astype(int)\n",
    "\n",
    "# # Saving the desired columns to a new csv file\n",
    "# df[['essay_id', 'score']].to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8059942,
     "sourceId": 71485,
     "sourceType": "competition"
    },
    {
     "datasetId": 4813598,
     "sourceId": 8141507,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4832208,
     "sourceId": 8166166,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4791897,
     "sourceId": 8339744,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5497.80216,
   "end_time": "2024-05-23T10:06:53.821752",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-23T08:35:16.019592",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

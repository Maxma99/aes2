{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è¯»å–æ•°æ®é›†ï¼Œå¹¶ä¸”è½¬å˜prompt ä¸º labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"  # æŒ‡å®šä½¿ç”¨ GPU 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 01:04:55.741598: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-30 01:04:55.803903: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-30 01:04:55.803947: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-30 01:04:55.805436: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-30 01:04:55.814763: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-30 01:04:57.447280: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, EvalPrediction\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/home/mcq/GitHub/aes2/kaggle/input/learning-agency-lab-automated-essay-scoring-2/\"\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(PATH + \"train.csv\")\n",
    "#data1 = pd.read_csv(PATHS.train_path)\n",
    "persuade = pd.read_csv('/home/mcq/GitHub/aes2/train_data/persuade_2.0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## å°†promptè½¬å˜ä¸ºæ•°å­—\n",
    "persuade[\"label\"] =  persuade[\"prompt_name\"].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "##è®¡ç®—äº¤å‰ç‚¹\n",
    "intersection = pd.merge(train_df, persuade, on=\"full_text\", how=\"inner\")[[\"essay_id\", \"full_text\", \"score\", \"prompt_name\",\"label\"]].reset_index(drop=True)\n",
    "persuade.rename(columns={'essay_id_comp': 'essay_id'}, inplace=True)\n",
    "persuade.rename(columns={'holistic_essay_score': 'score'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ•°æ®é›†å»é™¤äº¤å‰æ•°æ®ï¼Œ è¿”å›å¤§æ•°æ®é›†labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(intersection): 4436\n",
      "len(difference): 25996\n"
     ]
    }
   ],
   "source": [
    "difference = train_df[~train_df[\"essay_id\"].isin(intersection[\"essay_id\"])].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "###ç›´æ¥æ›¿æ¢SKFçš„trainå°±å¯ä»¥ \n",
    "difference1 = persuade[~persuade[\"essay_id\"].isin(intersection[\"essay_id\"])].reset_index(drop=True)\n",
    "difference1 = difference1.iloc[:, :3] \n",
    "skf_train = pd.concat([train_df, difference1], axis=0, ignore_index=True) \n",
    "### skf_trainå°±æ˜¯åŠ è¿‡é¢å¤–æ•°æ®é›†çš„trainäº†ï¼Œ \n",
    "\n",
    "\n",
    "\n",
    "difference2 = persuade[~persuade[\"essay_id\"].isin(intersection[\"essay_id\"])].reset_index(drop=True)\n",
    "# print(\"len(intersection):\", len(difference))\n",
    "# print(\"len(difference):\", len(difference2))\n",
    "### æœ‰25996ä¸ªæ•°æ®é›†\n",
    "###é¦–å…ˆdropæ‰0-6ä¹‹é—´çš„topicæ•°æ®ç‚¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = difference2['label'].isin([1,  5 , 0 , 7 , 6 , 8 ,14])\n",
    "df_dropped = difference2[~mask]\n",
    "GFX_add7 = difference2[~difference2[\"essay_id\"].isin(df_dropped[\"essay_id\"])].reset_index(drop=True)\n",
    "##GFX_add7é•¿åº¦ä¸º12873ï¼Œæ˜¯åœ¨7ä¸ªtopicä¹‹å†…çš„ç‚¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>Phones\\n\\nModern humans today are always on th...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BC75783F96E3</td>\n",
       "      <td>This essay will explain if drivers should or s...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74C8BC7417DE</td>\n",
       "      <td>Driving while the use of cellular devices\\n\\nT...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A8445CABFECE</td>\n",
       "      <td>Phones &amp; Driving\\n\\nDrivers should not be able...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6B4F7A0165B9</td>\n",
       "      <td>Cell Phone Operation While Driving\\n\\nThe abil...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       essay_id                                          full_text  score\n",
       "0  423A1CA112E2  Phones\\n\\nModern humans today are always on th...      3\n",
       "1  BC75783F96E3  This essay will explain if drivers should or s...      4\n",
       "2  74C8BC7417DE  Driving while the use of cellular devices\\n\\nT...      2\n",
       "3  A8445CABFECE  Phones & Driving\\n\\nDrivers should not be able...      3\n",
       "4  6B4F7A0165B9  Cell Phone Operation While Driving\\n\\nThe abil...      4"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GKF_train = df_dropped ###é•¿åº¦ä¸º13121,æ˜¯topicä¹‹å¤–çš„ç‚¹\n",
    "GKF_train = GKF_train.iloc[:, :3]  ##æ•°æ®è§„èŒƒåŒ–å¤„ç†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åœ¨åŸå§‹æ•°æ®é›†ä¸­æ·»åŠ é¢å¤–çš„7topicsä¹‹å†…çš„ä»£ç ï¼Œå¯¹åº”çš„æ˜¯GFX_add7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7612dea7dc6d4ed9bbd33265c80a44fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17307 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcq2/anaconda3/envs/aes/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import topicfeaturesmall\n",
    "PATH = \"/home/mcq2/GitHub/aes2/kaggle/input/learning-agency-lab-automated-essay-scoring-2/\"\n",
    "train = pd.read_csv(PATH + \"train.csv\")\n",
    "topic = topicfeaturesmall.predict_chunk(train)\n",
    "groups_1= topic['topic'] ## è¯»å–ä¸€ä¸‡ä¸ƒçš„topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_2 = GFX_add7['label'] ##è¯»å–é¢å¤–çš„topic\n",
    "groups = pd.concat([groups_1, groups_2], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GFX_add7 = GFX_add7.iloc[:, :3] ### æ³¨æ„è¿™ä¸ªä¸€å®šè¦æ”¾åœ¨groupæå–ä¹‹åï¼Œå› ä¸ºè¿™é‡Œå·²ç»æŠŠtopicåˆ—åˆ æ‰äº†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2 = pd.concat([train, GFX_add7], axis=0, ignore_index=True) ###æŠŠé¢å¤–çš„7ä¸ªtopicä¹‹å†…çš„ä»£ç æ•´åˆè¿›åŸæœ‰çš„æ•°æ®é›†ï¼Œè¿™é‡Œçš„ä»£ç ç»“æ„å’Œtrainä¸€æ ·"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä¸Šé¢çš„train2 ç”¨æ¥ä»£æ›¿trainè·‘featureå’Œfeature_selectionçš„ä»£ç ï¼ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä¸‹é¢çš„ä»£ç å°±æ˜¯åˆ†ç»„ï¼Œä¸€ä¸ªåœ¨GKFé‡Œé¢ï¼Œä¸€ä¸ªåœ¨GKFå¤–é¢ï¼Œæ”¾åœ¨baselineä»£ç çš„GKFå°±å¯ä»¥äº†ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = train_feats[feature_names].astype(np.float32).values \n",
    "\n",
    "X = train_2 # ### åœ¨è¿™é‡Œçš„æ—¶å€™ä½¿ç”¨train_2è·‘feature_selectionä¹‹åçš„pickelæ–‡ä»¶\n",
    "y_split = train_2['score'].astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "###GKFä»£ç , åªåŠ å…¥äº†ä¸€ä¸‡äºŒçš„topic=7çš„é¢å¤–æ•°æ®é›†\n",
    "###è¿™ä¸ªä»£ç å¯ä»¥ä¸ä¸‹é¢çš„è¿›è¡Œæ•´åˆ\n",
    "### å†™åœ¨è¿™é‡Œæ˜¯ä¸ºäº†è®©ä½ å‚è€ƒå®ƒå†™SKFçš„ä»£ç çš„ï¼Œ\n",
    "### æ‰€ä»¥æˆ‘æ³¨é‡Šæ‰äº†\n",
    "# from sklearn.model_selection import GroupKFold\n",
    "# LOAD = True \n",
    "\n",
    "# n_splits = 7 ## å¦‚æœå˜æ›´ä¸ºå¤§æ•°æ®é›†ï¼Œè¿™ä¸ª_splitè¦æ›´æ”¹\n",
    "# models = []\n",
    "\n",
    "\n",
    "# if not LOAD:\n",
    "#     for i in range(n_splits):\n",
    "#         models.append(lgb.Booster(model_file=f'kaggle/input/aes-lgbm/fold_{i+1}.txt'))\n",
    "# else:\n",
    "#     group_kfold = GroupKFold(n_splits=n_splits)\n",
    "#     f1_scores = []\n",
    "#     kappa_scores = []\n",
    "#     models = []\n",
    "#     predictions = []\n",
    " \n",
    "#     for i, (train_index, test_index) in enumerate(group_kfold.split(X, y_split, groups)):\n",
    "#         X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
    "#         y_train_fold, y_test_fold, y_test_fold_int = y_split[train_index], y_split[test_index], y_split[test_index]\n",
    "#         # å¯ä»¥é€šè¿‡è¿™ä¸‰è¡Œä»£ç çœ‹ä¸€ä¸‹æ•°æ®ï¼Œç›´æ¥åˆ æ‰å°±å¯ä»¥\n",
    "#         # print(f\"Fold {i}:\")\n",
    "#         # print(f\"  Train: index={train_index}, group={groups[train_index]}\")\n",
    "#         # print(f\"  Test:  index={test_index}, group={groups[test_index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åœ¨forå¾ªç¯é‡ŒåŠ å…¥é¢å¤–çš„è®­ç»ƒæ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = GKF_train ##æ³¨æ„è¿™é‡Œçš„X2è¦æ›´æ”¹ä¸ºGKF_train çš„feature select ä¹‹åçš„æ–‡ä»¶\n",
    "#X_2 = train_feats[feature_names].astype(np.float32).values \n",
    "y_split_2 = GKF_train['score'].astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=7, shuffle=True, random_state=0)\n",
    "train_index_2 = []\n",
    "i=1\n",
    "for train_index, test_index in skf.split(X_2,y_split_2):\n",
    "    train_index_2.append(train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "LOAD = True \n",
    "\n",
    "n_splits = 7 ## å¦‚æœå˜æ›´ä¸ºå¤§æ•°æ®é›†ï¼Œè¿™ä¸ª_splitè¦æ›´æ”¹\n",
    "models = []\n",
    "\n",
    "\n",
    "if not LOAD:\n",
    "    for i in range(n_splits):\n",
    "        models.append(lgb.Booster(model_file=f'kaggle/input/aes-lgbm/fold_{i+1}.txt'))\n",
    "else:\n",
    "    group_kfold = GroupKFold(n_splits=n_splits)\n",
    "    f1_scores = []\n",
    "    kappa_scores = []\n",
    "    models = []\n",
    "    predictions = []\n",
    " \n",
    "    for i, (train_index, test_index) in enumerate(group_kfold.split(X, y_split, groups)):\n",
    "        ### X, y_splitæ˜¯å·²ç»åŠ å…¥é¢å¤–æ•°æ®é›†çš„ä»£ç \n",
    "        ###ä½ åšSKFä¹Ÿåªè¦ä¹‹å‰ä¿®æ”¹æ•°æ®é›†å°±å®Œäº‹äº†\n",
    "        X_train_fold_1, X_test_fold = X[train_index], X[test_index]\n",
    "        X_train_fold_2 = X_2[train_index_2[i]]\n",
    "        X_train_fold = y_train_fold = np.hstack((X_train_fold_1, X_train_fold_2))\n",
    "        ## é“¾æ¥2ä¸ªè®­ç»ƒé›†\n",
    "\n",
    "        y_train_fold_1, y_test_fold, y_test_fold_int = y_split[train_index], y_split[test_index], y_split[test_index]\n",
    "        y_train_fold_2 = y_split_2[train_index_2[i]]\n",
    "        y_train_fold = np.hstack((y_train_fold_1, y_train_fold_2))\n",
    "        # å¯ä»¥é€šè¿‡è¿™ä¸‰è¡Œä»£ç çœ‹ä¸€ä¸‹æ•°æ®ï¼Œç›´æ¥åˆ æ‰å°±å¯ä»¥\n",
    "        # print(f\"Fold {i}:\")\n",
    "        # print(f\"  Train: index={train_index}, group={groups[train_index]}\")\n",
    "        # print(f\"  Test:  index={test_index}, group={groups[test_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»Ÿè®¡å•è¯æ•°é‡\n",
    "train_df['word_count_pure'] = train_df['full_text'].apply(lambda x: len(x.split()))\n",
    "persuade['word_count_pure'] = train_df['full_text'].apply(lambda x: len(x.split()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

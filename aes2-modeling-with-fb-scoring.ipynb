{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47020488",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T15:11:16.175683Z",
     "iopub.status.busy": "2024-06-02T15:11:16.174956Z",
     "iopub.status.idle": "2024-06-02T15:15:57.474652Z",
     "shell.execute_reply": "2024-06-02T15:15:57.473532Z"
    },
    "papermill": {
     "duration": 281.312397,
     "end_time": "2024-06-02T15:15:57.477292",
     "exception": false,
     "start_time": "2024-06-02T15:11:16.164895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_AVAILABLE = True\n"
     ]
    }
   ],
   "source": [
    "import aes2_added_fb_prize_as_features_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5578158",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T15:15:57.495608Z",
     "iopub.status.busy": "2024-06-02T15:15:57.495258Z",
     "iopub.status.idle": "2024-06-02T15:15:57.995366Z",
     "shell.execute_reply": "2024-06-02T15:15:57.994322Z"
    },
    "papermill": {
     "duration": 0.511276,
     "end_time": "2024-06-02T15:15:57.997389",
     "exception": false,
     "start_time": "2024-06-02T15:15:57.486113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44a43378",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-02T15:15:58.015237Z",
     "iopub.status.busy": "2024-06-02T15:15:58.014950Z",
     "iopub.status.idle": "2024-06-02T15:16:37.948279Z",
     "shell.execute_reply": "2024-06-02T15:16:37.947451Z"
    },
    "papermill": {
     "duration": 39.944833,
     "end_time": "2024-06-02T15:16:37.950628",
     "exception": false,
     "start_time": "2024-06-02T15:15:58.005795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"/home/mcq/GitHub/aes2/train_data/train_feats.pickle\", \"rb\") as f:\n",
    "    train_feats = pickle.load(f)\n",
    "with open(\"/home/mcq/GitHub/aes2/train_data/X.pickle\", \"rb\") as f:\n",
    "    X = pickle.load(f)\n",
    "with open(\"/home/mcq/GitHub/aes2/train_data/y.pickle\", \"rb\") as f:\n",
    "    y = pickle.load(f)\n",
    "with open(\"/home/mcq/GitHub/aes2/train_data/y_split.pickle\", \"rb\") as f:\n",
    "    y_split = pickle.load(f)\n",
    "with open(\n",
    "    \"/home/mcq/GitHub/aes2/train_data/feature_select.pickle\", \"rb\"\n",
    ") as f:\n",
    "    feature_select = pickle.load(f)\n",
    "    \n",
    "aes2_added_fb_prize_as_features_preprocessing.feature_select = feature_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c42bf6cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T15:16:37.969708Z",
     "iopub.status.busy": "2024-06-02T15:16:37.969002Z",
     "iopub.status.idle": "2024-06-02T15:16:37.995930Z",
     "shell.execute_reply": "2024-06-02T15:16:37.995034Z"
    },
    "papermill": {
     "duration": 0.03848,
     "end_time": "2024-06-02T15:16:37.997882",
     "exception": false,
     "start_time": "2024-06-02T15:16:37.959402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "      <th>argument_0</th>\n",
       "      <th>argument_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.838330</td>\n",
       "      <td>2.648617</td>\n",
       "      <td>3.225708</td>\n",
       "      <td>2.852826</td>\n",
       "      <td>2.682580</td>\n",
       "      <td>2.372594</td>\n",
       "      <td>0.184659</td>\n",
       "      <td>0.815341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.301917</td>\n",
       "      <td>3.215416</td>\n",
       "      <td>3.436492</td>\n",
       "      <td>3.428899</td>\n",
       "      <td>3.493132</td>\n",
       "      <td>2.969440</td>\n",
       "      <td>0.869833</td>\n",
       "      <td>0.130167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.223053</td>\n",
       "      <td>4.069751</td>\n",
       "      <td>4.395761</td>\n",
       "      <td>4.302904</td>\n",
       "      <td>4.315377</td>\n",
       "      <td>4.023932</td>\n",
       "      <td>0.124480</td>\n",
       "      <td>0.875520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.695875</td>\n",
       "      <td>3.485972</td>\n",
       "      <td>4.000536</td>\n",
       "      <td>3.655286</td>\n",
       "      <td>3.484632</td>\n",
       "      <td>3.629644</td>\n",
       "      <td>0.675310</td>\n",
       "      <td>0.324689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.449726</td>\n",
       "      <td>3.228402</td>\n",
       "      <td>3.503447</td>\n",
       "      <td>3.219933</td>\n",
       "      <td>3.524052</td>\n",
       "      <td>3.082691</td>\n",
       "      <td>0.935159</td>\n",
       "      <td>0.064841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cohesion    syntax  vocabulary  phraseology   grammar  conventions  \\\n",
       "0  2.838330  2.648617    3.225708     2.852826  2.682580     2.372594   \n",
       "1  3.301917  3.215416    3.436492     3.428899  3.493132     2.969440   \n",
       "2  4.223053  4.069751    4.395761     4.302904  4.315377     4.023932   \n",
       "3  3.695875  3.485972    4.000536     3.655286  3.484632     3.629644   \n",
       "4  3.449726  3.228402    3.503447     3.219933  3.524052     3.082691   \n",
       "\n",
       "   argument_0  argument_1  \n",
       "0    0.184659    0.815341  \n",
       "1    0.869833    0.130167  \n",
       "2    0.124480    0.875520  \n",
       "3    0.675310    0.324689  \n",
       "4    0.935159    0.064841  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats.iloc[:5, -8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6222a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17307, 13000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31f9552a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T15:16:38.016501Z",
     "iopub.status.busy": "2024-06-02T15:16:38.015806Z",
     "iopub.status.idle": "2024-06-02T15:16:39.220138Z",
     "shell.execute_reply": "2024-06-02T15:16:39.219348Z"
    },
    "papermill": {
     "duration": 1.216012,
     "end_time": "2024-06-02T15:16:39.222452",
     "exception": false,
     "start_time": "2024-06-02T15:16:38.006440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def clean_feature_names(features):\n",
    "    illegal_chars = ['[', ']', '<', '>']\n",
    "    cleaned_features = []\n",
    "    for feature in features:\n",
    "        for char in illegal_chars:\n",
    "            feature = feature.replace(char, 'lessthan')\n",
    "        cleaned_features.append(feature)\n",
    "    return cleaned_features\n",
    "\n",
    "train_feats.columns = clean_feature_names(train_feats.columns)\n",
    "feature_select = clean_feature_names(feature_select)\n",
    "X = train_feats[feature_select].astype(np.float32).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cbf452",
   "metadata": {},
   "source": [
    "# Find Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e19e2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_thresholds(true, pred, steps=50):\n",
    "\n",
    "    # SAVE TRIALS FOR PLOTTING\n",
    "    xs = [[],[],[],[],[]]\n",
    "    ys = [[],[],[],[],[]]\n",
    "\n",
    "    # COMPUTE BASELINE METRIC\n",
    "    threshold = [1.5, 2.5, 3.5, 4.5, 5.5]\n",
    "    pred2 = pd.cut(pred, [-np.inf] + threshold + [np.inf], \n",
    "                    labels=[1,2,3,4,5,6]).astype('int32')\n",
    "    best = cohen_kappa_score(true, pred2, weights=\"quadratic\")\n",
    "\n",
    "    # FIND FIVE OPTIMAL THRESHOLDS\n",
    "    for k in range(5):\n",
    "        for sign in [1,-1]:\n",
    "            v = threshold[k]\n",
    "            threshold2 = threshold.copy()\n",
    "            stop = 0\n",
    "            while stop<steps:\n",
    "\n",
    "                # TRY NEW THRESHOLD\n",
    "                v += sign * 0.01\n",
    "                threshold2[k] = v\n",
    "                pred2 = pd.cut(pred, [-np.inf] + threshold2 + [np.inf], \n",
    "                                labels=[1,2,3,4,5,6]).astype('int32')\n",
    "                metric = cohen_kappa_score(true, pred2, weights=\"quadratic\")\n",
    "\n",
    "                # SAVE TRIALS FOR PLOTTING\n",
    "                xs[k].append(v)\n",
    "                ys[k].append(metric)\n",
    "\n",
    "                # EARLY STOPPING\n",
    "                if metric<=best:\n",
    "                    stop += 1\n",
    "                else:\n",
    "                    stop = 0\n",
    "                    best = metric\n",
    "                    threshold = threshold2.copy()\n",
    "\n",
    "    # COMPUTE FINAL METRIC\n",
    "    pred2 = pd.cut(pred, [-np.inf] + threshold + [np.inf], \n",
    "                    labels=[1,2,3,4,5,6]).astype('int32')\n",
    "    best = cohen_kappa_score(true, pred2, weights=\"quadratic\")   \n",
    "\n",
    "    # RETURN RESULTS\n",
    "    threshold = [np.round(t,3) for t in threshold]\n",
    "    return best, threshold, xs, ys\n",
    "\n",
    "# best, thresholds, xs, ys = find_thresholds(y_split, oof, steps=500)\n",
    "# print('Best thresholds are:', thresholds )\n",
    "# print('=> achieve Overall CV QWK score =', best )\n",
    "\n",
    "# >> Output: thresholds = [1.5, 2.6, 3.5, 4.59, 5.55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46e4afb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T15:16:39.241641Z",
     "iopub.status.busy": "2024-06-02T15:16:39.240836Z",
     "iopub.status.idle": "2024-06-02T15:51:16.585126Z",
     "shell.execute_reply": "2024-06-02T15:51:16.584218Z"
    },
    "papermill": {
     "duration": 2077.356644,
     "end_time": "2024-06-02T15:51:16.587820",
     "exception": false,
     "start_time": "2024-06-02T15:16:39.231176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score, cohen_kappa_score\n",
    "from aes2_added_fb_prize_as_features_preprocessing import *\n",
    "\n",
    "models = []\n",
    "predictions = []\n",
    "f1_scores = []\n",
    "kappa_scores = []\n",
    "\n",
    "tuner_params = {\n",
    "    \"gpu_id\" : 5,\n",
    "    \"learning_rate_lgb\": 0.05,\n",
    "    \"max_depth_lgb\": 8,\n",
    "    \"num_leaves_lgb\": 10,\n",
    "    \"colsample_bytree_lgb\": 0.3,\n",
    "    \"reg_alpha_lgb\": 0.7,\n",
    "    \"reg_lambda_lgb\": 0.01,\n",
    "    \"n_estimators_lgb\": 700,\n",
    "    \"learning_rate_xgb\": 0.1,\n",
    "    \"max_depth_xgb\": 8,\n",
    "    \"num_leaves_xgb\": 10,\n",
    "    \"colsample_bytree_xgb\": 0.5,\n",
    "    \"reg_alpha_xgb\": 0.1,\n",
    "    \"reg_lambda_xgb\": 0.8,\n",
    "    \"n_estimators_xgb\": 1024,\n",
    "    \"n_splits\": 15\n",
    "}\n",
    "\n",
    "n_splits = tuner_params['n_splits']\n",
    "oof = np.zeros(len(train), dtype='float32')\n",
    "\n",
    "class Predictor:\n",
    "    def __init__(self, models: list):\n",
    "        self.models = models\n",
    "#         self.xgb_boost_best_iter = models[1].\n",
    "    def predict(self, X):\n",
    "        n_models = len(self.models)\n",
    "        predicted = None\n",
    "        n = 0.749\n",
    "        for i, model in enumerate(self.models):\n",
    "            if i == 0:\n",
    "                predicted = n*model.predict(X)\n",
    "            else:\n",
    "                # if not isinstance(X, xgb.DMatrix):\n",
    "                #     X = xgb.DMatrix(X)\n",
    "                predicted += (1-n)*model.predict(X)\n",
    "        return predicted\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "xgboost_best_iters = []\n",
    "light_best_iters = []\n",
    "thresholds = [1.5, 2.5, 3.5, 4.5, 5.5] # init threshold\n",
    "\n",
    "\n",
    "LOAD = True # re-train\n",
    "if not LOAD:\n",
    "    for i in range(n_splits):\n",
    "        random_indices = np.random.choice(X.shape[0], size=5000, replace=False)\n",
    "        random_test_X = X[random_indices, :]\n",
    "        random_test_y = y_split[random_indices]\n",
    "        lgb_predictor = lgb.Booster(model_file=f'kaggle/input/3models/aes-lgbm/fold_{i+1}.txt')\n",
    "        # cat_model = CatBoostRegressor()\n",
    "        # cat_model.load_model(f'kaggle/input/aes-catboost/fold_{i+1}.cbm')\n",
    "        xgb_regressor = xgb.Booster()\n",
    "        xgb_regressor.load_model(f'kaggle/input/3models/aes-xgboost/fold_{i+1}.bin')\n",
    "\n",
    "        predictor = Predictor([lgb_predictor, xgb_regressor])\n",
    "        \n",
    "        models.append(predictor)\n",
    "        \n",
    "        # # Make predictions on the test data for this fold\n",
    "        #         # Make predictions on the test data for this fold\n",
    "        predictions_fold = predictor.predict(random_test_X)\n",
    "        predictions_fold = predictions_fold + a\n",
    "        predictions_fold = predictions_fold.clip(1, 6).round().astype(int)\n",
    "        \n",
    "        # # Confusion Matrix for each fold\n",
    "        # cm = confusion_matrix(random_test_y, predictions_fold, labels=[x for x in range(1,7)])\n",
    "        # disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "        #                               display_labels=[x for x in range(1,7)])\n",
    "        # disp.plot()\n",
    "        # plt.show()\n",
    "        \n",
    "        # # Calculate and store the F1 score for this fold\n",
    "        f1_fold = f1_score(random_test_y, predictions_fold, average='weighted')\n",
    "        f1_scores.append(f1_fold)\n",
    "\n",
    "        # Calculate and store the Cohen's kappa score for this fold\n",
    "        kappa_fold = cohen_kappa_score(random_test_y, predictions_fold, weights='quadratic')\n",
    "        kappa_scores.append(kappa_fold)\n",
    "\n",
    "        print(f'F1 score across fold: {f1_fold}')\n",
    "        print(f'Cohen kappa score across fold: {kappa_fold}')\n",
    "        gc.collect()\n",
    "else:\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X, y_split), 1):\n",
    "    # Split the data into training and testing sets for this fold\n",
    "        print('fold',i)\n",
    "        X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
    "        y_train_fold, y_test_fold, y_test_fold_int = y[train_index], y[test_index], y_split[test_index]\n",
    "        callbacks = [log_evaluation(period=25), early_stopping(stopping_rounds=75,first_metric_only=True)]\n",
    "        light = lgb.LGBMRegressor(\n",
    "                objective = qwk_obj,\n",
    "                metrics = 'None',\n",
    "                learning_rate = tuner_params[\"learning_rate_lgb\"],\n",
    "                max_depth = tuner_params[\"max_depth_lgb\"],\n",
    "                num_leaves = tuner_params[\"num_leaves_lgb\"],\n",
    "                colsample_bytree = tuner_params[\"colsample_bytree_lgb\"],\n",
    "                reg_alpha = tuner_params[\"reg_alpha_lgb\"],\n",
    "                reg_lambda = tuner_params[\"reg_lambda_lgb\"],\n",
    "                n_estimators = tuner_params[\"n_estimators_lgb\"],\n",
    "                random_state=42,\n",
    "                extra_trees=True,\n",
    "                class_weight='balanced',\n",
    "                # device='gpu' if CUDA_AVAILABLE else 'cpu',\n",
    "                # device_type=\"gpu\",\n",
    "                verbosity = - 1\n",
    "            )\n",
    "\n",
    "        # Fit the model on the training data for this fold  \n",
    "        light.fit(\n",
    "            X_train_fold,\n",
    "            y_train_fold,\n",
    "            eval_names=['train', 'valid'],\n",
    "            eval_set=[(X_train_fold, y_train_fold), (X_test_fold, y_test_fold)],\n",
    "            eval_metric=quadratic_weighted_kappa,\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "        light_best_iters.append(light.best_iteration_)\n",
    "        \n",
    "        \n",
    "        light.booster_.save_model(f'kaggle/out/aes-lgbm/fold_{i}.txt')\n",
    "        print('\\nFold_{} LightGBM Model saved.\\n'.format(i))\n",
    "        \n",
    "        \n",
    "        xgb_callbacks = [\n",
    "            xgb.callback.EvaluationMonitor(period=25),\n",
    "            xgb.callback.EarlyStopping(75, metric_name=\"QWK\", maximize=True, save_best=True)\n",
    "        ]\n",
    "        xgb_regressor = xgb.XGBRegressor(\n",
    "            objective = qwk_obj,\n",
    "            metrics = 'None',\n",
    "            learning_rate = tuner_params[\"learning_rate_xgb\"],\n",
    "            max_depth = tuner_params[\"max_depth_xgb\"],\n",
    "            num_leaves = tuner_params[\"num_leaves_xgb\"],\n",
    "            colsample_bytree = tuner_params[\"colsample_bytree_xgb\"],\n",
    "            reg_alpha = tuner_params[\"reg_alpha_xgb\"],\n",
    "            reg_lambda = tuner_params[\"reg_lambda_xgb\"],\n",
    "            n_estimators = tuner_params[\"n_estimators_xgb\"],\n",
    "            random_state=42,\n",
    "            extra_trees=True,\n",
    "            class_weight='balanced',\n",
    "            tree_method=\"hist\",\n",
    "            # device=\"gpu\" if CUDA_AVAILABLE else \"cpu\",\n",
    "            gpu_id = tuner_params[\"gpu_id\"]\n",
    "        #             device='gpu',\n",
    "        #             verbosity = 1\n",
    "        )\n",
    "        \n",
    "        xgb_callbacks = [\n",
    "            xgb.callback.EvaluationMonitor(period=25),\n",
    "            xgb.callback.EarlyStopping(75, metric_name=\"QWK\", maximize=True, save_best=True)\n",
    "        ]\n",
    "        xgb_regressor.fit(\n",
    "            X_train_fold,\n",
    "            y_train_fold,\n",
    "            eval_set=[(X_train_fold, y_train_fold), (X_test_fold, y_test_fold)],\n",
    "            eval_metric=quadratic_weighted_kappa,\n",
    "            callbacks=xgb_callbacks\n",
    "        )\n",
    "        xgboost_best_iters.append(xgb_regressor.get_booster().best_iteration)\n",
    "        \n",
    "        xgb_regressor.save_model(f'kaggle/out/aes-xgboost/fold_{i}.bin')\n",
    "        print('\\nFold_{} XGBoost Model saved.\\n'.format(i)) \n",
    "        \n",
    "        predictor = Predictor([light, xgb_regressor])\n",
    "        \n",
    "        models.append(predictor)\n",
    "        # Make predictions on the test data for this fold\n",
    "        predictions_fold = predictor.predict(X_test_fold)\n",
    "        predictions_fold = predictions_fold + a\n",
    "        \n",
    "        \n",
    "        predictions_fold = pd.cut(\n",
    "            predictions_fold, [-np.inf] + thresholds + [np.inf], \n",
    "            labels=[1,2,3,4,5,6]\n",
    "            ).astype('int32')\n",
    "        oof[test_index] = predictions_fold\n",
    "        \n",
    "        predictions_fold = predictions_fold.clip(1, 6).round()\n",
    "        predictions.append(predictions_fold)\n",
    "        # Calculate and store the F1 score for this fold\n",
    "        f1_fold = f1_score(y_test_fold_int, predictions_fold, average='weighted')\n",
    "        f1_scores.append(f1_fold)\n",
    "\n",
    "        # Calculate and store the Cohen's kappa score for this fold\n",
    "        kappa_fold = cohen_kappa_score(y_test_fold_int, predictions_fold, weights='quadratic')\n",
    "        kappa_scores.append(kappa_fold)\n",
    "    #         predictor.booster_.save_model(f'fold_{i}.txt')\n",
    "        cm = confusion_matrix(y_test_fold_int, predictions_fold, labels=[x for x in range(1,7)])\n",
    "\n",
    "        disp = ConfusionMatrixDisplay(\n",
    "            confusion_matrix=cm,\n",
    "            display_labels=[x for x in range(1,7)]\n",
    "        )\n",
    "        disp.plot()\n",
    "        plt.show()\n",
    "        print(f'F1 score across fold: {f1_fold}')\n",
    "        print(f'Cohen kappa score across fold: {kappa_fold}')\n",
    "\n",
    "        gc.collect()\n",
    "        #if ENABLE_DONT_WASTE_YOUR_RUN_TIME:\n",
    "        #    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "624e8822",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T15:51:17.312550Z",
     "iopub.status.busy": "2024-06-02T15:51:17.312008Z",
     "iopub.status.idle": "2024-06-02T15:51:17.319001Z",
     "shell.execute_reply": "2024-06-02T15:51:17.317979Z"
    },
    "papermill": {
     "duration": 0.189866,
     "end_time": "2024-06-02T15:51:17.320888",
     "exception": false,
     "start_time": "2024-06-02T15:51:17.131022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 score across 15 folds: 0.6728648365558038\n",
      "Mean Cohen kappa score across 15 folds: 0.8341763402592286\n"
     ]
    }
   ],
   "source": [
    "mean_f1_score = np.mean(f1_scores)\n",
    "mean_kappa_score = np.mean(kappa_scores)\n",
    "# Print the mean scores\n",
    "print(f'Mean F1 score across {n_splits} folds: {mean_f1_score}')\n",
    "print(f'Mean Cohen kappa score across {n_splits} folds: {mean_kappa_score}')\n",
    "# print(f\"XGBoost mean best iters: {sum(xgboost_best_iters)/len(xgboost_best_iters)}\")\n",
    "# print(f\"LightBoost mean best iters: {sum(light_best_iters)/len(light_best_iters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76752f37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T15:51:17.683801Z",
     "iopub.status.busy": "2024-06-02T15:51:17.683169Z",
     "iopub.status.idle": "2024-06-02T15:53:37.174280Z",
     "shell.execute_reply": "2024-06-02T15:53:37.173190Z"
    },
    "papermill": {
     "duration": 139.675081,
     "end_time": "2024-06-02T15:53:37.176366",
     "exception": false,
     "start_time": "2024-06-02T15:51:17.501285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizers.__version__: 0.19.1\n",
      "transformers.__version__: 4.41.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea7a180140942708d5a8f1007f5ffd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizers.__version__: 0.19.1\n",
      "transformers.__version__: 4.41.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model: microsoft/deberta-v3-large Score: 0.4569  Scores: [0.4881251563991662, 0.45350791183634237, 0.4167653497073674, 0.4555629168241569, 0.47309887903749326, 0.4544346186864903]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    000d118\n",
      "Name: text_id, dtype: object\n",
      "0    000d118\n",
      "Name: text_id, dtype: object\n",
      "CustomModel(\n",
      "  (model): DebertaV2Model(\n",
      "    (embeddings): DebertaV2Embeddings(\n",
      "      (word_embeddings): Embedding(128100, 1024, padding_idx=0)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "      (dropout): StableDropout()\n",
      "    )\n",
      "    (encoder): DebertaV2Encoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-23): 24 x DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rel_embeddings): Embedding(512, 1024)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (pool): MeanPooling()\n",
      "  (fc): Linear(in_features=1024, out_features=6, bias=True)\n",
      ")\n",
      "/home/mcq/GitHub/aes2/kaggle/input/fb3models/0927-deberta-v3-large-unscale/microsoft-deberta-v3-large_fold0_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b5d0fc7f7949a19d073645063dc14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "    reader_close()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n",
      "    reader_close()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n",
      "    reader_close()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n",
      "    self._close()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    self.run()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    self.run()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/threading.py\", line 953, in run\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    000fe60\n",
      "Name: text_id, dtype: object\n",
      "0    000fe60\n",
      "Name: text_id, dtype: object\n",
      "CustomModel(\n",
      "  (model): DebertaV2Model(\n",
      "    (embeddings): DebertaV2Embeddings(\n",
      "      (word_embeddings): Embedding(128100, 1024, padding_idx=0)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "      (dropout): StableDropout()\n",
      "    )\n",
      "    (encoder): DebertaV2Encoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-23): 24 x DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rel_embeddings): Embedding(512, 1024)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (pool): MeanPooling()\n",
      "  (fc): Linear(in_features=1024, out_features=6, bias=True)\n",
      ")\n",
      "/home/mcq/GitHub/aes2/kaggle/input/fb3models/0927-deberta-v3-large-unscale/microsoft-deberta-v3-large_fold0_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8fa07cc4eaf4f7da2d88c028d8a66eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "    reader_close()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n",
      "    reader_close()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n",
      "    reader_close()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n",
      "    self._close()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n",
      "        self._close()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "_close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    self.run()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/threading.py\", line 953, in run\n",
      "    self.run()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/threading.py\", line 953, in run\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    001ab80\n",
      "Name: text_id, dtype: object\n",
      "0    001ab80\n",
      "Name: text_id, dtype: object\n",
      "CustomModel(\n",
      "  (model): DebertaV2Model(\n",
      "    (embeddings): DebertaV2Embeddings(\n",
      "      (word_embeddings): Embedding(128100, 1024, padding_idx=0)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "      (dropout): StableDropout()\n",
      "    )\n",
      "    (encoder): DebertaV2Encoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-23): 24 x DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rel_embeddings): Embedding(512, 1024)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (pool): MeanPooling()\n",
      "  (fc): Linear(in_features=1024, out_features=6, bias=True)\n",
      ")\n",
      "/home/mcq/GitHub/aes2/kaggle/input/fb3models/0927-deberta-v3-large-unscale/microsoft-deberta-v3-large_fold0_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50059ce827db4d70b20224387278e2c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "    reader_close()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    reader_close()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n",
      "    self.run()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._close()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "    self.run()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8df032691042f481eadae5a750b45f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features number:  21913\n",
      "[2. 3. 4.]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id  score\n",
       "0  000d118      2\n",
       "1  000fe60      3\n",
       "2  001ab80      4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# from aes2_added_fb_prize_as_features_preprocessing import preprocess_test, infer\n",
    "import aes2_added_fb_prize_as_features_preprocessing\n",
    "\n",
    "test_feats = aes2_added_fb_prize_as_features_preprocessing.preprocess_test()\n",
    "test_feats.columns = clean_feature_names(test_feats.columns)\n",
    "aes2_added_fb_prize_as_features_preprocessing.infer(test_feats, models)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8059942,
     "sourceId": 71485,
     "sourceType": "competition"
    },
    {
     "datasetId": 2453564,
     "sourceId": 4155787,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2508107,
     "sourceId": 4256323,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4813598,
     "sourceId": 8141507,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4832208,
     "sourceId": 8166166,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4791897,
     "sourceId": 8339744,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 175940118,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 176861104,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 176989302,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 177525613,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 177724159,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2546.990121,
   "end_time": "2024-06-02T15:53:40.489257",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-02T15:11:13.499136",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0cdeae3c30144b148c576c847f965f7e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d98b00034a2247afb877762c5e01b971",
       "placeholder": "​",
       "style": "IPY_MODEL_b55bbd361f6a4d6ab300cbfdbda2ecd4",
       "value": "Map: 100%"
      }
     },
     "194804008ff54a70b0a97f3db8fdecbd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2786df8b0f0840b5a17f6a974f607b0e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2c4d0a5596a04c2482cde8ded99c1363": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "34cb97d668d54707b602e01f92b66bfd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0cdeae3c30144b148c576c847f965f7e",
        "IPY_MODEL_aeaae7a06c3440cca7fef5beb58b816e",
        "IPY_MODEL_4141ce0201194c7bafe15889cfbd9a4f"
       ],
       "layout": "IPY_MODEL_aa27cd84b72740119a5cd85cf36ebcad"
      }
     },
     "351702fba9b04640928e6389ffaaa193": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "35345b3f7de44103b2e7b1b9124322ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3a65b2c90d2944cdb0491a545b740e9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2c4d0a5596a04c2482cde8ded99c1363",
       "placeholder": "​",
       "style": "IPY_MODEL_351702fba9b04640928e6389ffaaa193",
       "value": " 1/1 [00:01&lt;00:00,  1.16s/it]"
      }
     },
     "4141ce0201194c7bafe15889cfbd9a4f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a34ccd90b88842869298125923204da2",
       "placeholder": "​",
       "style": "IPY_MODEL_8a38608b91ee41aeba3cb53cf4b93a9c",
       "value": " 3/3 [00:00&lt;00:00, 65.17 examples/s]"
      }
     },
     "600e1016d78749fab150b3cba337c6fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8a38608b91ee41aeba3cb53cf4b93a9c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8e3aaf6bc26b4b678804acd1e268bc10": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "94c0adf705c74af8889871d9bb88da55": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a34ccd90b88842869298125923204da2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aa27cd84b72740119a5cd85cf36ebcad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aeaae7a06c3440cca7fef5beb58b816e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f16392a4bedd40589fd4221f8c55f11a",
       "max": 3,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_600e1016d78749fab150b3cba337c6fa",
       "value": 3
      }
     },
     "b55bbd361f6a4d6ab300cbfdbda2ecd4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b672493ce1d7438a99da0c6394d1ca0e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2786df8b0f0840b5a17f6a974f607b0e",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8e3aaf6bc26b4b678804acd1e268bc10",
       "value": 1
      }
     },
     "d98b00034a2247afb877762c5e01b971": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dbf6054374134d768decc541fb5a04a9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fe950becf9374c4d8dce62bc2cf1e745",
        "IPY_MODEL_b672493ce1d7438a99da0c6394d1ca0e",
        "IPY_MODEL_3a65b2c90d2944cdb0491a545b740e9d"
       ],
       "layout": "IPY_MODEL_94c0adf705c74af8889871d9bb88da55"
      }
     },
     "f16392a4bedd40589fd4221f8c55f11a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fe950becf9374c4d8dce62bc2cf1e745": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_194804008ff54a70b0a97f3db8fdecbd",
       "placeholder": "​",
       "style": "IPY_MODEL_35345b3f7de44103b2e7b1b9124322ec",
       "value": "100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

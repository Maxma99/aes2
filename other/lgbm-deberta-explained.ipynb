{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":71485,"databundleVersionId":8059942,"sourceType":"competition"},{"sourceId":8029842,"sourceType":"datasetVersion","datasetId":4732809},{"sourceId":8126207,"sourceType":"datasetVersion","datasetId":4791897},{"sourceId":8141507,"sourceType":"datasetVersion","datasetId":4813598},{"sourceId":8166166,"sourceType":"datasetVersion","datasetId":4832208}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":4553.236763,"end_time":"2024-04-21T19:30:38.939227","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-04-21T18:14:45.702464","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"0138c516ae214858a5ce12c12b045f4e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_175a9cb7c44446adbead564221292d1c","placeholder":"‚Äã","style":"IPY_MODEL_9e072d15478742c9b1ddd66618d8fc03","value":" 3/3 [00:00&lt;00:00, 66.72 examples/s]"}},"16532eea7d9142fabd660f57cc8038ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_98f18a0b0dfe4fca9c06393d83c71eb9","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a7d750951bae41b1ba798336c7541d71","value":3}},"175a9cb7c44446adbead564221292d1c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26b0572a2e6b457880cbd6cbe63aa099":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dd86d2be7d4d4320b145f62516aae3c4","IPY_MODEL_16532eea7d9142fabd660f57cc8038ad","IPY_MODEL_0138c516ae214858a5ce12c12b045f4e"],"layout":"IPY_MODEL_be22073923374e54970ae02fcfe66ffa"}},"46e2ac39056849b39d821917f2f9279d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"88473c39208d4054a4250f950b515b94":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98f18a0b0dfe4fca9c06393d83c71eb9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e072d15478742c9b1ddd66618d8fc03":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7d750951bae41b1ba798336c7541d71":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be22073923374e54970ae02fcfe66ffa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd86d2be7d4d4320b145f62516aae3c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88473c39208d4054a4250f950b515b94","placeholder":"‚Äã","style":"IPY_MODEL_46e2ac39056849b39d821917f2f9279d","value":"Map: 100%"}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# LGBM 15 fold + 5 fold Deberta Explained  üí®\n\n### Introduction:\nWelcome to this Jupyter notebook developed for The Learning Agency Lab - Automated Essay Scoring 2.0 . This notebook is designed to help you participate in the competition and to Develop automated techniques to improve upon essay scoring algorithms to improve student learning outcomes.\n\n\n\n### Inspiration and Credits üôå\nThis notebook is inspired by the work of SiddhVR, available at [this Kaggle project](https://www.kaggle.com/code/siddhvr/aes-2-0-deberta-lgbm-baseline). I extend my gratitude to SiddhVR for sharing their insights and code publicly.\n\n\n**Model Components:**\n\n1. **Light Gradient Boosting Machine (LGBM):** LGBM is a powerful gradient boosting framework that efficiently handles large datasets and provides high accuracy. It is employed as the primary machine learning algorithm in our model for essay scoring.\n\n2. **Deberta Transformer Embeddings:** Deberta is a state-of-the-art transformer-based language model. We utilize Deberta embeddings to capture rich semantic information from essays, enhancing the model's understanding of the text.\n\n3. **TF-IDF Vectorization:** Term Frequency-Inverse Document Frequency (TF-IDF) vectorization is utilized to convert text into numerical representations while considering the importance of words in essays. It helps in capturing the significance of words and phrases in the scoring process.\n\n4. **CountVectorizer:** CountVectorizer is used to convert text into a matrix of token counts. It enables us to extract features based on word frequencies, which contribute to the overall scoring mechanism.\n\n5. **Ensemble Learning:** Our model employs ensemble learning techniques, combining predictions from multiple models to improve the overall accuracy and robustness of the scoring process.\n\n**üåü Explore my profile and other public projects, and don't forget to share your feedback!**\n\n## üëâ [Visit my Profile]( https://www.kaggle.com/code/zulqarnainalipk) üëà\n\n\n**Working of the Model:**\n\n1. **Data Preprocessing:** The essay text undergoes preprocessing steps, including lowercasing, HTML tag removal, punctuation removal, spelling error detection, and contraction expansion.\n\n2. **Feature Engineering:** Features are extracted from the preprocessed text, including paragraph length, sentence count, word count, and other linguistic features.\n\n3. **Model Training:** The preprocessed features are fed into the LGBM model along with Deberta embeddings, TF-IDF vectors, and CountVectorizer representations. The model is trained using a combination of these features to learn the scoring patterns.\n\n4. **Cross-Validation:** The model undergoes cross-validation using stratified k-fold technique to ensure robustness and reliability in scoring.\n\n5. **Ensemble Prediction:** Predictions from multiple models trained on different folds are averaged to obtain the final predicted scores for the essays.\n\n6. **Submission Generation:** The predicted scores are then used to generate a submission file in CSV format, which can be used for evaluation or submission in essay scoring competitions.\n\n\n## Acknowledgments üôè\nI acknowledge The Learning Agency Lab organizers for providing the dataset and the competition platform.\n\nLet's get started! Feel free to reach out if you have any questions or need assistance along the way.\nüëâ [Visit my Profile](https://www.kaggle.com/zulqarnainalipk) üëà\n","metadata":{}},{"cell_type":"code","source":"import gc\nimport torch\nimport copy\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments,DataCollatorWithPadding\nimport nltk\nfrom datasets import Dataset\nfrom glob import glob\nimport numpy as np \nimport pandas as pd\nimport polars as pl\nimport re\nimport random\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom scipy.special import softmax\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier,GradientBoostingClassifier,BaggingClassifier\nfrom sklearn.linear_model import LogisticRegression, Perceptron\nfrom sklearn.svm import LinearSVC\nfrom sklearn.naive_bayes import GaussianNB,MultinomialNB,ComplementNB\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn import tree\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom imblearn.ensemble import BalancedBaggingClassifier\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.datasets import make_classification\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score\nfrom sklearn.metrics import cohen_kappa_score\nfrom lightgbm import log_evaluation, early_stopping\nimport lightgbm as lgb\nnltk.download('wordnet')","metadata":{"execution":{"iopub.execute_input":"2024-04-21T18:14:48.540130Z","iopub.status.busy":"2024-04-21T18:14:48.539756Z","iopub.status.idle":"2024-04-21T18:15:30.878339Z","shell.execute_reply":"2024-04-21T18:15:30.877376Z"},"papermill":{"duration":42.363242,"end_time":"2024-04-21T18:15:30.891095","exception":false,"start_time":"2024-04-21T18:14:48.527853","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n**Explaination**\n\n\n1. `MAX_LENGTH`: Maximum length of the input sequence. Set it to 1024 tokens.\n\n2. `TEST_DATA_PATH`: Path to the test data CSV file. \n\n3. `MODEL_PATH`: Path to the directory containing the trained models.\n\n4. `EVAL_BATCH_SIZE`: Batch size used for evaluation. Set it to 1, meaning each evaluation batch contains a single sample.\n\n","metadata":{}},{"cell_type":"code","source":"MAX_LENGTH = 1024\nTEST_DATA_PATH = \"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv\"\nMODEL_PATH = '/kaggle/input/aes2-400-20240419134941/*/*'\nEVAL_BATCH_SIZE = 1","metadata":{"execution":{"iopub.execute_input":"2024-04-21T18:15:30.914602Z","iopub.status.busy":"2024-04-21T18:15:30.913782Z","iopub.status.idle":"2024-04-21T18:15:30.918267Z","shell.execute_reply":"2024-04-21T18:15:30.917402Z"},"papermill":{"duration":0.018592,"end_time":"2024-04-21T18:15:30.920339","exception":false,"start_time":"2024-04-21T18:15:30.901747","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tokenization and Dataset Preparation","metadata":{}},{"cell_type":"markdown","source":"---\n **Explanation:**\n\n\n- **Model Loading:**\n  - The `glob` function is used  to retrieve the list of **models** available at the specified **MODEL_PATH**.\n\n- **Tokenizer Initialization:**\n  - The **tokenizer** is initialized using `AutoTokenizer.from_pretrained(models[0])`, where `models[0]` represents the first model in the list.\n\n- **Tokenization Function Definition:**\n  -  `tokenize` function is defined, which takes a `sample` as input and tokenizes the \"full_text\" column of the sample using the initialized **tokenizer**. Tokenization is performed with a maximum length of **MAX_LENGTH**, and truncation is applied if the text exceeds this length.\n\n- **Test Data Processing:**\n  - The test data CSV file located at **TEST_DATA_PATH** is read into a pandas DataFrame named **df_test**.\n\n- **Hugging Face Dataset Creation:**\n  - The pandas DataFrame **df_test** is converted into a Hugging Face Dataset named **ds**. The `tokenize` function is applied to tokenize the \"full_text\" column of each sample, and the \"essay_id\" and \"full_text\" columns are removed from the dataset.\n\n- **Training Arguments Initialization:**\n  - The **TrainingArguments** object **args** is initialized, specifying the evaluation batch size (`per_device_eval_batch_size`) and output directory for the Trainer. Here, the output directory is set to \".\", meaning the current directory.\n\n- **Model Evaluation Loop:**\n  - Iterates over each **model** in the **models** list.\n  \n- **Model Loading and Evaluation:**\n  - Loads the current **model** for sequence classification using `AutoModelForSequenceClassification.from_pretrained(model)`.\n  - Initializes a **Trainer** object with the loaded **model**, **args**, a `DataCollatorWithPadding` object initialized with the **tokenizer**, and the **tokenizer** itself.\n  - Uses the **Trainer** to make predictions on the test dataset **ds** and obtains the raw **predictions**.\n  - Applies softmax to the raw predictions along the last axis to obtain **class probabilities**.\n  \n- **Memory Management:**\n  - Deletes the **model** and **Trainer** objects to release memory using `del`.\n  - Clears the GPU memory cache using `torch.cuda.empty_cache()`.\n  - Performs garbage collection using `gc.collect()` to free up memory resources.\n\nWe efficiently evaluates each model on the test dataset, storing the predicted probabilities for further analysis. ","metadata":{}},{"cell_type":"code","source":"models = glob(MODEL_PATH)\ntokenizer = AutoTokenizer.from_pretrained(models[0])\n\ndef tokenize(sample):\n    return tokenizer(sample['full_text'], max_length=MAX_LENGTH, truncation=True)\n\ndf_test = pd.read_csv(TEST_DATA_PATH)\nds = Dataset.from_pandas(df_test).map(tokenize).remove_columns(['essay_id', 'full_text'])\n\nargs = TrainingArguments(\n    \".\", \n    per_device_eval_batch_size=EVAL_BATCH_SIZE, \n    report_to=\"none\"\n)\n\npredictions = []\nfor model in models:\n    model = AutoModelForSequenceClassification.from_pretrained(model)\n    trainer = Trainer(\n        model=model, \n        args=args, \n        data_collator=DataCollatorWithPadding(tokenizer), \n        tokenizer=tokenizer\n    )    \n    preds = trainer.predict(ds).predictions\n    predictions.append(softmax(preds, axis=-1))\n    del model, trainer\n    torch.cuda.empty_cache()\n    gc.collect()","metadata":{"execution":{"iopub.execute_input":"2024-04-21T18:15:30.942413Z","iopub.status.busy":"2024-04-21T18:15:30.942151Z","iopub.status.idle":"2024-04-21T18:16:52.174748Z","shell.execute_reply":"2024-04-21T18:16:52.173933Z"},"papermill":{"duration":81.246172,"end_time":"2024-04-21T18:16:52.177046","exception":false,"start_time":"2024-04-21T18:15:30.930874","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Loading and Evaluation Setup","metadata":{}},{"cell_type":"markdown","source":"---\n\n**Explanation:**\n\n\n- **Score Calculation:**\n  - A variable named **predicted_score** is initialized to 0. This variable will be used to aggregate the predicted scores from all models.\n  \n- **Aggregation Loop:**\n  - Iterates over each **p** in **predictions**, where **predictions** is the list containing the predicted probabilities from all models.\n  \n- **Summation of Predictions:**\n  - Adds each set of predicted probabilities **p** to the **predicted_score** variable.\n  \n- **Normalization:**\n  - Divides the **predicted_score** by the total number of models (**len(predictions)**) to obtain the average predicted score across all models.\n\nWe aggregates the predicted scores from all models by summing them and then normalizing by the total number of models. The resulting **predicted_score** represents the average predicted score across all models. ","metadata":{}},{"cell_type":"code","source":"predicted_score = 0.\nfor p in predictions:\n    predicted_score += p\n    \npredicted_score /= len(predictions)","metadata":{"execution":{"iopub.execute_input":"2024-04-21T18:16:52.200873Z","iopub.status.busy":"2024-04-21T18:16:52.200592Z","iopub.status.idle":"2024-04-21T18:16:52.204851Z","shell.execute_reply":"2024-04-21T18:16:52.204033Z"},"papermill":{"duration":0.018205,"end_time":"2024-04-21T18:16:52.206760","exception":false,"start_time":"2024-04-21T18:16:52.188555","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n**Explanation:**\n\n\n- **Score Assignment:**\n  - Adds a new column named **'score'** to the DataFrame **df_test**.\n  - Assigns the predicted score for each essay by finding the index of the maximum value in the **predicted_score** array along the last axis (-1) using `.argmax(-1)`.\n  - Since scores typically start from 1 in essay scoring tasks, 1 is added to the predicted index to get the actual score.\n  - This assigns the predicted scores to the 'score' column in the DataFrame.\n\n\nWe assigns the predicted scores to the 'score' column in the DataFrame **df_test** based on the highest probability score predicted by the model. ","metadata":{}},{"cell_type":"markdown","source":"## Generating Predictions for Test Data","metadata":{}},{"cell_type":"code","source":"df_test['score'] = predicted_score.argmax(-1) + 1\n","metadata":{"execution":{"iopub.execute_input":"2024-04-21T18:16:52.229873Z","iopub.status.busy":"2024-04-21T18:16:52.229608Z","iopub.status.idle":"2024-04-21T18:16:52.242944Z","shell.execute_reply":"2024-04-21T18:16:52.242109Z"},"papermill":{"duration":0.027118,"end_time":"2024-04-21T18:16:52.244936","exception":false,"start_time":"2024-04-21T18:16:52.217818","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n**Explanation:**\n\n\n- **DataFrame Selection:**\n  - Selects the 'essay_id' and 'score' columns from the DataFrame **df_test** using `df_test[['essay_id', 'score']]`.\n  \n- **CSV Export:**\n  - Writes the selected columns to a CSV file named **'submission1.csv'** using the `.to_csv()` function.\n  - The parameter `index=False` is used to exclude the DataFrame index from being written to the CSV file.\n\nExports the 'essay_id' and 'score' columns from the DataFrame **df_test** to a CSV file named **'submission1.csv'**, which can be used for submission or further analysis. ","metadata":{}},{"cell_type":"code","source":"df_test[['essay_id', 'score']].to_csv('submission1.csv', index=False)","metadata":{"execution":{"iopub.execute_input":"2024-04-21T18:16:52.268632Z","iopub.status.busy":"2024-04-21T18:16:52.268360Z","iopub.status.idle":"2024-04-21T18:16:52.340587Z","shell.execute_reply":"2024-04-21T18:16:52.339650Z"},"papermill":{"duration":0.086363,"end_time":"2024-04-21T18:16:52.342688","exception":false,"start_time":"2024-04-21T18:16:52.256325","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Loading\n\n","metadata":{"papermill":{"duration":0.011029,"end_time":"2024-04-21T18:16:52.365656","exception":false,"start_time":"2024-04-21T18:16:52.354627","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"---\n\n**Explanation:**\n\n\n- **Column Definition:**\n  - Defines a list named **columns** containing a single tuple.\n  - Inside the tuple, there is a Polars expression that splits the values in the \"full_text\" column by the pattern \"\\n\\n\" (double newline) using `.str.split(by=\"\\n\\n\")`. This effectively splits each essay into paragraphs.\n  - The result is aliased as \"paragraph\".\n\n- **File Paths:**\n  - Defines a variable named **PATH** containing the path to the directory where the training and test CSV files are located.\n\n- **Data Loading:**\n  - Loads the training data from the CSV file named \"train.csv\" located in the specified **PATH**.\n  - After loading, the \"full_text\" column is split into paragraphs using the defined **columns**.\n\n- **Test Data Loading:**\n  - Loads the test data from the CSV file named \"test.csv\" located in the specified **PATH**.\n  - Similar to the training data, the \"full_text\" column is split into paragraphs using the defined **columns**.\n\n- **Display:**\n  - Displays the first row of the training data using the `.head(1)` function.\n\nWe prepare the training and test datasets by splitting the \"full_text\" column into paragraphs, which can be useful for further analysis or model training.","metadata":{}},{"cell_type":"code","source":"columns = [  \n    (\n        pl.col(\"full_text\").str.split(by=\"\\n\\n\").alias(\"paragraph\")\n    ),\n]\nPATH = \"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/\"\n\ntrain = pl.read_csv(PATH + \"train.csv\").with_columns(columns)\ntest = pl.read_csv(PATH + \"test.csv\").with_columns(columns)\n\n","metadata":{"execution":{"iopub.execute_input":"2024-04-21T18:16:52.389469Z","iopub.status.busy":"2024-04-21T18:16:52.388925Z","iopub.status.idle":"2024-04-21T18:16:53.132206Z","shell.execute_reply":"2024-04-21T18:16:53.130728Z"},"papermill":{"duration":0.759005,"end_time":"2024-04-21T18:16:53.135881","exception":false,"start_time":"2024-04-21T18:16:52.376876","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Spelling Error Count Function","metadata":{}},{"cell_type":"markdown","source":"---\n\n**Explanation:**\n\n\n- **Spacy Initialization:**\n  - Imports the `spacy` library, which is used for natural language processing tasks.\n  - Loads the English language model \"en_core_web_sm\" using `spacy.load(\"en_core_web_sm\")`. This model is commonly used for basic NLP tasks.\n\n- **English Vocabulary Loading:**\n  - Opens the file located at '/kaggle/input/english-word-hx/words.txt' in read mode.\n  - Reads the contents of the file and stores each word as a lowercase string in a set named **english_vocab** after stripping any leading or trailing whitespace.\n\n- **Spelling Error Counting Function:**\n  - Defines a function named **count_spelling_errors** that takes a **text** input as an argument.\n  \n- **Text Processing:**\n  - Processes the input **text** using the loaded Spacy **nlp** object, which tokenizes and lemmatizes the text.\n  - Lemmatized tokens are generated by extracting the lowercase lemmas of each token in the processed document and storing them in the list **lemmatized_tokens**.\n\n- **Spelling Error Counting:**\n  - Counts the number of spelling errors in the **text** by iterating over each token in **lemmatized_tokens** and checking if it is not present in the **english_vocab** set.\n  - The total count of tokens not present in the English vocabulary is stored in the variable **spelling_errors**.\n\n- **Result Return:**\n  - Returns the **spelling_errors** count as the output of the function.\n\nWe define a function **count_spelling_errors** that calculates the number of spelling errors in a given text based on the tokens that do not exist in the provided English vocabulary set. ","metadata":{}},{"cell_type":"code","source":"import spacy\nimport re\n\nnlp = spacy.load(\"en_core_web_sm\")\nwith open('/kaggle/input/english-word-hx/words.txt', 'r') as file:\n    english_vocab = set(word.strip().lower() for word in file)\ndef count_spelling_errors(text):\n\n    \n    doc = nlp(text)\n    lemmatized_tokens = [token.lemma_.lower() for token in doc]\n\n    spelling_errors = sum(1 for token in lemmatized_tokens if token not in english_vocab)\n\n\n    return spelling_errors\n\n","metadata":{"execution":{"iopub.execute_input":"2024-04-21T18:16:53.177079Z","iopub.status.busy":"2024-04-21T18:16:53.176313Z","iopub.status.idle":"2024-04-21T18:16:55.616570Z","shell.execute_reply":"2024-04-21T18:16:55.615546Z"},"papermill":{"duration":2.464062,"end_time":"2024-04-21T18:16:55.618992","exception":false,"start_time":"2024-04-21T18:16:53.154930","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Contraction Expansion and Text Preprocessing Functions ","metadata":{"papermill":{"duration":0.011373,"end_time":"2024-04-21T18:16:55.642354","exception":false,"start_time":"2024-04-21T18:16:55.630981","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"---\n\n**Explanation:**\n\n\n- **Contractions Expansion:**\n  - A dictionary named **cList** is defined, containing mappings from common contractions to their expanded forms.\n  - A regular expression pattern **c_re** is created using `re.compile()` to match any contraction in the text.\n  - The function **expandContractions** takes a **text** input and uses the regular expression pattern to find contractions and replace them with their expanded forms.\n\n- **HTML Tag Removal:**\n  - The function **removeHTML** removes any HTML tags from the text using a regular expression pattern.\n\n- **Data Preprocessing:**\n  - The function **dataPreprocessing** performs several preprocessing steps on the input **x**:\n    - Converts the text to lowercase using `.lower()`.\n    - Removes HTML tags from the text using the **removeHTML** function.\n    - Removes Twitter handles by substituting any word starting with '@' with an empty string.\n    - Removes apostrophes followed by digits.\n    - Removes any digits from the text.\n    - Removes URLs starting with \"http\" or \"https\".\n    - Replaces multiple consecutive whitespaces with a single whitespace using `re.sub()`.\n    - Removes excessive periods and commas by replacing consecutive occurrences with a single instance.\n    - Strips any leading or trailing whitespaces from the text.\n","metadata":{}},{"cell_type":"code","source":"cList = {\n  \"ain't\": \"am not\",\"aren't\": \"are not\",\"can't\": \"cannot\",\"can't've\": \"cannot have\",\"'cause\": \"because\",  \"could've\": \"could have\",\"couldn't\": \"could not\",\"couldn't've\": \"could not have\",\"didn't\": \"did not\",\"doesn't\": \"does not\",\"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\"hasn't\": \"has not\",\n  \"haven't\": \"have not\",\"he'd\": \"he would\",\"he'd've\": \"he would have\",\"he'll\": \"he will\",\"he'll've\": \"he will have\",\"he's\": \"he is\",\n  \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\"how's\": \"how is\",\"I'd\": \"I would\",\"I'd've\": \"I would have\",\"I'll\": \"I will\",\"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\",\n  \"isn't\": \"is not\",\"it'd\": \"it had\",\"it'd've\": \"it would have\",\"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\",\"let's\": \"let us\",\"ma'am\": \"madam\",\"mayn't\": \"may not\",\n  \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\"mustn't've\": \"must not have\",\"needn't\": \"need not\",\"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n  \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\"she'll\": \"she will\",\"she'll've\": \"she will have\",\"she's\": \"she is\",\n  \"should've\": \"should have\",\"shouldn't\": \"should not\",\"shouldn't've\": \"should not have\",\"so've\": \"so have\",\"so's\": \"so is\",\"that'd\": \"that would\",\"that'd've\": \"that would have\",\"that's\": \"that is\",\"there'd\": \"there had\",\"there'd've\": \"there would have\",\"there's\": \"there is\",\"they'd\": \"they would\",\"they'd've\": \"they would have\",\"they'll\": \"they will\",\"they'll've\": \"they will have\",\"they're\": \"they are\",\"they've\": \"they have\",\"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we had\",\n  \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\"we're\": \"we are\",\"we've\": \"we have\",\n  \"weren't\": \"were not\",\"what'll\": \"what will\",\"what'll've\": \"what will have\",\n  \"what're\": \"what are\",\"what's\": \"what is\",\"what've\": \"what have\",\"when's\": \"when is\",\"when've\": \"when have\",\n  \"where'd\": \"where did\",\"where's\": \"where is\",\"where've\": \"where have\",\"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who's\": \"who is\",\"who've\": \"who have\",\"why's\": \"why is\",\n  \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\"won't've\": \"will not have\",\"would've\": \"would have\",\"wouldn't\": \"would not\",\n  \"wouldn't've\": \"would not have\",\"y'all\": \"you all\",\"y'alls\": \"you alls\",\"y'all'd\": \"you all would\",\n  \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you had\",\"you'd've\": \"you would have\",\"you'll\": \"you you will\",\"you'll've\": \"you you will have\",\"you're\": \"you are\",  \"you've\": \"you have\"\n   }\n\nc_re = re.compile('(%s)' % '|'.join(cList.keys()))\n\ndef expandContractions(text, c_re=c_re):\n    def replace(match):\n        return cList[match.group(0)]\n    return c_re.sub(replace, text)\n\ndef removeHTML(x):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',x)\ndef dataPreprocessing(x):\n    x = x.lower()\n    x = removeHTML(x)\n    x = re.sub(\"@\\w+\", '',x)\n    x = re.sub(\"'\\d+\", '',x)\n    x = re.sub(\"\\d+\", '',x)\n    x = re.sub(\"http\\w+\", '',x)\n    x = re.sub(r\"\\s+\", \" \", x)\n#     x = expandContractions(x)\n    x = re.sub(r\"\\.+\", \".\", x)\n    x = re.sub(r\"\\,+\", \",\", x)\n    x = x.strip()\n    return x","metadata":{"execution":{"iopub.execute_input":"2024-04-21T18:16:55.666427Z","iopub.status.busy":"2024-04-21T18:16:55.666108Z","iopub.status.idle":"2024-04-21T18:16:55.709966Z","shell.execute_reply":"2024-04-21T18:16:55.709134Z"},"papermill":{"duration":0.058184,"end_time":"2024-04-21T18:16:55.711902","exception":false,"start_time":"2024-04-21T18:16:55.653718","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Punctuation Removal Function","metadata":{"papermill":{"duration":0.011249,"end_time":"2024-04-21T18:16:55.734697","exception":false,"start_time":"2024-04-21T18:16:55.723448","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"---\n\n**Explanation:**\n\nFunction **remove_punctuation** is defined to remove punctuation from a given text:\n\n- **Punctuation Removal:**\n  - The function takes a **text** input as an argument.\n  - A translator is created using `str.maketrans('', '', string.punctuation)`, which generates a translation table that maps each character in the string `string.punctuation` to `None`. This effectively removes all punctuation characters.\n  - The translation table is then applied to the input **text** using `text.translate(translator)`, which removes all punctuation characters from the text.\n  - The processed text with removed punctuation is returned as the output of the function.\n\n- **Example Usage:**\n  - An example **text** string \"Hello, world! This is a test.\" is provided.\n  - The **remove_punctuation** function is called with the example **text** as input, and the processed text with removed punctuation is printed.\n\n","metadata":{}},{"cell_type":"code","source":"import string\n\ndef remove_punctuation(text):\n\n    translator = str.maketrans('', '', string.punctuation)\n    return text.translate(translator)\n\ntext = \"Hello, world! This is a test.\"\nprint(remove_punctuation(text))\n","metadata":{"execution":{"iopub.execute_input":"2024-04-21T18:16:55.759228Z","iopub.status.busy":"2024-04-21T18:16:55.758593Z","iopub.status.idle":"2024-04-21T18:16:55.764823Z","shell.execute_reply":"2024-04-21T18:16:55.763906Z"},"papermill":{"duration":0.020731,"end_time":"2024-04-21T18:16:55.766924","exception":false,"start_time":"2024-04-21T18:16:55.746193","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Paragraph Preprocessing","metadata":{}},{"cell_type":"markdown","source":"---\n\n**Explanation:**\n\nWe define twowo functions for paragraph preprocessing and feature engineering:\n\n- **Paragraph Preprocessing:**\n  - The function **Paragraph_Preprocess** takes a DataFrame **tmp** as input.\n  - The DataFrame **tmp** is exploded on the 'paragraph' column, which means that each row containing a list of paragraphs is expanded into multiple rows, each containing a single paragraph.\n  - Text preprocessing operations are applied to each paragraph in the DataFrame:\n    - The **dataPreprocessing** function is applied to clean the text data.\n    - The **remove_punctuation** function is applied to remove punctuation from the text.\n    - The **count_spelling_errors** function is applied to count the number of spelling errors in each paragraph.\n    - The length of each paragraph in terms of characters and sentences is calculated.\n  - The resulting DataFrame **tmp** contains processed paragraph data.\n\n- **Paragraph Feature Engineering:**\n  - The function **Paragraph_Eng** takes a DataFrame **train_tmp** as input.\n  - The DataFrame is grouped by the 'essay_id' column, and various aggregate statistics are computed for the paragraph-level features.\n  - Aggregate statistics include count, maximum, mean, minimum, sum, first, last, kurtosis, and quantiles for features such as paragraph length, sentence count, word count, and spelling error count.\n  - The resulting DataFrame **df** is converted to a pandas DataFrame.\n  - The 'score' column from the original training data is appended to the DataFrame.\n  - The function returns the DataFrame **train_feats**, which contains engineered features at the paragraph level.\n\n- **Feature Names Extraction:**\n  - Extracts the feature names from the DataFrame **train_feats** excluding 'essay_id' and 'score' columns.\n\n- **Output Display:**\n  - Prints the number of features extracted.\n  - Displays the first three rows of the DataFrame **train_feats** containing the engineered features.\n\nThese functions preprocess paragraphs and perform feature engineering to extract relevant features from the text data. ","metadata":{}},{"cell_type":"code","source":"\ndef Paragraph_Preprocess(tmp):\n    tmp = tmp.explode('paragraph')\n    tmp = tmp.with_columns(pl.col('paragraph').map_elements(dataPreprocessing))\n    tmp = tmp.with_columns(pl.col('paragraph').map_elements(remove_punctuation).alias('paragraph_no_pinctuation'))\n    tmp = tmp.with_columns(pl.col('paragraph_no_pinctuation').map_elements(count_spelling_errors).alias(\"paragraph_error_num\"))\n    tmp = tmp.with_columns(pl.col('paragraph').map_elements(lambda x: len(x)).alias(\"paragraph_len\"))\n    tmp = tmp.with_columns(pl.col('paragraph').map_elements(lambda x: len(x.split('.'))).alias(\"paragraph_sentence_cnt\"),\n                    pl.col('paragraph').map_elements(lambda x: len(x.split(' '))).alias(\"paragraph_word_cnt\"),)\n\n    return tmp\n# feature_eng\nparagraph_fea = ['paragraph_len','paragraph_sentence_cnt','paragraph_word_cnt']\nparagraph_fea2 = ['paragraph_error_num'] + paragraph_fea\ndef Paragraph_Eng(train_tmp):\n    num_list = [0, 50,75,100,125,150,175,200,250,300,350,400,500,600]\n    num_list2 = [0, 50,75,100,125,150,175,200,250,300,350,400,500,600,700]\n    aggs = [\n        *[pl.col('paragraph').filter(pl.col('paragraph_len') >= i).count().alias(f\"paragraph_>{i}_cnt\") for i in [0, 50,75,100,125,150,175,200,250,300,350,400,500,600,700] ], \n        *[pl.col('paragraph').filter(pl.col('paragraph_len') <= i).count().alias(f\"paragraph_<{i}_cnt\") for i in [25,49]], \n\n        *[pl.col(fea).max().alias(f\"{fea}_max\") for fea in paragraph_fea2],\n        *[pl.col(fea).mean().alias(f\"{fea}_mean\") for fea in paragraph_fea2],\n        *[pl.col(fea).min().alias(f\"{fea}_min\") for fea in paragraph_fea2],\n        *[pl.col(fea).sum().alias(f\"{fea}_sum\") for fea in paragraph_fea2],\n        *[pl.col(fea).first().alias(f\"{fea}_first\") for fea in paragraph_fea2],\n        *[pl.col(fea).last().alias(f\"{fea}_last\") for fea in paragraph_fea2],\n        *[pl.col(fea).kurtosis().alias(f\"{fea}_kurtosis\") for fea in paragraph_fea2],\n        *[pl.col(fea).quantile(0.25).alias(f\"{fea}_q1\") for fea in paragraph_fea2],  # Ê±ÇÂõõÂàÜ‰πã‰∏ÄÂÄº\n        *[pl.col(fea).quantile(0.75).alias(f\"{fea}_q3\") for fea in paragraph_fea2],  # Ê±ÇÂõõÂàÜ‰πã‰∏âÂÄº\n    \n        ]\n    df = train_tmp.group_by(['essay_id'], maintain_order=True).agg(aggs).sort(\"essay_id\")\n    df = df.to_pandas()\n    return df\ntmp = Paragraph_Preprocess(train)\ntrain_feats = Paragraph_Eng(tmp)\ntrain_feats['score'] = train['score']\n\nfeature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\nprint('Features Number: ',len(feature_names))\n","metadata":{"execution":{"iopub.execute_input":"2024-04-21T18:16:55.791220Z","iopub.status.busy":"2024-04-21T18:16:55.790944Z","iopub.status.idle":"2024-04-21T18:37:19.550600Z","shell.execute_reply":"2024-04-21T18:37:19.549711Z"},"papermill":{"duration":1223.786542,"end_time":"2024-04-21T18:37:19.564908","exception":false,"start_time":"2024-04-21T18:16:55.778366","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sentence Preprocessing","metadata":{"papermill":{"duration":0.011815,"end_time":"2024-04-21T18:37:19.589354","exception":false,"start_time":"2024-04-21T18:37:19.577539","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"---\n\n**Explanation:**\n\nWe defines two additional functions for sentence-level preprocessing and feature engineering:\n\n- **Sentence Preprocessing:**\n  - The function **Sentence_Preprocess** takes a DataFrame **tmp** as input.\n  - The 'full_text' column of the DataFrame is processed to split each essay into sentences using the period ('.') as the delimiter.\n  - The resulting DataFrame **tmp** contains the 'sentence' column with each element representing a sentence.\n  - The 'sentence' column is then exploded to create multiple rows, each containing a single sentence.\n  - The length of each sentence in terms of characters and words is calculated.\n\n- **Sentence Feature Engineering:**\n  - The function **Sentence_Eng** takes a DataFrame **train_tmp** as input.\n  - The DataFrame is grouped by the 'essay_id' column, and various aggregate statistics are computed for the sentence-level features.\n  - Aggregate statistics include count, maximum, mean, minimum, sum, first, last, kurtosis, and quantiles for features such as sentence length and word count.\n  - The resulting DataFrame **df** is converted to a pandas DataFrame.\n  - The sentence-level features are merged with the existing features in the DataFrame **train_feats** based on the 'essay_id' column.\n\n- **Feature Names Extraction:**\n  - Extracts the feature names from the DataFrame **train_feats** excluding 'essay_id' and 'score' columns.\n\n- **Output Display:**\n  - Prints the number of features extracted after merging sentence-level features.\n  \nThese functions preprocess sentences and perform feature engineering to extract relevant features from the text data at the sentence level. ","metadata":{}},{"cell_type":"code","source":"def Sentence_Preprocess(tmp):\n    tmp = tmp.with_columns(pl.col('full_text').map_elements(dataPreprocessing).str.split(by=\".\").alias(\"sentence\"))\n    tmp = tmp.explode('sentence')\n    tmp = tmp.with_columns(pl.col('sentence').map_elements(lambda x: len(x)).alias(\"sentence_len\"))\n\n    tmp = tmp.with_columns(pl.col('sentence').map_elements(lambda x: len(x.split(' '))).alias(\"sentence_word_cnt\"))\n    \n    return tmp\nsentence_fea = ['sentence_len','sentence_word_cnt']\ndef Sentence_Eng(train_tmp):\n    aggs = [\n        *[pl.col('sentence').filter(pl.col('sentence_len') >= i).count().alias(f\"sentence_>{i}_cnt\") for i in [0,15,50,100,150,200,250,300] ], \n        *[pl.col('sentence').filter(pl.col('sentence_len') <= i).count().alias(f\"sentence_<{i}_cnt\") for i in [15,50] ], \n\n        *[pl.col(fea).max().alias(f\"{fea}_max\") for fea in sentence_fea],\n        *[pl.col(fea).mean().alias(f\"{fea}_mean\") for fea in sentence_fea],\n        *[pl.col(fea).min().alias(f\"{fea}_min\") for fea in sentence_fea],\n        *[pl.col(fea).sum().alias(f\"{fea}_sum\") for fea in sentence_fea],\n        *[pl.col(fea).first().alias(f\"{fea}_first\") for fea in sentence_fea],\n        *[pl.col(fea).last().alias(f\"{fea}_last\") for fea in sentence_fea],\n        *[pl.col(fea).kurtosis().alias(f\"{fea}_kurtosis\") for fea in sentence_fea],\n        *[pl.col(fea).quantile(0.25).alias(f\"{fea}_q1\") for fea in sentence_fea],  \n        *[pl.col(fea).quantile(0.75).alias(f\"{fea}_q3\") for fea in sentence_fea],  \n    \n        ]\n    df = train_tmp.group_by(['essay_id'], maintain_order=True).agg(aggs).sort(\"essay_id\")\n    df = df.to_pandas()\n    return df\n\ntmp = Sentence_Preprocess(train)\ntrain_feats = train_feats.merge(Sentence_Eng(tmp), on='essay_id', how='left')\n\nfeature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\nprint('Features Number: ',len(feature_names))\n","metadata":{"execution":{"iopub.execute_input":"2024-04-21T18:37:19.614406Z","iopub.status.busy":"2024-04-21T18:37:19.614104Z","iopub.status.idle":"2024-04-21T18:37:26.445921Z","shell.execute_reply":"2024-04-21T18:37:26.444911Z"},"papermill":{"duration":6.846932,"end_time":"2024-04-21T18:37:26.447978","exception":false,"start_time":"2024-04-21T18:37:19.601046","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Word Preprocessing","metadata":{"papermill":{"duration":0.012742,"end_time":"2024-04-21T18:37:26.473392","exception":false,"start_time":"2024-04-21T18:37:26.460650","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"---\n\n**Explanation:**\n\nWe define two more functions are  for word-level preprocessing and feature engineering:\n\n- **Word Preprocessing:**\n  - The function **Word_Preprocess** takes a DataFrame **tmp** as input.\n  - The 'full_text' column of the DataFrame is processed to split each essay into words using a space (' ') as the delimiter.\n  - The resulting DataFrame **tmp** contains the 'word' column with each element representing a word.\n  - The 'word' column is then exploded to create multiple rows, each containing a single word.\n  - The length of each word in terms of characters is calculated.\n  - Any rows with word lengths equal to 0 are filtered out to remove empty words.\n\n- **Word Feature Engineering:**\n  - The function **Word_Eng** takes a DataFrame **train_tmp** as input.\n  - The DataFrame is grouped by the 'essay_id' column, and various aggregate statistics are computed for the word-level features.\n  - Aggregate statistics include count of words with lengths from 1 to 15, maximum word length, mean word length, standard deviation of word length, and quantiles of word length.\n  - The resulting DataFrame **df** is converted to a pandas DataFrame.\n  - The word-level features are merged with the existing features in the DataFrame **train_feats** based on the 'essay_id' column.\n\n- **Feature Names Extraction:**\n  - Extracts the feature names from the DataFrame **train_feats** excluding 'essay_id' and 'score' columns.\n\n- **Output Display:**\n  - Prints the number of features extracted after merging word-level features.\n  \nThese functions preprocess words and perform feature engineering to extract relevant features from the text data at the word level. ","metadata":{}},{"cell_type":"code","source":"def Word_Preprocess(tmp):\n    tmp = tmp.with_columns(pl.col('full_text').map_elements(dataPreprocessing).str.split(by=\" \").alias(\"word\"))\n    tmp = tmp.explode('word')\n    tmp = tmp.with_columns(pl.col('word').map_elements(lambda x: len(x)).alias(\"word_len\"))\n    tmp = tmp.filter(pl.col('word_len')!=0)\n    \n    return tmp\ndef Word_Eng(train_tmp):\n    aggs = [\n        *[pl.col('word').filter(pl.col('word_len') >= i+1).count().alias(f\"word_{i+1}_cnt\") for i in range(15) ], \n        pl.col('word_len').max().alias(f\"word_len_max\"),\n        pl.col('word_len').mean().alias(f\"word_len_mean\"),\n        pl.col('word_len').std().alias(f\"word_len_std\"),\n        pl.col('word_len').quantile(0.25).alias(f\"word_len_q1\"),\n        pl.col('word_len').quantile(0.50).alias(f\"word_len_q2\"),\n        pl.col('word_len').quantile(0.75).alias(f\"word_len_q3\"),\n        ]\n    df = train_tmp.group_by(['essay_id'], maintain_order=True).agg(aggs).sort(\"essay_id\")\n    df = df.to_pandas()\n    return df\n\ntmp = Word_Preprocess(train)\ntrain_feats = train_feats.merge(Word_Eng(tmp), on='essay_id', how='left')\n\nfeature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\nprint('Features Number: ',len(feature_names))\n","metadata":{"execution":{"iopub.execute_input":"2024-04-21T18:37:26.499075Z","iopub.status.busy":"2024-04-21T18:37:26.498764Z","iopub.status.idle":"2024-04-21T18:37:39.345723Z","shell.execute_reply":"2024-04-21T18:37:39.344776Z"},"papermill":{"duration":12.862153,"end_time":"2024-04-21T18:37:39.347724","exception":false,"start_time":"2024-04-21T18:37:26.485571","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tf-idf Vectorizer Setup and Feature Engineering","metadata":{"papermill":{"duration":0.012539,"end_time":"2024-04-21T18:37:39.373150","exception":false,"start_time":"2024-04-21T18:37:39.360611","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"---\n\n**Explanation:**\n\nA TF-IDF vectorizer is used to convert the essays into numerical features, followed by merging these features with the existing feature set:\n\n- **TF-IDF Vectorization:**\n  - The **TfidfVectorizer** class is initialized with the following parameters:\n    - **tokenizer**: A lambda function is provided to tokenize each document. Since the essays are already preprocessed and tokenized, the identity function lambda x: x is used to maintain the tokens as they are.\n    - **preprocessor**: A lambda function is provided to preprocess each document. Again, the identity function is used here to maintain the documents as they are.\n    - **token_pattern**: None is provided, as tokenization is already done and no specific pattern is needed.\n    - **strip_accents**: 'unicode' is used to remove accents during preprocessing.\n    - **analyzer**: 'word' is specified to analyze words as the basic elements.\n    - **ngram_range**: The range of n-grams considered is set to (3,6), meaning it will consider n-grams of sizes 3 to 6.\n    - **min_df**: The minimum document frequency is set to 0.05, meaning words that occur in less than 5% of the documents will be ignored.\n    - **max_df**: The maximum document frequency is set to 0.95, meaning words that occur in more than 95% of the documents will be ignored.\n    - **sublinear_tf**: True is specified to apply sublinear term frequency scaling, which tends to emphasize the importance of less frequent terms.\n  - The **fit_transform** method is called on the vectorizer with the list comprehension `[i for i in train['full_text']]` to fit the vectorizer to the training data and transform it into a TF-IDF matrix.\n  - The resulting TF-IDF matrix is converted to a dense matrix using the **toarray** method.\n  - A DataFrame **df** is created from the dense matrix, where each column represents a TF-IDF feature.\n  - Column names are assigned as 'tfid_0', 'tfid_1', ..., 'tfid_n' where n is the number of features.\n  - The 'essay_id' column is added to the DataFrame to facilitate merging with other features.\n\n- **Merging Features:**\n  - The TF-IDF features DataFrame **df** is merged with the existing feature DataFrame **train_feats** based on the 'essay_id' column.\n\n- **Feature Names Extraction:**\n  - Extracts the feature names from the DataFrame **train_feats** excluding 'essay_id' and 'score' columns.\n\n- **Output Display:**\n  - Prints the number of features extracted after merging TF-IDF features.\n\nWe add TF-IDF features derived from the essays to the existing feature set. These features capture the importance of words and n-grams in each essay and can be used as input .","metadata":{}},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(\n            tokenizer=lambda x: x,\n            preprocessor=lambda x: x,\n            token_pattern=None,\n            strip_accents='unicode',\n            analyzer = 'word',\n            ngram_range=(3,6),\n            min_df=0.05,\n            max_df=0.95,\n            sublinear_tf=True,\n)\n\ntrain_tfid = vectorizer.fit_transform([i for i in train['full_text']])\ndense_matrix = train_tfid.toarray()\ndf = pd.DataFrame(dense_matrix)\ntfid_columns = [ f'tfid_{i}' for i in range(len(df.columns))]\ndf.columns = tfid_columns\ndf['essay_id'] = train_feats['essay_id']\ntrain_feats = train_feats.merge(df, on='essay_id', how='left')\nfeature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\nprint('Number of Features: ',len(feature_names))\n","metadata":{"execution":{"iopub.execute_input":"2024-04-21T18:37:39.399737Z","iopub.status.busy":"2024-04-21T18:37:39.399459Z","iopub.status.idle":"2024-04-21T18:40:47.082236Z","shell.execute_reply":"2024-04-21T18:40:47.081178Z"},"papermill":{"duration":187.716069,"end_time":"2024-04-21T18:40:47.101684","exception":false,"start_time":"2024-04-21T18:37:39.385615","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CountVectorizer Setup and Feature Engineering","metadata":{"execution":{"iopub.execute_input":"2024-04-15T13:20:02.359567Z","iopub.status.busy":"2024-04-15T13:20:02.359229Z","iopub.status.idle":"2024-04-15T13:20:02.363863Z","shell.execute_reply":"2024-04-15T13:20:02.362844Z","shell.execute_reply.started":"2024-04-15T13:20:02.359539Z"},"papermill":{"duration":0.014496,"end_time":"2024-04-21T18:40:47.174935","exception":false,"start_time":"2024-04-21T18:40:47.160439","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"---\n\n**Explanation:**\n\nA countVectorizer is used to convert the essays into numerical features, followed by merging these features with the existing feature set:\n\n- **CountVectorizer Configuration:**\n  - The **CountVectorizer** class is initialized with similar parameters to the TF-IDF vectorizer:\n    - **tokenizer**: A lambda function is provided to tokenize each document.\n    - **preprocessor**: A lambda function is provided to preprocess each document.\n    - **token_pattern**: None is provided, as tokenization is already done.\n    - **strip_accents**: 'unicode' is used to remove accents during preprocessing.\n    - **analyzer**: 'word' is specified to analyze words as the basic elements.\n    - **ngram_range**: The range of n-grams considered is set to (2,3), meaning it will consider n-grams of sizes 2 to 3.\n    - **min_df**: The minimum document frequency is set to 0.10, meaning words that occur in less than 10% of the documents will be ignored.\n    - **max_df**: The maximum document frequency is set to 0.85, meaning words that occur in more than 85% of the documents will be ignored.\n\n- **Vectorization and Dense Matrix Conversion:**\n  - The **fit_transform** method is called on the CountVectorizer with the list comprehension `[i for i in train['full_text']]` to fit the vectorizer to the training data and transform it into a count matrix.\n  - The resulting count matrix is converted to a dense matrix using the **toarray** method.\n\n- **DataFrame Creation and Column Naming:**\n  - A DataFrame **df** is created from the dense matrix, where each column represents a count feature.\n  - Column names are assigned as 'tfid_cnt_0', 'tfid_cnt_1', ..., 'tfid_cnt_n' where n is the number of features.\n\n- **Merging Features:**\n  - The count features DataFrame **df** is merged with the existing feature DataFrame **train_feats** based on the 'essay_id' column.\n\nWe add count features derived from the essays to the existing feature set. These features represent the frequency of occurrence of specific word n-grams in each essay .","metadata":{}},{"cell_type":"code","source":"vectorizer_cnt = CountVectorizer(\n            tokenizer=lambda x: x,\n            preprocessor=lambda x: x,\n            token_pattern=None,\n            strip_accents='unicode',\n            analyzer = 'word',\n            ngram_range=(2,3),\n            min_df=0.10,\n            max_df=0.85,\n)\ntrain_tfid = vectorizer_cnt.fit_transform([i for i in train['full_text']])\ndense_matrix = train_tfid.toarray()\ndf = pd.DataFrame(dense_matrix)\ntfid_columns = [ f'tfid_cnt_{i}' for i in range(len(df.columns))]\ndf.columns = tfid_columns\ndf['essay_id'] = train_feats['essay_id']\ntrain_feats = train_feats.merge(df, on='essay_id', how='left')","metadata":{"execution":{"iopub.execute_input":"2024-04-21T18:40:47.205187Z","iopub.status.busy":"2024-04-21T18:40:47.204411Z","iopub.status.idle":"2024-04-21T18:42:01.149673Z","shell.execute_reply":"2024-04-21T18:42:01.148811Z"},"papermill":{"duration":73.962799,"end_time":"2024-04-21T18:42:01.152059","exception":false,"start_time":"2024-04-21T18:40:47.189260","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Deberta Embeddings and Model Evaluation Setup","metadata":{"papermill":{"duration":0.012792,"end_time":"2024-04-21T18:42:01.178477","exception":false,"start_time":"2024-04-21T18:42:01.165685","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"---\n\n**Explanation:**\n\nout-of-fold (OOF) predictions from a pre-trained DeBERTa model are loaded and added as features to the existing feature set:\n\n- **Loading DeBERTa Out-of-Fold Predictions:**\n  - The **joblib.load** function is used to load the out-of-fold predictions stored in the file '/kaggle/input/aes2-400-20240419134941/oof.pkl'.\n  - The variable **deberta_oof** now contains the loaded OOF predictions.\n\n- **Adding DeBERTa OOF Predictions as Features:**\n  - A loop iterates over the range of 6, assuming there are 6 different predictions from the DeBERTa model.\n  - For each prediction index **i**, a new column named **f'deberta_oof_{i}'** is added to the DataFrame **train_feats**. The values for these columns are taken from the **deberta_oof** array.\n\n- **Feature Names Extraction:**\n  - After adding DeBERTa OOF predictions as features, the script extracts feature names from the DataFrame **train_feats**, excluding the 'essay_id' and 'score' columns.\n\n- **Output Display:**\n  - Prints the number of features extracted after adding DeBERTa OOF predictions.\n\n- **DataFrame Shape:**\n  - The shape of the DataFrame **train_feats** is printed to display the number of rows and columns after adding the new features.\n\nLoad DeBERTa out-of-fold predictions and adds them as features to the existing feature set. These features represent the predictions made by the DeBERTa model on the training data .","metadata":{}},{"cell_type":"code","source":"import joblib\n\ndeberta_oof = joblib.load('/kaggle/input/aes2-400-20240419134941/oof.pkl')\nprint(deberta_oof.shape, train_feats.shape)\n\nfor i in range(6):\n    train_feats[f'deberta_oof_{i}'] = deberta_oof[:, i]\n\nfeature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\nprint('Features Number: ',len(feature_names))    \n\ntrain_feats.shape","metadata":{"execution":{"iopub.execute_input":"2024-04-21T18:42:01.205837Z","iopub.status.busy":"2024-04-21T18:42:01.205274Z","iopub.status.idle":"2024-04-21T18:42:01.277907Z","shell.execute_reply":"2024-04-21T18:42:01.276967Z"},"papermill":{"duration":0.088353,"end_time":"2024-04-21T18:42:01.279743","exception":false,"start_time":"2024-04-21T18:42:01.191390","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# QWK Metric Definitions and Parameters ","metadata":{}},{"cell_type":"markdown","source":"---\n\n**Explanation:**\n\nWe defines functions related to the Quadratic Weighted Kappa (QWK) metric and an objective function for gradient boosting models:\n\n- **Quadratic Weighted Kappa Function (`quadratic_weighted_kappa`):**\n  - This function calculates the Quadratic Weighted Kappa (QWK) metric between the true labels and predicted labels.\n  - It takes two arguments: `y_true` (true labels) and `y_pred` (predicted labels).\n  - It first adjusts the labels and predictions by adding a constant `a` to both, which helps handle cases where the label or prediction range does not start from 0.\n  - The predictions are clipped between 1 and 6 to ensure they fall within the valid range.\n  - The `cohen_kappa_score` function from scikit-learn is used to compute the QWK score with quadratic weights.\n  - The function returns a tuple ('QWK', qwk, True), where 'QWK' is a string indicating the name of the metric, `qwk` is the computed QWK score, and True indicates that higher values of the metric are better.\n\n- **Objective Function for Gradient Boosting (`qwk_obj`):**\n  - This function defines a custom objective function for gradient boosting models based on the QWK metric.\n  - It takes two arguments: `y_true` (true labels) and `y_pred` (predicted labels).\n  - Similar to the previous function, it adjusts the labels and predictions by adding a constant `a` to both.\n  - Predictions are clipped between 1 and 6.\n  - The function computes the gradient and Hessian of the objective function with respect to the predicted labels.\n  - These gradients and Hessians are used during the training of gradient boosting models to optimize the objective function.\n  - The computed gradients and Hessians are returned as tuples `(grad, hess)`.\n\n- **Constants `a` and `b`:**\n  - Constants `a` and `b` are defined with values 2.998 and 1.092, respectively. These constants are used in both the QWK function and the objective function.\n  - `a` is added to both true labels and predicted labels to handle cases where the label or prediction range does not start from 0.\n  - `b` is used in the objective function calculation.\n\n","metadata":{}},{"cell_type":"code","source":"def quadratic_weighted_kappa(y_true, y_pred):\n    y_true = y_true + a\n    y_pred = (y_pred + a).clip(1, 6).round()\n    qwk = cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n    return 'QWK', qwk, True\ndef qwk_obj(y_true, y_pred):\n    labels = y_true + a\n    preds = y_pred + a\n    preds = preds.clip(1, 6)\n    f = 1/2*np.sum((preds-labels)**2)\n    g = 1/2*np.sum((preds-a)**2+b)\n    df = preds - labels\n    dg = preds - a\n    grad = (df/g - f*dg/g**2)*len(labels)\n    hess = np.ones(len(labels))\n    return grad, hess\na = 2.998\nb = 1.092\n","metadata":{"execution":{"iopub.execute_input":"2024-04-21T18:42:01.307375Z","iopub.status.busy":"2024-04-21T18:42:01.307122Z","iopub.status.idle":"2024-04-21T18:42:01.314334Z","shell.execute_reply":"2024-04-21T18:42:01.313437Z"},"papermill":{"duration":0.023086,"end_time":"2024-04-21T18:42:01.316141","exception":false,"start_time":"2024-04-21T18:42:01.293055","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preparation for Model Training","metadata":{}},{"cell_type":"markdown","source":"---\n\n**Explanation:**\n\nThe feature matrix `X` and the target variables `y_split`, `y`, and `oof` are prepared for training and evaluation:\n\n- **Feature Matrix `X`:**\n  - The feature matrix `X` is extracted from the DataFrame `train_feats`. Only the features are selected for training, and the column names stored in the list `feature_names` are used to index the DataFrame.\n  - The `.astype(np.float32)` method is used to cast the feature values to 32-bit floating-point numbers to reduce memory usage.\n  - The `.values` attribute is used to extract the values from the DataFrame, resulting in a NumPy array.\n\n- **Split Target Variable `y_split`:**\n  - The target variable `y_split` is extracted from the 'score' column of the DataFrame `train_feats`. It is cast to an integer data type using `.astype(int)`.\n  - This variable is used for splitting the dataset into training and validation sets.\n\n- **Adjusted Target Variable `y`:**\n  - The target variable `y` is derived from the 'score' column of the DataFrame `train_feats`.\n  - A constant `a` is subtracted from the 'score' values to adjust them, ensuring that the range starts from 0. This adjustment is consistent with the previous parts of the code.\n\n- **Out-of-Fold Target Variable `oof`:**\n  - The out-of-fold (OOF) target variable `oof` is extracted from the 'score' column of the DataFrame `train_feats`.\n  - OOF predictions are typically used for model evaluation and ensemble methods.\n","metadata":{}},{"cell_type":"code","source":"X = train_feats[feature_names].astype(np.float32).values\n\ny_split = train_feats['score'].astype(int).values\ny = train_feats['score'].astype(np.float32).values-a\noof = train_feats['score'].astype(int).values","metadata":{"execution":{"iopub.execute_input":"2024-04-21T18:42:01.343557Z","iopub.status.busy":"2024-04-21T18:42:01.343308Z","iopub.status.idle":"2024-04-21T18:42:03.250364Z","shell.execute_reply":"2024-04-21T18:42:03.249349Z"},"papermill":{"duration":1.923511,"end_time":"2024-04-21T18:42:03.252712","exception":false,"start_time":"2024-04-21T18:42:01.329201","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(feature_names)","metadata":{"execution":{"iopub.execute_input":"2024-04-21T18:42:03.281032Z","iopub.status.busy":"2024-04-21T18:42:03.280711Z","iopub.status.idle":"2024-04-21T18:42:03.286376Z","shell.execute_reply":"2024-04-21T18:42:03.285506Z"},"papermill":{"duration":0.02162,"end_time":"2024-04-21T18:42:03.288200","exception":false,"start_time":"2024-04-21T18:42:03.266580","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Selection Wrapper Function","metadata":{}},{"cell_type":"markdown","source":"---\n\n**Explanation:**\n\nThe `feature_select_wrapper` function performs feature selection using LightGBM regression models trained within a Stratified K-Fold cross-validation loop. Here's a breakdown of the function:\n\n- **Feature Selection Process:**\n  - The function starts by defining a list of features to be considered for selection, obtained from the `feature_names` variable.\n  - It initializes a Series `fse` with zeros as the index, where each index corresponds to a feature name.\n\n- **Stratified K-Fold Cross-Validation:**\n  - The function uses Stratified K-Fold cross-validation (`StratifiedKFold`) with 5 folds (`n_splits=5`). This ensures that class distributions are approximately equal in each fold.\n  - Within each fold, the training data is split into train and test sets (`X_train_fold`, `X_test_fold`, `y_train_fold`, `y_test_fold`, `y_test_fold_int`) using the indices generated by `skf.split`.\n  - A LightGBM regression model is instantiated (`lgb.LGBMRegressor`) with specified hyperparameters for regression.\n  - The model is trained on the training data (`X_train_fold`, `y_train_fold`) and evaluated on both the training and validation sets (`eval_set`), using the Quadratic Weighted Kappa as the evaluation metric (`eval_metric=quadratic_weighted_kappa`).\n  - The model's predictions on the test set (`X_test_fold`) are computed and rounded to the nearest integer within the range [1, 6].\n  - Performance metrics such as F1 score (`f1_fold`) and Cohen's kappa score (`kappa_fold`) are computed and printed for each fold.\n  - Additionally, a confusion matrix (`cm`) is generated and displayed for visual inspection of model performance.\n\n- **Feature Importance Calculation:**\n  - Feature importance scores (`predictor.feature_importances_`) from each fold are aggregated in the `fse` Series, where each score is added to the corresponding feature's entry.\n  - After processing all folds, the feature importance scores in `fse` are sorted in descending order, and the top 13,000 features are selected (`feature_select`).\n\n- **Return Value:**\n  - The function returns the list of selected features (`feature_select`).\n\nWe create a function to allows for iterative feature selection based on the importance scores generated by LightGBM models trained in a cross-validation framework. By evaluating model performance and feature importance across multiple folds, it provides a  method for selecting informative features. ","metadata":{}},{"cell_type":"code","source":"def feature_select_wrapper():\n\n    features = feature_names\n\n    \n    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n    fse = pd.Series(0, index=features)\n    \n        \n        \n    for train_index, test_index in skf.split(X, y_split):\n\n        X_train_fold, X_test_fold = X[train_index], X[test_index]\n\n\n        y_train_fold, y_test_fold, y_test_fold_int = y[train_index], y[test_index], y_split[test_index]\n\n        model = lgb.LGBMRegressor(\n                    objective = qwk_obj,\n                    metrics = 'None',\n                    learning_rate = 0.01,\n                    max_depth = 5,\n                    num_leaves = 10,\n                    colsample_bytree=0.3,\n                    reg_alpha = 0.7,\n                    reg_lambda = 0.1,\n                    n_estimators=700,\n                    random_state=412,\n                    extra_trees=True,\n                    class_weight='balanced',\n                    verbosity = - 1)\n\n        predictor = model.fit(X_train_fold,\n                                      y_train_fold,\n                                      eval_names=['train', 'valid'],\n                                      eval_set=[(X_train_fold, y_train_fold), (X_test_fold, y_test_fold)],\n                                      eval_metric=quadratic_weighted_kappa,\n                                      callbacks=callbacks,)\n        models.append(predictor)\n        predictions_fold = predictor.predict(X_test_fold)\n        predictions_fold = predictions_fold + a\n        oof[test_index]=predictions_fold\n        predictions_fold = predictions_fold.clip(1, 6).round()\n        predictions.append(predictions_fold)\n        f1_fold = f1_score(y_test_fold_int, predictions_fold, average='weighted')\n        f1_scores.append(f1_fold)\n\n\n        kappa_fold = cohen_kappa_score(y_test_fold_int, predictions_fold, weights='quadratic')\n        kappa_scores.append(kappa_fold)\n\n        cm = confusion_matrix(y_test_fold_int, predictions_fold, labels=[x for x in range(1,7)])\n\n        disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                                      display_labels=[x for x in range(1,7)])\n        disp.plot()\n        plt.show()\n        print(f'F1 score across fold: {f1_fold}')\n        print(f'Cohen kappa score across fold: {kappa_fold}')\n\n        fse += pd.Series(predictor.feature_importances_, features)\n    \n    \n    \n    feature_select = fse.sort_values(ascending=False).index.tolist()[:13000]\n    return feature_select","metadata":{"execution":{"iopub.execute_input":"2024-04-21T18:42:03.316099Z","iopub.status.busy":"2024-04-21T18:42:03.315811Z","iopub.status.idle":"2024-04-21T18:42:03.329303Z","shell.execute_reply":"2024-04-21T18:42:03.328427Z"},"papermill":{"duration":0.029568,"end_time":"2024-04-21T18:42:03.331093","exception":false,"start_time":"2024-04-21T18:42:03.301525","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Training and Evaluation Loop","metadata":{}},{"cell_type":"code","source":"f1_scores = []\nkappa_scores = []\nmodels = []\npredictions = []\ncallbacks = [log_evaluation(period=25), early_stopping(stopping_rounds=75,first_metric_only=True)]\nfeature_select = feature_select_wrapper()","metadata":{"execution":{"iopub.execute_input":"2024-04-21T18:42:03.359208Z","iopub.status.busy":"2024-04-21T18:42:03.358430Z","iopub.status.idle":"2024-04-21T18:57:18.293309Z","shell.execute_reply":"2024-04-21T18:57:18.292402Z"},"papermill":{"duration":914.951107,"end_time":"2024-04-21T18:57:18.295416","exception":false,"start_time":"2024-04-21T18:42:03.344309","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_feats[feature_select].astype(np.float32).values","metadata":{"execution":{"iopub.execute_input":"2024-04-21T18:57:18.341411Z","iopub.status.busy":"2024-04-21T18:57:18.341135Z","iopub.status.idle":"2024-04-21T18:57:19.506192Z","shell.execute_reply":"2024-04-21T18:57:19.505363Z"},"papermill":{"duration":1.190316,"end_time":"2024-04-21T18:57:19.508449","exception":false,"start_time":"2024-04-21T18:57:18.318133","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Evaluation Metrics Calculation","metadata":{"papermill":{"duration":0.022061,"end_time":"2024-04-21T18:57:19.553143","exception":false,"start_time":"2024-04-21T18:57:19.531082","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"___\n\n**Explaination**\n\nWe conducts model training and evaluation using a LightGBM regressor within a Stratified K-Fold cross-validation loop. \n\n- **Setting up Cross-Validation:**\n  - The number of splits for Stratified K-Fold cross-validation is set to 15 (`n_splits = 15`). This means the dataset will be split into 15 folds.\n  - Stratified K-Fold cross-validation is initialized with the specified parameters.\n\n- **Model Training and Evaluation:**\n  - Within the loop, each fold is iterated over.\n  - Training and testing data are split based on the current fold indices.\n  - A LightGBM regressor model is instantiated with specified hyperparameters for regression.\n  - The model is trained on the training data and evaluated on both the training and validation sets.\n  - Predictions are made on the test set, and performance metrics such as F1 score and Cohen's kappa score are computed and printed for each fold.\n  - A confusion matrix is generated and displayed to visualize the model's performance on each fold.\n\n- **Aggregating Results:**\n  - F1 scores and Cohen's kappa scores for each fold are stored in the respective lists (`f1_scores` and `kappa_scores`).\n  - After iterating over all folds, the mean F1 score and mean Cohen's kappa score across all folds are computed and printed.\n\n","metadata":{}},{"cell_type":"code","source":"n_splits = 15\n\nskf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n\nf1_scores = []\nkappa_scores = []\nmodels = []\npredictions = []\ncallbacks = [log_evaluation(period=25), early_stopping(stopping_rounds=75,first_metric_only=True)]\n\ni=1\nfor train_index, test_index in skf.split(X, y_split):\n   \n    print('fold',i)\n    X_train_fold, X_test_fold = X[train_index], X[test_index]\n    \n   \n    y_train_fold, y_test_fold, y_test_fold_int = y[train_index], y[test_index], y_split[test_index]\n    \n    model = lgb.LGBMRegressor(\n                objective = qwk_obj,\n                metrics = 'None',\n                learning_rate = 0.01,\n                max_depth = 5,\n                num_leaves = 10,\n                colsample_bytree=0.3,\n                reg_alpha = 0.7,\n                reg_lambda = 0.1,\n                n_estimators=700,\n                random_state=42,\n                extra_trees=True,\n                class_weight='balanced',\n                verbosity = - 1)\n\n    predictor = model.fit(X_train_fold,\n                                  y_train_fold,\n                                  eval_names=['train', 'valid'],\n                                  eval_set=[(X_train_fold, y_train_fold), (X_test_fold, y_test_fold)],\n                                  eval_metric=quadratic_weighted_kappa,\n                                  callbacks=callbacks,)\n    models.append(predictor)\n    predictions_fold = predictor.predict(X_test_fold)\n    predictions_fold = predictions_fold + a\n    oof[test_index]=predictions_fold\n    predictions_fold = predictions_fold.clip(1, 6).round()\n    predictions.append(predictions_fold)\n    f1_fold = f1_score(y_test_fold_int, predictions_fold, average='weighted')\n    f1_scores.append(f1_fold)\n    \n    \n    kappa_fold = cohen_kappa_score(y_test_fold_int, predictions_fold, weights='quadratic')\n    kappa_scores.append(kappa_fold)\n    \n    cm = confusion_matrix(y_test_fold_int, predictions_fold, labels=[x for x in range(1,7)])\n\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                                  display_labels=[x for x in range(1,7)])\n    disp.plot()\n    plt.show()\n    print(f'F1 score across fold: {f1_fold}')\n    print(f'Cohen kappa score across fold: {kappa_fold}')\n    i+=1\n\nmean_f1_score = np.mean(f1_scores)\nmean_kappa_score = np.mean(kappa_scores)\n\nprint(f'Mean F1 score across {n_splits} folds: {mean_f1_score}')\nprint(f'Mean Cohen kappa score across {n_splits} folds: {mean_kappa_score}')","metadata":{"execution":{"iopub.execute_input":"2024-04-21T18:57:19.598570Z","iopub.status.busy":"2024-04-21T18:57:19.598279Z","iopub.status.idle":"2024-04-21T19:30:33.834154Z","shell.execute_reply":"2024-04-21T19:30:33.833233Z"},"papermill":{"duration":1994.261645,"end_time":"2024-04-21T19:30:33.836685","exception":false,"start_time":"2024-04-21T18:57:19.575040","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n\nwith open('models.pkl', 'wb') as f:\n    pickle.dump(models, f)","metadata":{"execution":{"iopub.execute_input":"2024-04-21T19:30:33.933753Z","iopub.status.busy":"2024-04-21T19:30:33.933452Z","iopub.status.idle":"2024-04-21T19:30:34.117903Z","shell.execute_reply":"2024-04-21T19:30:34.117069Z"},"papermill":{"duration":0.235488,"end_time":"2024-04-21T19:30:34.120422","exception":false,"start_time":"2024-04-21T19:30:33.884934","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('models.pkl', 'rb') as f:\n    models = pickle.load(f)","metadata":{"execution":{"iopub.execute_input":"2024-04-21T19:30:34.218116Z","iopub.status.busy":"2024-04-21T19:30:34.217800Z","iopub.status.idle":"2024-04-21T19:30:34.359192Z","shell.execute_reply":"2024-04-21T19:30:34.358193Z"},"papermill":{"duration":0.19219,"end_time":"2024-04-21T19:30:34.361661","exception":false,"start_time":"2024-04-21T19:30:34.169471","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Inference**","metadata":{"papermill":{"duration":0.047177,"end_time":"2024-04-21T19:30:34.457555","exception":false,"start_time":"2024-04-21T19:30:34.410378","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"___\n\n**Explaination**\n- **Paragraph Preprocessing:**\n  - The `Paragraph_Preprocess` function is applied to the test data (`test`) to preprocess the paragraphs.\n  - The resulting processed paragraphs are then used to extract paragraph features using the `Paragraph_Eng` function.\n  - The extracted paragraph features are stored in `test_feats`.\n\n- **Sentence Preprocessing:**\n  - The `Sentence_Preprocess` function is applied to the test data to preprocess the sentences within the essays.\n  - Features related to sentence length and word count are extracted using the `Sentence_Eng` function.\n  - The extracted sentence features are merged with `test_feats`.\n\n- **Word Preprocessing:**\n  - The `Word_Preprocess` function is applied to the test data to preprocess individual words.\n  - Features related to word length and word count are extracted using the `Word_Eng` function.\n  - The extracted word features are merged with `test_feats`.\n\n- **TfidfVectorizer:**\n  - The TfidfVectorizer (`vectorizer`) is applied to transform the test essays into TF-IDF features.\n  - The TF-IDF features are merged with `test_feats`.\n\n- **CountVectorizer:**\n  - The CountVectorizer (`vectorizer_cnt`) is applied to transform the test essays into count-based features.\n  - The count-based features are merged with `test_feats`.\n\n- **Deberta Out-of-Fold Predictions:**\n  - The out-of-fold predictions from the Deberta model (`predicted_score`) are assigned to columns in `test_feats` for each score category.\n\n- **Feature Number:**\n  - The number of features extracted is calculated by excluding the 'essay_id' and 'score' columns from `test_feats`.\n  - The total number of features is printed.\n\n\n\n","metadata":{}},{"cell_type":"code","source":"# Paragraph\ntmp = Paragraph_Preprocess(test)\ntest_feats = Paragraph_Eng(tmp)\n# Sentence\ntmp = Sentence_Preprocess(test)\ntest_feats = test_feats.merge(Sentence_Eng(tmp), on='essay_id', how='left')\n# Word\ntmp = Word_Preprocess(test)\ntest_feats = test_feats.merge(Word_Eng(tmp), on='essay_id', how='left')\n\n# Tfidf\ntest_tfid = vectorizer.transform([i for i in test['full_text']])\ndense_matrix = test_tfid.toarray()\ndf = pd.DataFrame(dense_matrix)\ntfid_columns = [ f'tfid_{i}' for i in range(len(df.columns))]\ndf.columns = tfid_columns\ndf['essay_id'] = test_feats['essay_id']\ntest_feats = test_feats.merge(df, on='essay_id', how='left')\n\n# CountVectorizer\ntest_tfid = vectorizer_cnt.transform([i for i in test['full_text']])\ndense_matrix = test_tfid.toarray()\ndf = pd.DataFrame(dense_matrix)\ntfid_columns = [ f'tfid_cnt_{i}' for i in range(len(df.columns))]\ndf.columns = tfid_columns\ndf['essay_id'] = test_feats['essay_id']\ntest_feats = test_feats.merge(df, on='essay_id', how='left')\n\nfor i in range(6):\n    test_feats[f'deberta_oof_{i}'] = predicted_score[:, i]\n\n# Features number\nfeature_names = list(filter(lambda x: x not in ['essay_id','score'], test_feats.columns))\nprint('Features number: ',len(feature_names))\n","metadata":{"execution":{"iopub.execute_input":"2024-04-21T19:30:34.556586Z","iopub.status.busy":"2024-04-21T19:30:34.556265Z","iopub.status.idle":"2024-04-21T19:30:35.067207Z","shell.execute_reply":"2024-04-21T19:30:35.066082Z"},"papermill":{"duration":0.564458,"end_time":"2024-04-21T19:30:35.069143","exception":false,"start_time":"2024-04-21T19:30:34.504685","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generating Submission File\n","metadata":{}},{"cell_type":"markdown","source":"___\n\n**Explaination**\n- **Ensemble Prediction:**\n  - For each model in the list `models`, predictions are made using the selected features (`feature_select`) from the test data (`test_feats`).\n  - The predictions are adjusted by adding `a` to align them with the scoring scale.\n  - The adjusted predictions from all models are stored in the `probabilities` list.\n  \n- **Aggregating Predictions:**\n  - The predictions from all models are averaged element-wise to obtain the final prediction probabilities for each sample in the test data.\n  \n- **Rounding Predictions:**\n  - The averaged probabilities are rounded to the nearest integer value to get the final predicted scores.\n  - Predicted scores below 1 are clipped to 1, and scores above 6 are clipped to 6 to ensure they fall within the valid scoring range.\n  \n- **Displaying Predictions:**\n  - The final predictions are printed to the console.\n\n","metadata":{}},{"cell_type":"code","source":"probabilities = []\nfor model in models:\n    proba= model.predict(test_feats[feature_select])+ a\n    probabilities.append(proba)\n\npredictions = np.mean(probabilities, axis=0)\n\npredictions = np.round(predictions.clip(1, 6))\n\nprint(predictions)","metadata":{"execution":{"iopub.execute_input":"2024-04-21T19:30:35.166837Z","iopub.status.busy":"2024-04-21T19:30:35.166549Z","iopub.status.idle":"2024-04-21T19:30:35.929946Z","shell.execute_reply":"2024-04-21T19:30:35.928932Z"},"papermill":{"duration":0.814368,"end_time":"2024-04-21T19:30:35.932296","exception":false,"start_time":"2024-04-21T19:30:35.117928","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission=pd.read_csv(\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/sample_submission.csv\")\nsubmission['score']=predictions\nsubmission['score']=submission['score'].astype(int)\nsubmission.to_csv(\"submission.csv\",index=None)\n","metadata":{"execution":{"iopub.execute_input":"2024-04-21T19:30:36.031965Z","iopub.status.busy":"2024-04-21T19:30:36.031247Z","iopub.status.idle":"2024-04-21T19:30:36.060924Z","shell.execute_reply":"2024-04-21T19:30:36.060053Z"},"papermill":{"duration":0.08022,"end_time":"2024-04-21T19:30:36.062814","exception":false,"start_time":"2024-04-21T19:30:35.982594","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Keep Exploring! üëÄ\n\nThank you for delving into this notebook! If you found it insightful or beneficial, I encourage you to explore more of my projects and contributions on my profile.\n\nüëâ [Visit my Profile](https://www.kaggle.com/zulqarnainalipk) üëà\n\n[GitHub]( https://github.com/zulqarnainalipk) |\n[LinkedIn]( https://www.linkedin.com/in/zulqarnainalipk/)\n\n## Share Your Thoughts! üôè\n\nYour feedback is invaluable! Your insights and suggestions drive our ongoing improvement. If you have any comments, questions, or ideas to contribute, please feel free to reach out.\n\nüì¨ Contact me via email: [zulqar445ali@gmail.com](mailto:zulqar445ali@gmail.com)\n\nI extend my sincere gratitude for your time and engagement. Your support inspires me to create even more valuable content.\nHappy coding and best of luck in your data science endeavors! üöÄ\n\n","metadata":{}}]}
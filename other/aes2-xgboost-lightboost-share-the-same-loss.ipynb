{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cabe250d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-14T02:25:31.201219Z",
     "iopub.status.busy": "2024-05-14T02:25:31.200872Z",
     "iopub.status.idle": "2024-05-14T02:25:35.775012Z",
     "shell.execute_reply": "2024-05-14T02:25:35.773642Z"
    },
    "papermill": {
     "duration": 4.589983,
     "end_time": "2024-05-14T02:25:35.777022",
     "exception": false,
     "start_time": "2024-05-14T02:25:31.187039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_AVAILABLE = True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "\n",
    "_test = pd.read_csv(\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv\")\n",
    "ENABLE_DONT_WASTE_YOUR_RUN_TIME = len(_test) < 10\n",
    "# ENABLE_DONT_WASTE_YOUR_RUN_TIME = False\n",
    "if ENABLE_DONT_WASTE_YOUR_RUN_TIME:\n",
    "    import shutil\n",
    "\n",
    "#     shutil.copyfile(\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/sample_submission.csv\", \"submission.csv\")\n",
    "#     exit(0)\n",
    "    del _test\n",
    "    gc.collect()\n",
    "\n",
    "import torch\n",
    "\n",
    "CUDA_AVAILABLE = torch.cuda.is_available()\n",
    "print(f\"{CUDA_AVAILABLE = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392d94ed",
   "metadata": {
    "papermill": {
     "duration": 0.011841,
     "end_time": "2024-05-14T02:25:35.801109",
     "exception": false,
     "start_time": "2024-05-14T02:25:35.789268",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22d9e26a",
   "metadata": {
    "papermill": {
     "duration": 0.014115,
     "end_time": "2024-05-14T02:25:35.828490",
     "exception": false,
     "start_time": "2024-05-14T02:25:35.814375",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Project Overview:\n",
    "Automated Essay Scoring with Open-Source Solutions Background The first automated essay scoring competition, the Automated Student Assessment Prize (ASAP), was held twelve years ago. Since then, advancements in Automated Writing Evaluation (AWE) systems have aimed to reduce the time and cost associated with manual grading of student essays. However, many of these advancements are not widely accessible due to cost barriers, limiting their impact, especially in underserved communities.\n",
    "\n",
    "Goal The goal of this competition\n",
    "is to develop an open-source essay scoring algorithm that improves upon the original ASAP competition. By leveraging updated datasets and new ideas, the aim is to provide reliable and accessible automated grading solutions to overtaxed teachers, particularly in underserved communities. The competition seeks to reduce the high expense and time required for manual grading and enable the introduction of essays into testing, a key indicator of student learning.\n",
    "\n",
    "Dataset\n",
    "The competition utilizes the largest open-access writing dataset aligned with current standards for student-appropriate assessments. The dataset includes high-quality, realistic classroom writing samples, addressing the limitations of previous efforts by encompassing diverse economic and location populations to mitigate potential algorithmic bias. The dataset focuses on common essay formats used in classroom settings, providing a more expansive and representative sample for training and evaluation. Approach\n",
    "\n",
    "Data Loading,\n",
    "We begin by importing the necessary libraries for our task, including pandas, matplotlib.pyplot, seaborn, numpy, and torch. Data Loading We load the training data from a CSV file using pandas read_csv function. The df_train DataFrame now holds our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6669426",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T02:25:35.856476Z",
     "iopub.status.busy": "2024-05-14T02:25:35.856133Z",
     "iopub.status.idle": "2024-05-14T02:25:35.982372Z",
     "shell.execute_reply": "2024-05-14T02:25:35.981294Z"
    },
    "papermill": {
     "duration": 0.14215,
     "end_time": "2024-05-14T02:25:35.984539",
     "exception": false,
     "start_time": "2024-05-14T02:25:35.842389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_AVAILABLE = True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "\n",
    "_test = pd.read_csv(\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv\")\n",
    "ENABLE_DONT_WASTE_YOUR_RUN_TIME = len(_test) < 10\n",
    "# ENABLE_DONT_WASTE_YOUR_RUN_TIME = False\n",
    "if ENABLE_DONT_WASTE_YOUR_RUN_TIME:\n",
    "    import shutil\n",
    "\n",
    "#     shutil.copyfile(\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/sample_submission.csv\", \"submission.csv\")\n",
    "#     exit(0)\n",
    "    del _test\n",
    "    gc.collect()\n",
    "\n",
    "import torch\n",
    "\n",
    "CUDA_AVAILABLE = torch.cuda.is_available()\n",
    "print(f\"{CUDA_AVAILABLE = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e8ff1e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T02:25:36.010566Z",
     "iopub.status.busy": "2024-05-14T02:25:36.010264Z",
     "iopub.status.idle": "2024-05-14T02:26:15.038700Z",
     "shell.execute_reply": "2024-05-14T02:26:15.037769Z"
    },
    "papermill": {
     "duration": 39.061076,
     "end_time": "2024-05-14T02:26:15.058021",
     "exception": false,
     "start_time": "2024-05-14T02:25:35.996945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-14 02:25:42.925900: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-14 02:25:42.926004: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-14 02:25:43.053389: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [Errno -3] Temporary\n",
      "[nltk_data]     failure in name resolution>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "import copy\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "import nltk\n",
    "from datasets import Dataset\n",
    "from glob import glob\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import re\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier,GradientBoostingClassifier,BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,ComplementNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from lightgbm import log_evaluation, early_stopping\n",
    "import lightgbm as lgb\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1ba9315",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T02:26:15.086373Z",
     "iopub.status.busy": "2024-05-14T02:26:15.086056Z",
     "iopub.status.idle": "2024-05-14T02:27:26.155206Z",
     "shell.execute_reply": "2024-05-14T02:27:26.154192Z"
    },
    "papermill": {
     "duration": 71.085316,
     "end_time": "2024-05-14T02:27:26.157580",
     "exception": false,
     "start_time": "2024-05-14T02:26:15.072264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fefb9d16acf844778c489e143d2fff6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = 1024\n",
    "TEST_DATA_PATH = \"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv\"\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "import gc\n",
    "import glob\n",
    "MODEL_PATHS = [\n",
    "    '/kaggle/input/aes2-400-20240419134941/*/*',\n",
    "    '/kaggle/input/best-model-1/deberta-large-fold1/checkpoint-100/',\n",
    "    '/kaggle/input/train-best-model-3/deberta-large-fold1/checkpoint-200/'\n",
    "]\n",
    "EVAL_BATCH_SIZE = 1\n",
    "\n",
    "models = []\n",
    "for path in MODEL_PATHS:\n",
    "    models.extend(glob.glob(path))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(models[0])\n",
    "\n",
    "def tokenize(sample):\n",
    "    return tokenizer(sample['full_text'], max_length=MAX_LENGTH, truncation=True)\n",
    "\n",
    "df_test = pd.read_csv(TEST_DATA_PATH)\n",
    "ds = Dataset.from_pandas(df_test).map(tokenize).remove_columns(['essay_id', 'full_text'])\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \".\", \n",
    "    per_device_eval_batch_size=EVAL_BATCH_SIZE, \n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "predictions = []\n",
    "for model in models:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model)\n",
    "    trainer = Trainer(\n",
    "        model=model, \n",
    "        args=args, \n",
    "        data_collator=DataCollatorWithPadding(tokenizer), \n",
    "        tokenizer=tokenizer\n",
    "    )    \n",
    "    preds = trainer.predict(ds).predictions\n",
    "    predictions.append(softmax(preds, axis=-1))\n",
    "    del model, trainer\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "466365b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T02:27:26.185356Z",
     "iopub.status.busy": "2024-05-14T02:27:26.185059Z",
     "iopub.status.idle": "2024-05-14T02:27:26.189481Z",
     "shell.execute_reply": "2024-05-14T02:27:26.188724Z"
    },
    "papermill": {
     "duration": 0.020224,
     "end_time": "2024-05-14T02:27:26.191287",
     "exception": false,
     "start_time": "2024-05-14T02:27:26.171063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_score = 0.\n",
    "for p in predictions:\n",
    "    predicted_score += p\n",
    "    \n",
    "predicted_score /= len(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bba80f39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T02:27:26.218659Z",
     "iopub.status.busy": "2024-05-14T02:27:26.218392Z",
     "iopub.status.idle": "2024-05-14T02:27:26.233152Z",
     "shell.execute_reply": "2024-05-14T02:27:26.232465Z"
    },
    "papermill": {
     "duration": 0.030677,
     "end_time": "2024-05-14T02:27:26.234934",
     "exception": false,
     "start_time": "2024-05-14T02:27:26.204257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test['score'] = predicted_score.argmax(-1) + 1\n",
    "df_test.head()\n",
    "df_test[['essay_id', 'score']].to_csv('submission1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ce21b6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T02:27:26.262187Z",
     "iopub.status.busy": "2024-05-14T02:27:26.261926Z",
     "iopub.status.idle": "2024-05-14T02:27:26.905583Z",
     "shell.execute_reply": "2024-05-14T02:27:26.904683Z"
    },
    "papermill": {
     "duration": 0.659595,
     "end_time": "2024-05-14T02:27:26.907786",
     "exception": false,
     "start_time": "2024-05-14T02:27:26.248191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>essay_id</th><th>full_text</th><th>score</th><th>paragraph</th></tr><tr><td>str</td><td>str</td><td>i64</td><td>list[str]</td></tr></thead><tbody><tr><td>&quot;000d118&quot;</td><td>&quot;Many people ha…</td><td>3</td><td>[&quot;Many people have car where they live. The thing they don&#x27;t know is that when you use a car alot of thing can happen like you can get in accidet or the smoke that the car has is bad to breath on if someone is walk but in VAUBAN,Germany they dont have that proble because 70 percent of vauban&#x27;s families do not own cars,and 57 percent sold a car to move there. Street parkig ,driveways and home garages are forbidden on the outskirts of freiburd that near the French and Swiss borders. You probaly won&#x27;t see a car in Vauban&#x27;s streets because they are completely &quot;car free&quot; but If some that lives in VAUBAN that owns a car ownership is allowed,but there are only two places that you can park a large garages at the edge of the development,where a car owner buys a space but it not cheap to buy one they sell the space for you car for $40,000 along with a home. The vauban people completed this in 2006 ,they said that this an example of a growing trend in Europe,The untile states and some where else are suburban life from auto use this is called &quot;smart planning&quot;. The current efforts to drastically reduce greenhouse gas emissions from tailes the passengee cars are responsible for 12 percent of greenhouse gas emissions in Europe and up to 50 percent in some car intensive in the United States. I honeslty think that good idea that they did that is Vaudan because that makes cities denser and better for walking and in VAUBAN there are 5,500 residents within a rectangular square mile. In the artical David Gold berg said that &quot;All of our development since World war 2 has been centered on the cars,and that will have to change&quot; and i think that was very true what David Gold said because alot thing we need cars to do we can go anyway were with out cars beacuse some people are a very lazy to walk to place thats why they alot of people use car and i think that it was a good idea that that they did that in VAUBAN so people can see how we really don&#x27;t need car to go to place from place because we can walk from were we need to go or we can ride bycles with out the use of a car. It good that they are doing that if you thik about your help the earth in way and thats a very good thing to. In the United states ,the Environmental protection Agency is promoting what is called &quot;car reduced&quot;communtunties,and the legislators are starting to act,if cautiously. Maany experts expect pubic transport serving suburbs to play a much larger role in a new six years federal transportation bill to approved this year. In previous bill,80 percent of appropriations have by law gone to highways and only 20 percent to other transports. There many good reason why they should do this.    &quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 4)\n",
       "┌──────────┬───────────────────────────────────┬───────┬───────────────────────────────────┐\n",
       "│ essay_id ┆ full_text                         ┆ score ┆ paragraph                         │\n",
       "│ ---      ┆ ---                               ┆ ---   ┆ ---                               │\n",
       "│ str      ┆ str                               ┆ i64   ┆ list[str]                         │\n",
       "╞══════════╪═══════════════════════════════════╪═══════╪═══════════════════════════════════╡\n",
       "│ 000d118  ┆ Many people have car where they … ┆ 3     ┆ [\"Many people have car where the… │\n",
       "└──────────┴───────────────────────────────────┴───────┴───────────────────────────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [  \n",
    "    (\n",
    "        pl.col(\"full_text\").str.split(by=\"\\n\\n\").alias(\"paragraph\")\n",
    "    ),\n",
    "]\n",
    "PATH = \"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/\"\n",
    "\n",
    "train = pl.read_csv(PATH + \"train.csv\").with_columns(columns)\n",
    "test = pl.read_csv(PATH + \"test.csv\").with_columns(columns)\n",
    "\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11f499bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T02:27:26.936612Z",
     "iopub.status.busy": "2024-05-14T02:27:26.936346Z",
     "iopub.status.idle": "2024-05-14T02:27:26.955821Z",
     "shell.execute_reply": "2024-05-14T02:27:26.955018Z"
    },
    "papermill": {
     "duration": 0.035963,
     "end_time": "2024-05-14T02:27:26.957621",
     "exception": false,
     "start_time": "2024-05-14T02:27:26.921658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cList = {\n",
    "  \"ain't\": \"am not\",\"aren't\": \"are not\",\"can't\": \"cannot\",\"can't've\": \"cannot have\",\"'cause\": \"because\",  \"could've\": \"could have\",\"couldn't\": \"could not\",\"couldn't've\": \"could not have\",\"didn't\": \"did not\",\"doesn't\": \"does not\",\"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\"hasn't\": \"has not\",\n",
    "  \"haven't\": \"have not\",\"he'd\": \"he would\",\"he'd've\": \"he would have\",\"he'll\": \"he will\",\"he'll've\": \"he will have\",\"he's\": \"he is\",\n",
    "  \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\"how's\": \"how is\",\"I'd\": \"I would\",\"I'd've\": \"I would have\",\"I'll\": \"I will\",\"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\",\n",
    "  \"isn't\": \"is not\",\"it'd\": \"it had\",\"it'd've\": \"it would have\",\"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\",\"let's\": \"let us\",\"ma'am\": \"madam\",\"mayn't\": \"may not\",\n",
    "  \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\"mustn't've\": \"must not have\",\"needn't\": \"need not\",\"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n",
    "  \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\"she'll\": \"she will\",\"she'll've\": \"she will have\",\"she's\": \"she is\",\n",
    "  \"should've\": \"should have\",\"shouldn't\": \"should not\",\"shouldn't've\": \"should not have\",\"so've\": \"so have\",\"so's\": \"so is\",\"that'd\": \"that would\",\"that'd've\": \"that would have\",\"that's\": \"that is\",\"there'd\": \"there had\",\"there'd've\": \"there would have\",\"there's\": \"there is\",\"they'd\": \"they would\",\"they'd've\": \"they would have\",\"they'll\": \"they will\",\"they'll've\": \"they will have\",\"they're\": \"they are\",\"they've\": \"they have\",\"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we had\",\n",
    "  \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\"we're\": \"we are\",\"we've\": \"we have\",\n",
    "  \"weren't\": \"were not\",\"what'll\": \"what will\",\"what'll've\": \"what will have\",\n",
    "  \"what're\": \"what are\",\"what's\": \"what is\",\"what've\": \"what have\",\"when's\": \"when is\",\"when've\": \"when have\",\n",
    "  \"where'd\": \"where did\",\"where's\": \"where is\",\"where've\": \"where have\",\"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who's\": \"who is\",\"who've\": \"who have\",\"why's\": \"why is\",\n",
    "  \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\"won't've\": \"will not have\",\"would've\": \"would have\",\"wouldn't\": \"would not\",\n",
    "  \"wouldn't've\": \"would not have\",\"y'all\": \"you all\",\"y'alls\": \"you alls\",\"y'all'd\": \"you all would\",\n",
    "  \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you had\",\"you'd've\": \"you would have\",\"you'll\": \"you you will\",\"you'll've\": \"you you will have\",\"you're\": \"you are\",  \"you've\": \"you have\"\n",
    "   }\n",
    "\n",
    "c_re = re.compile('(%s)' % '|'.join(cList.keys()))\n",
    "\n",
    "def expandContractions(text, c_re=c_re):\n",
    "    def replace(match):\n",
    "        return cList[match.group(0)]\n",
    "    return c_re.sub(replace, text)\n",
    "\n",
    "def removeHTML(x):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',x)\n",
    "def dataPreprocessing(x):\n",
    "    x = x.lower()\n",
    "    x = removeHTML(x)\n",
    "    x = re.sub(\"@\\w+\", '',x)\n",
    "    x = re.sub(\"'\\d+\", '',x)\n",
    "    x = re.sub(\"\\d+\", '',x)\n",
    "    x = re.sub(\"http\\w+\", '',x)\n",
    "    x = re.sub(r\"\\s+\", \" \", x)\n",
    "#     x = expandContractions(x)\n",
    "    x = re.sub(r\"\\.+\", \".\", x)\n",
    "    x = re.sub(r\"\\,+\", \",\", x)\n",
    "    x = x.strip()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8150125a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-14T02:27:26.985501Z",
     "iopub.status.busy": "2024-05-14T02:27:26.984742Z",
     "iopub.status.idle": "2024-05-14T02:27:27.765821Z",
     "shell.execute_reply": "2024-05-14T02:27:27.764476Z"
    },
    "papermill": {
     "duration": 0.796651,
     "end_time": "2024-05-14T02:27:27.767528",
     "exception": true,
     "start_time": "2024-05-14T02:27:26.970877",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "If you find this notebook, Please consider upvoting. This encourages me to share more useful codes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you find this notebook, Please consider upvoting. This encourages me to share more useful codes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: If you find this notebook, Please consider upvoting. This encourages me to share more useful codes"
     ]
    }
   ],
   "source": [
    "raise Exception(\"If you find this notebook, Please consider upvoting. This encourages me to share more useful codes\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64e77da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T06:18:03.524531Z",
     "iopub.status.busy": "2024-05-03T06:18:03.523958Z",
     "iopub.status.idle": "2024-05-03T06:18:06.182846Z",
     "shell.execute_reply": "2024-05-03T06:18:06.181835Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "with open('/kaggle/input/english-word-hx/words.txt', 'r') as file:\n",
    "    english_vocab = set(word.strip().lower() for word in file)\n",
    "    \n",
    "def count_spelling_errors(text):\n",
    "    doc = nlp(text)\n",
    "    lemmatized_tokens = [token.lemma_.lower() for token in doc]\n",
    "    spelling_errors = sum(1 for token in lemmatized_tokens if token not in english_vocab)\n",
    "    return spelling_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6849159a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T06:18:06.218068Z",
     "iopub.status.busy": "2024-05-03T06:18:06.217644Z",
     "iopub.status.idle": "2024-05-03T06:18:06.224434Z",
     "shell.execute_reply": "2024-05-03T06:18:06.223398Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"\n",
    "    Remove all punctuation from the input text.\n",
    "    \n",
    "    Args:\n",
    "    - text (str): The input text.\n",
    "    \n",
    "    Returns:\n",
    "    - str: The text with punctuation removed.\n",
    "    \"\"\"\n",
    "\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7ac23e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T06:18:06.253064Z",
     "iopub.status.busy": "2024-05-03T06:18:06.252649Z",
     "iopub.status.idle": "2024-05-03T06:18:07.550285Z",
     "shell.execute_reply": "2024-05-03T06:18:07.549225Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Paragraph_Preprocess(tmp):\n",
    "\n",
    "    tmp = tmp.explode('paragraph')\n",
    "    tmp = tmp.with_columns(pl.col('paragraph').map_elements(dataPreprocessing))\n",
    "    tmp = tmp.with_columns(pl.col('paragraph').map_elements(remove_punctuation).alias('paragraph_no_pinctuation'))\n",
    "    tmp = tmp.with_columns(pl.col('paragraph_no_pinctuation').map_elements(count_spelling_errors).alias(\"paragraph_error_num\"))\n",
    "    tmp = tmp.with_columns(pl.col('paragraph').map_elements(lambda x: len(x)).alias(\"paragraph_len\"))\n",
    "    tmp = tmp.with_columns(pl.col('paragraph').map_elements(lambda x: len(x.split('.'))).alias(\"paragraph_sentence_cnt\"),\n",
    "                    pl.col('paragraph').map_elements(lambda x: len(x.split(' '))).alias(\"paragraph_word_cnt\"),)\n",
    "    return tmp\n",
    "\n",
    "# feature_eng\n",
    "paragraph_fea = ['paragraph_len','paragraph_sentence_cnt','paragraph_word_cnt']\n",
    "paragraph_fea2 = ['paragraph_error_num'] + paragraph_fea\n",
    "def Paragraph_Eng(train_tmp):\n",
    "    num_list = [0, 50,75,100,125,150,175,200,250,300,350,400,500,600]\n",
    "    num_list2 = [0, 50,75,100,125,150,175,200,250,300,350,400,500,600,700]\n",
    "    aggs = [\n",
    "        *[pl.col('paragraph').filter(pl.col('paragraph_len') >= i).count().alias(f\"paragraph_>{i}_cnt\") for i in [0, 50,75,100,125,150,175,200,250,300,350,400,500,600,700] ], \n",
    "        *[pl.col('paragraph').filter(pl.col('paragraph_len') <= i).count().alias(f\"paragraph_<{i}_cnt\") for i in [25,49]], \n",
    "        *[pl.col(fea).max().alias(f\"{fea}_max\") for fea in paragraph_fea2],\n",
    "        *[pl.col(fea).mean().alias(f\"{fea}_mean\") for fea in paragraph_fea2],\n",
    "        *[pl.col(fea).min().alias(f\"{fea}_min\") for fea in paragraph_fea2],\n",
    "        *[pl.col(fea).sum().alias(f\"{fea}_sum\") for fea in paragraph_fea2],\n",
    "        *[pl.col(fea).first().alias(f\"{fea}_first\") for fea in paragraph_fea2],\n",
    "        *[pl.col(fea).last().alias(f\"{fea}_last\") for fea in paragraph_fea2],\n",
    "        *[pl.col(fea).kurtosis().alias(f\"{fea}_kurtosis\") for fea in paragraph_fea2],\n",
    "        *[pl.col(fea).quantile(0.25).alias(f\"{fea}_q1\") for fea in paragraph_fea2],\n",
    "        *[pl.col(fea).quantile(0.75).alias(f\"{fea}_q3\") for fea in paragraph_fea2],\n",
    "        ]\n",
    "    df = train_tmp.group_by(['essay_id'], maintain_order=True).agg(aggs).sort(\"essay_id\")\n",
    "    df = df.to_pandas()\n",
    "    return df\n",
    "\n",
    "if ENABLE_DONT_WASTE_YOUR_RUN_TIME:\n",
    "    with open(\"/kaggle/input/aes2-cache/paragraph_preprocess_tmp.pickle\", \"rb\") as f:\n",
    "        tmp = pickle.load(f)\n",
    "    with open(\"/kaggle/input/aes2-cache/paragraph_preprocess_train_feats.pickle\", \"rb\") as f:\n",
    "        train_feats = pickle.load(f)\n",
    "else:\n",
    "    tmp = Paragraph_Preprocess(train)\n",
    "    train_feats = Paragraph_Eng(tmp)\n",
    "\n",
    "feature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\n",
    "print('Features Number: ',len(feature_names))\n",
    "train_feats.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac36adf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T06:18:07.578222Z",
     "iopub.status.busy": "2024-05-03T06:18:07.577892Z",
     "iopub.status.idle": "2024-05-03T06:18:15.508876Z",
     "shell.execute_reply": "2024-05-03T06:18:15.507826Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Sentence_Preprocess(tmp):\n",
    "    tmp = tmp.with_columns(pl.col('full_text').map_elements(dataPreprocessing).str.split(by=\".\").alias(\"sentence\"))\n",
    "    tmp = tmp.explode('sentence')\n",
    "    tmp = tmp.with_columns(pl.col('sentence').map_elements(lambda x: len(x)).alias(\"sentence_len\"))\n",
    "    tmp = tmp.with_columns(pl.col('sentence').map_elements(lambda x: len(x.split(' '))).alias(\"sentence_word_cnt\"))    \n",
    "    return tmp\n",
    "\n",
    "# feature_eng\n",
    "sentence_fea = ['sentence_len','sentence_word_cnt']\n",
    "def Sentence_Eng(train_tmp):\n",
    "    aggs = [\n",
    "        *[pl.col('sentence').filter(pl.col('sentence_len') >= i).count().alias(f\"sentence_>{i}_cnt\") for i in [0,15,50,100,150,200,250,300] ], \n",
    "        *[pl.col('sentence').filter(pl.col('sentence_len') <= i).count().alias(f\"sentence_<{i}_cnt\") for i in [15,50] ], \n",
    "        *[pl.col(fea).max().alias(f\"{fea}_max\") for fea in sentence_fea],\n",
    "        *[pl.col(fea).mean().alias(f\"{fea}_mean\") for fea in sentence_fea],\n",
    "        *[pl.col(fea).min().alias(f\"{fea}_min\") for fea in sentence_fea],\n",
    "        *[pl.col(fea).sum().alias(f\"{fea}_sum\") for fea in sentence_fea],\n",
    "        *[pl.col(fea).first().alias(f\"{fea}_first\") for fea in sentence_fea],\n",
    "        *[pl.col(fea).last().alias(f\"{fea}_last\") for fea in sentence_fea],\n",
    "        *[pl.col(fea).kurtosis().alias(f\"{fea}_kurtosis\") for fea in sentence_fea],\n",
    "        *[pl.col(fea).quantile(0.25).alias(f\"{fea}_q1\") for fea in sentence_fea],\n",
    "        *[pl.col(fea).quantile(0.75).alias(f\"{fea}_q3\") for fea in sentence_fea],\n",
    "    \n",
    "        ]\n",
    "    df = train_tmp.group_by(['essay_id'], maintain_order=True).agg(aggs).sort(\"essay_id\")\n",
    "    df = df.to_pandas()\n",
    "    return df\n",
    "\n",
    "tmp = Sentence_Preprocess(train)\n",
    "train_feats = train_feats.merge(Sentence_Eng(tmp), on='essay_id', how='left')\n",
    "\n",
    "feature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\n",
    "print('Features Number: ',len(feature_names))\n",
    "train_feats.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca285a49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T06:18:15.540394Z",
     "iopub.status.busy": "2024-05-03T06:18:15.540064Z",
     "iopub.status.idle": "2024-05-03T06:18:29.121129Z",
     "shell.execute_reply": "2024-05-03T06:18:29.120061Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# word feature\n",
    "def Word_Preprocess(tmp):\n",
    "    tmp = tmp.with_columns(pl.col('full_text').map_elements(dataPreprocessing).str.split(by=\" \").alias(\"word\"))\n",
    "    tmp = tmp.explode('word')\n",
    "    tmp = tmp.with_columns(pl.col('word').map_elements(lambda x: len(x)).alias(\"word_len\"))\n",
    "    tmp = tmp.filter(pl.col('word_len')!=0)    \n",
    "    return tmp\n",
    "\n",
    "# feature_eng\n",
    "def Word_Eng(train_tmp):\n",
    "    aggs = [\n",
    "        *[pl.col('word').filter(pl.col('word_len') >= i+1).count().alias(f\"word_{i+1}_cnt\") for i in range(15) ], \n",
    "        pl.col('word_len').max().alias(f\"word_len_max\"),\n",
    "        pl.col('word_len').mean().alias(f\"word_len_mean\"),\n",
    "        pl.col('word_len').std().alias(f\"word_len_std\"),\n",
    "        pl.col('word_len').quantile(0.25).alias(f\"word_len_q1\"),\n",
    "        pl.col('word_len').quantile(0.50).alias(f\"word_len_q2\"),\n",
    "        pl.col('word_len').quantile(0.75).alias(f\"word_len_q3\"),\n",
    "        ]\n",
    "    df = train_tmp.group_by(['essay_id'], maintain_order=True).agg(aggs).sort(\"essay_id\")\n",
    "    df = df.to_pandas()\n",
    "    return df\n",
    "\n",
    "tmp = Word_Preprocess(train)\n",
    "train_feats = train_feats.merge(Word_Eng(tmp), on='essay_id', how='left')\n",
    "\n",
    "feature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\n",
    "print('Features Number: ',len(feature_names))\n",
    "train_feats.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46ac3e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T06:18:29.151459Z",
     "iopub.status.busy": "2024-05-03T06:18:29.151132Z",
     "iopub.status.idle": "2024-05-03T06:21:57.267952Z",
     "shell.execute_reply": "2024-05-03T06:21:57.266995Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "            tokenizer=lambda x: x,\n",
    "            preprocessor=lambda x: x,\n",
    "            token_pattern=None,\n",
    "            strip_accents='unicode',\n",
    "            analyzer = 'word',\n",
    "            ngram_range=(3,6),\n",
    "            min_df=0.05,\n",
    "            max_df=0.95,\n",
    "            sublinear_tf=True,\n",
    ")\n",
    "\n",
    "train_tfid = vectorizer.fit_transform([i for i in train['full_text']])\n",
    "dense_matrix = train_tfid.toarray()\n",
    "df = pd.DataFrame(dense_matrix)\n",
    "tfid_columns = [ f'tfid_{i}' for i in range(len(df.columns))]\n",
    "df.columns = tfid_columns\n",
    "df['essay_id'] = train_feats['essay_id']\n",
    "train_feats = train_feats.merge(df, on='essay_id', how='left')\n",
    "feature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\n",
    "print('Number of Features: ',len(feature_names))\n",
    "train_feats.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a002fa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T06:21:57.314480Z",
     "iopub.status.busy": "2024-05-03T06:21:57.313584Z",
     "iopub.status.idle": "2024-05-03T06:23:18.100331Z",
     "shell.execute_reply": "2024-05-03T06:23:18.099143Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorizer_cnt = CountVectorizer(\n",
    "            tokenizer=lambda x: x,\n",
    "            preprocessor=lambda x: x,\n",
    "            token_pattern=None,\n",
    "            strip_accents='unicode',\n",
    "            analyzer = 'word',\n",
    "            ngram_range=(2,3),\n",
    "            min_df=0.10,\n",
    "            max_df=0.85,\n",
    ")\n",
    "train_tfid = vectorizer_cnt.fit_transform([i for i in train['full_text']])\n",
    "dense_matrix = train_tfid.toarray()\n",
    "df = pd.DataFrame(dense_matrix)\n",
    "tfid_columns = [ f'tfid_cnt_{i}' for i in range(len(df.columns))]\n",
    "df.columns = tfid_columns\n",
    "df['essay_id'] = train_feats['essay_id']\n",
    "train_feats = train_feats.merge(df, on='essay_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca1bc6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T06:23:18.140841Z",
     "iopub.status.busy": "2024-05-03T06:23:18.139912Z",
     "iopub.status.idle": "2024-05-03T06:23:18.250198Z",
     "shell.execute_reply": "2024-05-03T06:23:18.249023Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "deberta_oof = joblib.load('/kaggle/input/aes2-400-20240419134941/oof.pkl')\n",
    "print(deberta_oof.shape, train_feats.shape)\n",
    "\n",
    "for i in range(6):\n",
    "    train_feats[f'deberta_oof_{i}'] = deberta_oof[:, i]\n",
    "\n",
    "feature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\n",
    "print('Features Number: ',len(feature_names))    \n",
    "\n",
    "train_feats.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab346d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T06:23:18.285098Z",
     "iopub.status.busy": "2024-05-03T06:23:18.284219Z",
     "iopub.status.idle": "2024-05-03T06:23:18.297681Z",
     "shell.execute_reply": "2024-05-03T06:23:18.296676Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# idea from https://www.kaggle.com/code/rsakata/optimize-qwk-by-lgb/notebook#QWK-objective\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    if isinstance(y_pred, xgb.QuantileDMatrix):\n",
    "        # XGB\n",
    "        y_true, y_pred = y_pred, y_true\n",
    "\n",
    "        y_true = (y_true.get_label() + a).round()\n",
    "        y_pred = (y_pred + a).clip(1, 6).round()\n",
    "        qwk = cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n",
    "        return 'QWK', qwk\n",
    "\n",
    "    else:\n",
    "        # For lgb\n",
    "        y_true = y_true + a\n",
    "        y_pred = (y_pred + a).clip(1, 6).round()\n",
    "        qwk = cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n",
    "        return 'QWK', qwk, True\n",
    "def qwk_obj(y_true, y_pred):\n",
    "    labels = y_true + a\n",
    "    preds = y_pred + a\n",
    "    preds = preds.clip(1, 6)\n",
    "    f = 1/2*np.sum((preds-labels)**2)\n",
    "    g = 1/2*np.sum((preds-a)**2+b)\n",
    "    df = preds - labels\n",
    "    dg = preds - a\n",
    "    grad = (df/g - f*dg/g**2)*len(labels)\n",
    "    hess = np.ones(len(labels))\n",
    "    return grad, hess\n",
    "a = 2.998\n",
    "b = 1.092"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4725e907",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T06:23:18.332136Z",
     "iopub.status.busy": "2024-05-03T06:23:18.331077Z",
     "iopub.status.idle": "2024-05-03T06:23:18.343454Z",
     "shell.execute_reply": "2024-05-03T06:23:18.342561Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/kaggle/input/aes2-400-fes-202404291649/usefe_list.pkl', mode='br') as fi:\n",
    "  feature_names = pickle.load(fi)\n",
    "feature_select = feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07332eef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T06:23:18.374362Z",
     "iopub.status.busy": "2024-05-03T06:23:18.373551Z",
     "iopub.status.idle": "2024-05-03T06:23:19.535215Z",
     "shell.execute_reply": "2024-05-03T06:23:19.534326Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = train_feats[feature_names].astype(np.float32).values\n",
    "\n",
    "y_split = train[\"score\"].to_pandas().astype(int).values\n",
    "y = train[\"score\"].to_pandas().astype(np.float32).values-a\n",
    "oof = train[\"score\"].to_pandas().astype(int).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f2c844",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T06:23:19.566793Z",
     "iopub.status.busy": "2024-05-03T06:23:19.566417Z",
     "iopub.status.idle": "2024-05-03T06:26:12.759460Z",
     "shell.execute_reply": "2024-05-03T06:26:12.758140Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOAD = True # re-train\n",
    "# Define the number of splits for cross-validation\n",
    "# n_splits = 15\n",
    "n_splits = 16\n",
    "models = []\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "class Predictor:\n",
    "    def __init__(self, models: list):\n",
    "        self.models = models\n",
    "    def predict(self, X):\n",
    "        n_models = len(self.models)\n",
    "        predicted = None\n",
    "        for i, model in enumerate(self.models):\n",
    "            if i == 0:\n",
    "                predicted = 0.76*model.predict(X)\n",
    "            else:\n",
    "                predicted += 0.24*model.predict(X)\n",
    "        return predicted\n",
    "\n",
    "\n",
    "if not LOAD:\n",
    "    for i in range(n_splits):\n",
    "        models.append(lgb.Booster(model_file=f'/kaggle/input/aes-15fold/fold_{i+1}.txt'))\n",
    "else:\n",
    "    # Initialize StratifiedKFold with the specified number of splits\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "    # Lists to store scores\n",
    "    f1_scores = []\n",
    "    kappa_scores = []\n",
    "    models = []\n",
    "    predictions = []\n",
    "    callbacks = [log_evaluation(period=25), early_stopping(stopping_rounds=75,first_metric_only=True)]\n",
    "    # Loop through each fold of the cross-validation\n",
    "    i=1\n",
    "    for train_index, test_index in skf.split(X, y_split):\n",
    "        # Split the data into training and testing sets for this fold\n",
    "        print('fold',i)\n",
    "        X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
    "        y_train_fold, y_test_fold, y_test_fold_int = y[train_index], y[test_index], y_split[test_index]\n",
    "\n",
    "        light = lgb.LGBMRegressor(\n",
    "                    objective = qwk_obj,\n",
    "                    metrics = 'None',\n",
    "                    learning_rate = 0.05,\n",
    "                    max_depth = 8,\n",
    "                    num_leaves = 10,\n",
    "                    colsample_bytree=0.3,\n",
    "                    reg_alpha = 2.,\n",
    "                    reg_lambda = 0.1,\n",
    "                    n_estimators=700,\n",
    "                    random_state=42,\n",
    "                    extra_trees=True,\n",
    "                    class_weight='balanced',\n",
    "                    device='gpu' if CUDA_AVAILABLE else 'cpu',\n",
    "                    verbosity = - 1\n",
    "        )\n",
    "\n",
    "        # Fit the model on the training data for this fold  \n",
    "        light.fit(X_train_fold,\n",
    "                              y_train_fold,\n",
    "                              eval_names=['train', 'valid'],\n",
    "                              eval_set=[(X_train_fold, y_train_fold), (X_test_fold, y_test_fold)],\n",
    "                              eval_metric=quadratic_weighted_kappa,\n",
    "                              callbacks=callbacks\n",
    "                             )\n",
    "        xgb_regressor = xgb.XGBRegressor(\n",
    "            objective = qwk_obj,\n",
    "            metrics = 'None',\n",
    "            learning_rate = 0.1,\n",
    "            max_depth = 8,\n",
    "            num_leaves = 10,\n",
    "            colsample_bytree=0.5,\n",
    "            reg_alpha = 1.0,\n",
    "            reg_lambda = 0.1,\n",
    "            n_estimators=1024,\n",
    "            random_state=42,\n",
    "            extra_trees=True,\n",
    "            class_weight='balanced',\n",
    "            tree_method=\"hist\",\n",
    "            device=\"gpu\" if CUDA_AVAILABLE else \"cpu\"\n",
    "        #             device='gpu',\n",
    "        #             verbosity = 1\n",
    "        )\n",
    "    \n",
    "        xgb_callbacks = [\n",
    "            xgb.callback.EvaluationMonitor(period=25),\n",
    "            xgb.callback.EarlyStopping(75, metric_name=\"QWK\", maximize=True, save_best=True)\n",
    "        ]\n",
    "        xgb_regressor.fit(\n",
    "            X_train_fold,\n",
    "            y_train_fold,\n",
    "            eval_set=[(X_train_fold, y_train_fold), (X_test_fold, y_test_fold)],\n",
    "            eval_metric=quadratic_weighted_kappa,\n",
    "            callbacks=xgb_callbacks\n",
    "        )\n",
    "        predictor = Predictor([light, xgb_regressor])\n",
    "        # predictor = lgb_regressor.fit(X_train_fold, y_train_fold)\n",
    "        #predictor = xgb_regressor.fit(X_train_fold, y_train_fold)\n",
    "        models.append(predictor)\n",
    "        # Make predictions on the test data for this fold\n",
    "        predictions_fold = predictor.predict(X_test_fold)\n",
    "        predictions_fold = predictions_fold + a\n",
    "        predictions_fold = predictions_fold.clip(1, 6).round()\n",
    "        predictions.append(predictions_fold)\n",
    "        # Calculate and store the F1 score for this fold\n",
    "        f1_fold = f1_score(y_test_fold_int, predictions_fold, average='weighted')\n",
    "        f1_scores.append(f1_fold)\n",
    "\n",
    "        # Calculate and store the Cohen's kappa score for this fold\n",
    "        kappa_fold = cohen_kappa_score(y_test_fold_int, predictions_fold, weights='quadratic')\n",
    "        kappa_scores.append(kappa_fold)\n",
    "#         predictor.booster_.save_model(f'fold_{i}.txt')\n",
    "\n",
    "        print(f'F1 score across fold: {f1_fold}')\n",
    "        print(f'Cohen kappa score across fold: {kappa_fold}')\n",
    "        i+=1\n",
    "        gc.collect()\n",
    "        if ENABLE_DONT_WASTE_YOUR_RUN_TIME:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c85162b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T06:26:12.822000Z",
     "iopub.status.busy": "2024-05-03T06:26:12.821204Z",
     "iopub.status.idle": "2024-05-03T06:26:13.476810Z",
     "shell.execute_reply": "2024-05-03T06:26:13.475663Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp = Paragraph_Preprocess(test)\n",
    "test_feats = Paragraph_Eng(tmp)\n",
    "# Sentence\n",
    "tmp = Sentence_Preprocess(test)\n",
    "test_feats = test_feats.merge(Sentence_Eng(tmp), on='essay_id', how='left')\n",
    "# Word\n",
    "tmp = Word_Preprocess(test)\n",
    "test_feats = test_feats.merge(Word_Eng(tmp), on='essay_id', how='left')\n",
    "\n",
    "# Tfidf\n",
    "test_tfid = vectorizer.transform([i for i in test['full_text']])\n",
    "dense_matrix = test_tfid.toarray()\n",
    "df = pd.DataFrame(dense_matrix)\n",
    "tfid_columns = [ f'tfid_{i}' for i in range(len(df.columns))]\n",
    "df.columns = tfid_columns\n",
    "df['essay_id'] = test_feats['essay_id']\n",
    "test_feats = test_feats.merge(df, on='essay_id', how='left')\n",
    "\n",
    "# CountVectorizer\n",
    "test_tfid = vectorizer_cnt.transform([i for i in test['full_text']])\n",
    "dense_matrix = test_tfid.toarray()\n",
    "df = pd.DataFrame(dense_matrix)\n",
    "tfid_columns = [ f'tfid_cnt_{i}' for i in range(len(df.columns))]\n",
    "df.columns = tfid_columns\n",
    "df['essay_id'] = test_feats['essay_id']\n",
    "test_feats = test_feats.merge(df, on='essay_id', how='left')\n",
    "\n",
    "for i in range(6):\n",
    "    test_feats[f'deberta_oof_{i}'] = predicted_score[:, i]\n",
    "\n",
    "# Features number\n",
    "feature_names = list(filter(lambda x: x not in ['essay_id','score'], test_feats.columns))\n",
    "print('Features number: ',len(feature_names))\n",
    "test_feats.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c22a174",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T06:26:13.542004Z",
     "iopub.status.busy": "2024-05-03T06:26:13.541597Z",
     "iopub.status.idle": "2024-05-03T06:26:15.429014Z",
     "shell.execute_reply": "2024-05-03T06:26:15.427440Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "probabilities = []\n",
    "for model in models:\n",
    "    proba= model.predict(test_feats[feature_select])+ a\n",
    "    probabilities.append(proba)\n",
    "\n",
    "predictions = np.mean(probabilities, axis=0)\n",
    "\n",
    "predictions = np.round(predictions.clip(1, 6))\n",
    "\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaa1749",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T06:26:15.487484Z",
     "iopub.status.busy": "2024-05-03T06:26:15.486752Z",
     "iopub.status.idle": "2024-05-03T06:26:15.506914Z",
     "shell.execute_reply": "2024-05-03T06:26:15.505946Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission=pd.read_csv(\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/sample_submission.csv\")\n",
    "submission['score']=predictions\n",
    "submission['score']=submission['score'].astype(int)\n",
    "submission.to_csv(\"submission.csv\",index=None)\n",
    "display(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f90e92f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "#df1 = pd.read_csv('submission1.csv')\n",
    "#df2 = pd.read_csv('submission.csv')\n",
    "\n",
    "# # Merging the dataframes on 'essay_id'\n",
    "#df = pd.merge(left=df1, right=df2, on='essay_id', suffixes=('_1', '_2'))\n",
    "\n",
    "# # Calculating the average score directly without apply()\n",
    "#df['score'] = (df['score_1'] * 0.02 + df['score_2'] * 0.98).round().astype(int)\n",
    "\n",
    "# # Saving the desired columns to a new csv file\n",
    "#df[['essay_id', 'score']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1fb9b8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1533f971",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b81cca4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6119f315",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dce46e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17f61bb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a839c23",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7641c952",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f845b7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80519b96",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298e3148",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8059942,
     "sourceId": 71485,
     "sourceType": "competition"
    },
    {
     "datasetId": 4813598,
     "sourceId": 8141507,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4832208,
     "sourceId": 8166166,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4871040,
     "sourceId": 8217734,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4902588,
     "sourceId": 8260229,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 170434135,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 170531930,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 174935366,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 122.276566,
   "end_time": "2024-05-14T02:27:30.660955",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-14T02:25:28.384389",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01aa34af58e841fdaf95f8e49b36fb0d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "240384dd02de47ceac99043143779471": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "343dea38e1c54e11a5b78067e02f32e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "48092c17ba8544d7bb07f3d476bdbf50": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7ba933a9a75f4d2cb34fa25bd603ec1f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bc2a92fdb11d41e48c724da74da503ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c240299384464a9992e8993b016c5a8b",
       "placeholder": "​",
       "style": "IPY_MODEL_343dea38e1c54e11a5b78067e02f32e2",
       "value": "100%"
      }
     },
     "c240299384464a9992e8993b016c5a8b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e248f460f99342b08ff85d643ba955e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_240384dd02de47ceac99043143779471",
       "placeholder": "​",
       "style": "IPY_MODEL_48092c17ba8544d7bb07f3d476bdbf50",
       "value": " 3/3 [00:00&lt;00:00, 133.26ex/s]"
      }
     },
     "f5b40364b49740c7bcc613b52defcbc7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fd9a2e1a32eb4dce98a898df98c3e9f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f5b40364b49740c7bcc613b52defcbc7",
       "max": 3.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7ba933a9a75f4d2cb34fa25bd603ec1f",
       "value": 3.0
      }
     },
     "fefb9d16acf844778c489e143d2fff6e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bc2a92fdb11d41e48c724da74da503ce",
        "IPY_MODEL_fd9a2e1a32eb4dce98a898df98c3e9f6",
        "IPY_MODEL_e248f460f99342b08ff85d643ba955e5"
       ],
       "layout": "IPY_MODEL_01aa34af58e841fdaf95f8e49b36fb0d"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

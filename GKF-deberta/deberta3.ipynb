{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 10:23:23.653551: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-01 10:23:23.653622: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-01 10:23:23.655101: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-01 10:23:23.665391: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-01 10:23:24.641787: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # 指定使用 GPU 3\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # \"jax\" or \"tensorflow\" or \"torch\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras_nlp\n",
    "\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "#cmap = mpl.cm.get_cmap('coolwarm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.15.0\n",
      "Keras: 3.0.5\n",
      "KerasNLP: 0.8.2\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"Keras:\", keras.__version__)\n",
    "print(\"KerasNLP:\", keras_nlp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed = 42  # Random seed\n",
    "    preset = \"deberta_v3_extra_small_en\" # Name of pretrained models\n",
    "    sequence_length = 1024  # Input sequence length\n",
    "    epochs = 5 # Training epochs\n",
    "    batch_size = 32  # Batch size\n",
    "    scheduler = 'cosine'  # Learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(CFG.seed) ##每次的随机值相同，方便复现\n",
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "PATH = \"/home/mcq/GitHub/aes2/kaggle/input/learning-agency-lab-automated-essay-scoring-2/\"\n",
    "train = pd.read_csv(PATH + \"train.csv\")\n",
    "\n",
    "with open(\n",
    "    \"/home/mcq/GitHub/aes2/train_data/base_skf_feat/category-feat.pkl\", \"rb\"\n",
    ") as f:\n",
    "    topic = pickle.load(f)\n",
    "\n",
    "groups = topic['topic'] ### 这个groups是分类依据，原理是返回这个group对应的index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split  # Import package\n",
    "\n",
    "# train, valid = train_test_split(train, test_size=0.2, stratify= train['score'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_ordinal(y, num_classes=None, dtype=\"float32\"):\n",
    "    \"\"\"\n",
    "    评分值编码\n",
    "    \"\"\"\n",
    "    y = np.array(y, dtype=\"int\")\n",
    "    input_shape = y.shape\n",
    "\n",
    "    # Shrink the last dimension if the shape is (..., 1).\n",
    "    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n",
    "        input_shape = tuple(input_shape[:-1])\n",
    "\n",
    "    y = y.reshape(-1)\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    n = y.shape[0]\n",
    "    range_values = np.arange(num_classes - 1)\n",
    "    range_values = np.tile(np.expand_dims(range_values, 0), [n, 1])\n",
    "    ordinal = np.zeros((n, num_classes - 1), dtype=dtype)\n",
    "    ordinal[range_values < np.expand_dims(y, -1)] = 1\n",
    "    output_shape = input_shape + (num_classes - 1,)\n",
    "    ordinal = np.reshape(ordinal, output_shape)\n",
    "    return ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = keras_nlp.models.DebertaV3Preprocessor.from_preset(\n",
    "    preset=CFG.preset, # Name of the model\n",
    "    sequence_length=CFG.sequence_length, # Max sequence length, will be padded if shorter\n",
    ")\n",
    "\n",
    "def preprocess_fn(text, label=None):\n",
    "    text = preprocessor(text)  # Preprocess text\n",
    "    return (text, label) if label is not None else text  # Return processed text and label if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(texts, labels=None, batch_size=32,\n",
    "                  cache=True, drop_remainder=True,\n",
    "                  shuffle=1024):\n",
    "    AUTO = tf.data.AUTOTUNE  # AUTOTUNE option\n",
    "    slices = (texts,) if labels is None else (texts, labels)  # Create slices\n",
    "    ds = tf.data.Dataset.from_tensor_slices(slices)  # Create dataset from slices\n",
    "    ds = ds.cache() if cache else ds  # Cache dataset if enabled\n",
    "    ds = ds.map(preprocess_fn, num_parallel_calls=AUTO)  # 针对数据集做预处理\n",
    "    opt = tf.data.Options()  # Create dataset options\n",
    "    if shuffle: \n",
    "        ds = ds.shuffle(shuffle, seed=CFG.seed)  # Shuffle dataset if enabled\n",
    "        opt.experimental_deterministic = False\n",
    "    ds = ds.with_options(opt)  # Set dataset options\n",
    "    ds = ds.batch(batch_size, drop_remainder=drop_remainder)  # Batch dataset\n",
    "    ds = ds.prefetch(AUTO)  # Prefetch next batch\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_lr_callback(batch_size=8, mode='cos', epochs=10, plot=False):\n",
    "    lr_start, lr_max, lr_min = 0.6e-5, 0.3e-5 * batch_size, 0.3e-5\n",
    "    lr_ramp_ep, lr_sus_ep, lr_decay = 2, 0, 0.75\n",
    "\n",
    "    def lrfn(epoch):  # Learning rate update function\n",
    "        if epoch < lr_ramp_ep: lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep: lr = lr_max\n",
    "        elif mode == 'exp': lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "        elif mode == 'step': lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)\n",
    "        elif mode == 'cos':\n",
    "            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep + 3, epoch - lr_ramp_ep - lr_sus_ep\n",
    "            phase = math.pi * decay_epoch_index / decay_total_epochs\n",
    "            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n",
    "        return lr\n",
    "\n",
    "    # if plot:  # Plot lr curve if plot is True\n",
    "    #     plt.figure(figsize=(10, 5))\n",
    "    #     plt.plot(np.arange(epochs), [lrfn(epoch) for epoch in np.arange(epochs)], marker='o')\n",
    "    #     plt.xlabel('epoch'); plt.ylabel('lr')\n",
    "    #     plt.title('LR Scheduler')\n",
    "    #     plt.show()\n",
    "\n",
    "    return keras.callbacks.LearningRateScheduler(lrfn, verbose=False)  # Create lr callback\n",
    "\n",
    "lr_cb = get_lr_callback(CFG.batch_size, plot=True)\n",
    "\n",
    "ckpt_cb = keras.callbacks.ModelCheckpoint(\n",
    "    \"best_model.weights.h5\",\n",
    "    monitor=\"val_weighted_kappa\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode=\"max\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedKappa(keras.metrics.Metric):\n",
    "    def __init__(self, num_classes=6, epsilon=1e-6):\n",
    "        super().__init__(name=\"weighted_kappa\")\n",
    "        self.num_classes = num_classes\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        label_vec = keras.ops.arange(num_classes, dtype=keras.backend.floatx())\n",
    "        self.row_label_vec = keras.ops.reshape(label_vec, [1, num_classes])\n",
    "        self.col_label_vec = keras.ops.reshape(label_vec, [num_classes, 1])\n",
    "        col_mat = keras.ops.tile(self.col_label_vec, [1, num_classes])\n",
    "        row_mat = keras.ops.tile(self.row_label_vec, [num_classes, 1])\n",
    "        self.weight_mat = (col_mat - row_mat) ** 2\n",
    "\n",
    "        self.numerator = self.add_weight(name=\"numerator\", initializer=\"zeros\")\n",
    "        self.denominator = self.add_weight(name=\"denominator\", initializer=\"zeros\")\n",
    "\n",
    "        # +++\n",
    "        self.o_sum = self.add_weight(name = 'o_sum', initializer = 'zeros')\n",
    "        self.e_sum = self.add_weight(name = 'e_sum', initializer = 'zeros')\n",
    "        # +++\n",
    "\n",
    "    def update_state(self, y_true, y_pred, **args):\n",
    "        # revert ordinal regression labels to classification labels\n",
    "        ## 只在这里做了修改\n",
    "        y_true = keras.ops.one_hot(keras.ops.sum(y_true, axis=-1) - 1, 6)\n",
    "        y_pred = keras.ops.one_hot(\n",
    "            keras.ops.sum(keras.ops.cast(y_pred > 0.5, dtype=\"int8\"), axis=-1) - 1, 6\n",
    "        )\n",
    "        # weighted kappa calculation\n",
    "        y_true = keras.ops.cast(y_true, dtype=self.col_label_vec.dtype)\n",
    "        y_pred = keras.ops.cast(y_pred, dtype=self.weight_mat.dtype)\n",
    "        batch_size = keras.ops.shape(y_true)[0]\n",
    "\n",
    "        cat_labels = keras.ops.matmul(y_true, self.col_label_vec)\n",
    "        cat_label_mat = keras.ops.tile(cat_labels, [1, self.num_classes])\n",
    "        row_label_mat = keras.ops.tile(self.row_label_vec, [batch_size, 1])\n",
    "\n",
    "        weight = (cat_label_mat - row_label_mat) ** 2\n",
    "\n",
    "        self.numerator.assign_add(keras.ops.sum(weight * y_pred))\n",
    "        label_dist = keras.ops.sum(y_true, axis=0, keepdims=True)\n",
    "        pred_dist = keras.ops.sum(y_pred, axis=0, keepdims=True)\n",
    "        w_pred_dist = keras.ops.matmul(\n",
    "            self.weight_mat, keras.ops.transpose(pred_dist, [1, 0])\n",
    "        )\n",
    "        self.denominator.assign_add(\n",
    "            keras.ops.sum(keras.ops.matmul(label_dist, w_pred_dist))\n",
    "        )\n",
    "\n",
    "        # +++\n",
    "        self.o_sum.assign_add(keras.ops.sum(y_pred))\n",
    "        self.e_sum.assign_add(keras.ops.sum(\n",
    "            keras.ops.matmul(keras.ops.transpose(label_dist, [1, 0]), pred_dist)\n",
    "        ))\n",
    "        # +++\n",
    "\n",
    "    def result(self):\n",
    "        # ---\n",
    "        # return 1.0 - keras.ops.divide_no_nan(self.numerator, self.denominator)\n",
    "        # ---\n",
    "        # +++\n",
    "        return 1.0 - (\n",
    "            keras.ops.divide_no_nan(self.numerator, self.denominator)\n",
    "            * keras.ops.divide_no_nan(self.e_sum, self.o_sum)\n",
    "        )\n",
    "        # +++\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.numerator.assign(0)\n",
    "        self.denominator.assign(0)\n",
    "\n",
    "        # +++\n",
    "        self.o_sum.assign(0)\n",
    "        self.e_sum.assign(0)\n",
    "        # +++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ token_ids           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ deberta_v3_classif… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">70,832,262</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DebertaV3Classifi…</span> │                   │            │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ deberta_v3_class… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ token_ids           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ deberta_v3_classif… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │ \u001b[38;5;34m70,832,262\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDebertaV3Classifi…\u001b[0m │                   │            │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ deberta_v3_class… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,832,262</span> (270.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m70,832,262\u001b[0m (270.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,832,262</span> (270.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m70,832,262\u001b[0m (270.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DebertaV3Classifier model\n",
    "classifier = keras_nlp.models.DebertaV3Classifier.from_preset(\n",
    "    CFG.preset, preprocessor=None, num_classes=6\n",
    ")\n",
    "inputs = classifier.input\n",
    "logits = classifier(inputs)\n",
    "\n",
    "# Compute final output\n",
    "outputs = keras.layers.Activation(\"sigmoid\")(logits)\n",
    "\n",
    "# Build Model\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model with optimizer, loss, and metrics\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(5e-6),\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\n",
    "        WeightedKappa()\n",
    "    ],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_split= train['score'].astype(np.float32).values\n",
    "X= train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 增加了一列fold\n",
    "from sklearn.model_selection import GroupKFold\n",
    "train[\"fold\"] = None\n",
    "group_kfold = GroupKFold(n_splits=7)\n",
    "folds = list(group_kfold.split(X, y_split, groups))\n",
    "for fold_idx, (_, val_idx) in enumerate(folds):\n",
    "    train.loc[val_idx, \"fold\"] = fold_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = build_dataset(\n",
    "    train_texts, train_labels, batch_size=CFG.batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "train_ds_1 = Dataset.from_pandas(train)\n",
    "\n",
    "train_texts = train['full_text']  # Extract training texts\n",
    "train_labels = np.array(train['score']) # Extract training labels\n",
    "train_ds = build_dataset(\n",
    "    train_texts, train_labels, batch_size=CFG.batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_PrefetchDataset' object has no attribute 'select'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold_idx \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39munique(train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m#args.output_dir = os.path.join(\"output\", f\"fold_{fold_idx}\")\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     train_ds \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m([i \u001b[38;5;28;01mfor\u001b[39;00m i, f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_ds_1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;241m!=\u001b[39m fold_idx])\n\u001b[1;32m      4\u001b[0m     eval_ds \u001b[38;5;241m=\u001b[39m train_ds\u001b[38;5;241m.\u001b[39mselect([i \u001b[38;5;28;01mfor\u001b[39;00m i, f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_ds_1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;241m==\u001b[39m fold_idx])\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Start training the model\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_PrefetchDataset' object has no attribute 'select'"
     ]
    }
   ],
   "source": [
    "for fold_idx in np.unique(train[\"fold\"]):\n",
    "    #args.output_dir = os.path.join(\"output\", f\"fold_{fold_idx}\")\n",
    "    train_ds = train_ds.select([i for i, f in enumerate(train_ds_1[\"fold\"]) if f != fold_idx])\n",
    "    eval_ds = train_ds.select([i for i, f in enumerate(train_ds_1[\"fold\"]) if f == fold_idx])\n",
    "    \n",
    "    # Start training the model\n",
    "    history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=CFG.epochs,\n",
    "    validation_data=eval_ds,\n",
    "    callbacks=[lr_cb, ckpt_cb]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

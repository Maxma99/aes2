{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"  # 指定使用 GPU 3\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizers.__version__: 0.19.1\n",
      "transformers.__version__: 4.41.1\n",
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import ast\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import keras\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import tokenizers\n",
    "import transformers\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification, BertForSequenceClassification\n",
    "%env TOKENIZERS_PARALLELISM=false\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification, \n",
    "    Trainer, \n",
    "    TrainingArguments, \n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import Dataset\n",
    "from glob import glob\n",
    "import gc\n",
    "import torch\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "with open('kaggle/input/english-word-hx/words.txt', 'r') as file:\n",
    "    english_vocab = set(word.strip().lower() for word in file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据load和处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keras.utils.set_random_seed(42) ##每次的随机值相同，方便复现\n",
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "columns = [  \n",
    "    (\n",
    "        pl.col(\"full_text\").str.split(by=\"\\n\\n\").alias(\"paragraph\")\n",
    "    ),\n",
    "]\n",
    "PATH = \"kaggle/input/learning-agency-lab-automated-essay-scoring-2/\"\n",
    "TEST_DATA_PATH = \"kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv\"\n",
    "MAX_LENGTH = 1024\n",
    "EVAL_BATCH_SIZE = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 添加模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directlyfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"addy88/argument-classifier\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"addy88/argument-classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/home/mcq2/GitHub/aes2/kaggle/input/learning-agency-lab-automated-essay-scoring-2/'\n",
    "\n",
    "train = pl.read_csv(PATH + \"train.csv\").with_columns(columns) \n",
    "test = pl.read_csv(PATH + \"test.csv\").with_columns(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 小型预处理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(tmp):   \n",
    "    tmp = tmp.with_columns(pl.col('full_text').str.slice(0, 513).alias\n",
    "    (\"cut\"))\n",
    "    return tmp\n",
    "\n",
    "test = cut(test)\n",
    "\n",
    "df =pd.DataFrame({ \"cut\": test['cut']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    \".\", \n",
    "    per_device_eval_batch_size=1, \n",
    "    report_to=\"none\"\n",
    "    \n",
    ")\n",
    "def tokenize(sample):\n",
    "    return tokenizer(sample['cut'], max_length=MAX_LENGTH, truncation=True)\n",
    "\n",
    "trainer = Trainer(\n",
    "        model=model, \n",
    "        args=args, \n",
    "        data_collator=DataCollatorWithPadding(tokenizer), \n",
    "        tokenizer=tokenizer\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d96a99a72e34a29b071a09e952253ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = Dataset.from_pandas(df).map(tokenize).remove_columns(['cut'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/3 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = trainer.predict(ds).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "predictions.append(softmax(preds, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.184659  , 0.815341  ],\n",
      "       [0.86983293, 0.13016711],\n",
      "       [0.12448   , 0.87552005]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deberta_oof = joblib.load('/kaggle/input/aes2-400-20240419134941/oof.pkl')\n",
    "print(deberta_oof.shape, train_feats.shape)\n",
    "\n",
    "for i in range(6):\n",
    "    train_feats[f'deberta_oof_{i}'] = deberta_oof[:, i]\n",
    "\n",
    "feature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\n",
    "print('Features Number: ', len(feature_names)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df['full_text'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.cfg, self.texts[item])\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sample):\n",
    "    return tokenizer(sample['full_text'], max_length=MAX_LENGTH, truncation=True)\n",
    "\n",
    "df_test = pd.read_csv(TEST_DATA_PATH)\n",
    "ds = Dataset.from_pandas(df_test).map(tokenize).remove_columns(['essay_id', 'full_text'])\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \".\", \n",
    "    per_device_eval_batch_size=EVAL_BATCH_SIZE, \n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "predictions = []\n",
    "for model in models:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model)\n",
    "    trainer = Trainer(\n",
    "        model=model, \n",
    "        args=args, \n",
    "        data_collator=DataCollatorWithPadding(tokenizer), \n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "    \n",
    "    preds = trainer.tokenizer.predict(ds).predictions\n",
    "    predictions.append(softmax(preds, axis=-1))  #predictions.append(...) 将转换后的概率分布添加到 predictions 列表中，用于进一步处理或评估。\n",
    "    del model, trainer\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "# predicted_score = 0.\n",
    "\n",
    "# for p in predictions:\n",
    "#     predicted_score += p\n",
    "    \n",
    "# predicted_score /= len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = trainer.predict(ds).predictions\n",
    "\n",
    "def predict_chunk(test: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        submission = pd.DataFrame(np.ones((len(test), 2)))\n",
    "        submission.columns = ['text_id', 'score_cut']\n",
    "        submission[\"text_id\"] = test[\"text_id\"]\n",
    "        # print(test[\"text_id\"].head(5))\n",
    "        # print(submission[\"text_id\"].head(5))\n",
    "        # sort by length to speed up inference\n",
    "        test['tokenize_length'] = [len(tokenizer(text)['input_ids']) for text in test['full_text'].values]\n",
    "        test = test.sort_values('tokenize_length', ascending=True).reset_index(drop=True)\n",
    "\n",
    "        # test_dataset = TestDataset(CFG, test)\n",
    "        # test_loader = DataLoader(test_dataset,\n",
    "        #                          batch_size=CFG.batch_size,\n",
    "        #                          shuffle=False,\n",
    "        #                          collate_fn=DataCollatorWithPadding(tokenizer=CFG.tokenizer, padding='longest'),\n",
    "        #                          num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "        predictions = []\n",
    "\n",
    "        \n",
    "        #model.load_state_dict(state['model'], strict=False)\n",
    "        for i in \n",
    "        prediction = trainer.predict(ds).predictions\n",
    "\n",
    "        predictions.append(prediction)\n",
    "        # del model, state, prediction; \n",
    "        # gc.collect()\n",
    "        # torch.cuda.empty_cache()\n",
    "\n",
    "        #predictions = np.mean(predictions, axis=0)\n",
    "\n",
    "        ## 把prediction 放在test的一个列里\n",
    "        test['score_cut'] = predictions\n",
    "\n",
    "\n",
    "        submission = submission.drop(['score_cut']).merge(test[['text_id'] + ['score_cut']], on='text_id', how='left')\n",
    "#         display(submission.head())\n",
    "        submission[['text_id'] + ['score_cut']].to_csv(f'submission.csv', index=False)\n",
    "        #torch.cuda.empty_cache()\n",
    "        #gc.collect()\n",
    "        return submission\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test = pd.read_csv(\n",
    "            '/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv'\n",
    "    ).rename(columns={\"essay_id\": \"text_id\"})\n",
    "    submission = predict(test)\n",
    "    submission.to_csv(f'submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset['train'],\n",
    "    eval_dataset=encoded_dataset['test']\n",
    ")\n",
    "\n",
    "# Train and evaluate\n",
    "trainer.train()\n",
    "trainer.evaluate()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"fine-tuned-model\")\n",
    "\n",
    "\n",
    "model = lgb.LGBMRegressor(\n",
    "                    objective = qwk_obj,\n",
    "                    metrics = 'None',\n",
    "                    learning_rate = 0.05,\n",
    "                    max_depth = 5,\n",
    "                    num_leaves = 10,\n",
    "                    colsample_bytree=0.3,\n",
    "                    reg_alpha = 0.7,\n",
    "                    reg_lambda = 0.1,\n",
    "                    n_estimators=700,\n",
    "                    random_state=412,\n",
    "                    extra_trees=True,\n",
    "                    class_weight='balanced',\n",
    "                    verbosity = - 1)\n",
    "\n",
    "        predictor = model.fit(X_train_fold,\n",
    "                              y_train_fold,\n",
    "                              eval_names=['train', 'valid'],\n",
    "                              eval_set=[(X_train_fold, y_train_fold), (X_test_fold, y_test_fold)],\n",
    "                              eval_metric=quadratic_weighted_kappa,\n",
    "                              callbacks=callbacks)\n",
    "        models.append(predictor)\n",
    "        predictions_fold = predictor.predict(X_test_fold)\n",
    "        predictions_fold = predictions_fold + a\n",
    "        predictions_fold = predictions_fold.clip(1, 6).round()\n",
    "        predictions.append(predictions_fold)\n",
    "        f1_fold = f1_score(y_test_fold_int, predictions_fold, average='weighted')\n",
    "        f1_scores.append(f1_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fb3_deberta_family_inference_9_28_updated\n",
    "\n",
    "if len(df_test) < 10:\n",
    "    fb3_predicted = fb3_deberta_family_inference_9_28_updated.predict_chunk(\n",
    "        df_test.rename(columns={\"essay_id\": \"text_id\"})\n",
    "    )\n",
    "else:\n",
    "    fb3_predicted = fb3_deberta_family_inference_9_28_updated.predict(\n",
    "        df_test.rename(columns={\"essay_id\": \"text_id\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

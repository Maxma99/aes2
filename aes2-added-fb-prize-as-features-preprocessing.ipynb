{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7495491",
   "metadata": {
    "_cell_guid": "93791fbe-0e54-4418-9ca5-645f547416ff",
    "_uuid": "6a1368c0-cd07-40cc-abb8-b0bd5628379e",
    "papermill": {
     "duration": 0.011909,
     "end_time": "2024-06-12T20:09:34.060455",
     "exception": false,
     "start_time": "2024-06-12T20:09:34.048546",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "https://www.kaggle.com/datasets/cdeotte/deberta-v3-small-finetuned-v1## ℹ️ Info\n",
    "\n",
    "| Method | LB |\n",
    "| --- | :---: |\n",
    "| LGBM 5 fold | 0.801 |\n",
    "| LGBM 15 fold | 0.802 |\n",
    "| LGBM 15 fold + post-processing | 0.803 |\n",
    "| LGBM 15 fold + 5 fold Deberta (Ensemble) | 0.807 |\n",
    "| LGBM 16 fold + 5 fold Deberta (Ensemble) | 0.808 |\n",
    "| LGBM 15 fold + 5 fold Deberta (Ensemble) + CountVectorizer | 0.810 |\n",
    "| LGBM 15 fold + 5 fold Deberta (as features) + CountVectorizer | 0.811 |\n",
    "| LGBM 16 fold + 5 fold Deberta (as features) + CountVectorizer + HashingVectorizer | 0.811 |\n",
    "| LGBM 15 fold + 5 fold Deberta (as features) + TfidfVectorizer(ngram(3,6)) + CountVectorizer | 0.812 |\n",
    "| LGBM 15 fold + (new)5 fold Deberta (as features) + TfidfVectorizer(ngram(3,6)) + CountVectorizer(ngram(3,5)) | 0.816 |\n",
    "| LGBM 15 fold + (new)5 fold Deberta (as features) + TfidfVectorizer(ngram(3,6)) + CountVectorizer(ngram(3,4)) | 0.817 |\n",
    "| LGBM 15 fold + (new)5 fold Deberta (as features) + more feature engineering + feature selection | 0.817 |\n",
    "\n",
    "\n",
    "* 2024/04/15 : forked original great work kernels\n",
    "    * https://www.kaggle.com/code/olyatsimboy/5-fold-deberta-lgbm\n",
    "    * https://www.kaggle.com/code/aikhmelnytskyy/quick-start-lgbm\n",
    "    * https://www.kaggle.com/code/hideyukizushi/aes2-5folddeberta-lgbm-countvectorizer-lb-810\n",
    "    * https://www.kaggle.com/code/olyatsimboy/81-1-aes2-5folddeberta-lgbm-stacking  \n",
    "    \n",
    "    \n",
    "* 2024/04/16 : ~~add HashingVectorizer~~ (not work)\n",
    "* 2024/04/21 : Add MetaFEs. Train deberta-v3-large local (5Fold SKF) : https://www.kaggle.com/datasets/hideyukizushi/aes2-400-20240419134941    \n",
    "* 2024/04/22 : change TfidfVectorizer ngram to (3,6), CountVectorizer ngram to (3,5)\n",
    "* 2024/04/23 : change CountVectorizer ngram to (3,4)\n",
    "* 2024/04/24 : MORE FEATURE ENGINEERING + FEATURE SELECTION : https://www.kaggle.com/code/xianhellg/more-feature-engineering-feature-selection-0-817\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01b4657e",
   "metadata": {
    "_cell_guid": "39ea00e9-fa5f-4cda-b826-bc63e1f1b389",
    "_uuid": "cfa25779-6ecb-4dca-8128-361083aab4ef",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T20:09:34.084914Z",
     "iopub.status.busy": "2024-06-12T20:09:34.084542Z",
     "iopub.status.idle": "2024-06-12T20:09:38.771373Z",
     "shell.execute_reply": "2024-06-12T20:09:38.770334Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 4.701451,
     "end_time": "2024-06-12T20:09:38.773520",
     "exception": false,
     "start_time": "2024-06-12T20:09:34.072069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_AVAILABLE = True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "import pickle\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5,6,7,8\" \n",
    "sys.path.append('/home/mcq/GitHub/aes2')\n",
    "sys.path.append('/home/mcq/GitHub/aes2/topic-classificatio')\n",
    "# import add_2_features\n",
    "_test = pd.read_csv(\"/home/mcq/GitHub/aes2/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv\")\n",
    "# ENABLE_DONT_WASTE_YOUR_RUN_TIME = len(_test) < 10\n",
    "ENABLE_DONT_WASTE_YOUR_RUN_TIME = False\n",
    "if ENABLE_DONT_WASTE_YOUR_RUN_TIME:\n",
    "    import shutil\n",
    "\n",
    "#     shutil.copyfile(\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/sample_submission.csv\", \"submission.csv\")\n",
    "#     exit(0)\n",
    "    del _test\n",
    "    gc.collect()\n",
    "\n",
    "import torch\n",
    "CUDA_AVAILABLE = torch.cuda.is_available()\n",
    "print(f\"{CUDA_AVAILABLE = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c178a6d",
   "metadata": {
    "_cell_guid": "38da6f04-c177-43c8-abf3-705e1075fbee",
    "_uuid": "d0fbe785-ae3f-467b-baf4-ae291566226e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T20:09:38.797659Z",
     "iopub.status.busy": "2024-06-12T20:09:38.797097Z",
     "iopub.status.idle": "2024-06-12T20:09:38.801175Z",
     "shell.execute_reply": "2024-06-12T20:09:38.800328Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.018139,
     "end_time": "2024-06-12T20:09:38.803074",
     "exception": false,
     "start_time": "2024-06-12T20:09:38.784935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !cp /kaggle/input/learning-agency-lab-automated-essay-scoring-2/sample_submission.csv submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba189c80",
   "metadata": {
    "_cell_guid": "a4e1a7ed-69d4-46ca-b44c-d731e06490eb",
    "_uuid": "77c003d4-4dd3-4425-811f-4342a0c97436",
    "papermill": {
     "duration": 0.010944,
     "end_time": "2024-06-12T20:09:38.825419",
     "exception": false,
     "start_time": "2024-06-12T20:09:38.814475",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"color:white;display:fill;border-radius:5px;background-color:seaGreen;text-align:center;letter-spacing:0.1px;overflow:hidden;padding:20px;color:white;overflow:hidden;margin:0;font-size:100%\">▶️ 5 Fold Deberta ◀️</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab31d3e3",
   "metadata": {
    "_cell_guid": "e12174c9-2442-4e15-9f5c-64eae94c1c11",
    "_uuid": "dba95b2d-7c6c-460d-a2d4-2cf1b4f34175",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.010861,
     "end_time": "2024-06-12T20:09:38.870968",
     "exception": false,
     "start_time": "2024-06-12T20:09:38.860107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fb_oof = pd.read_csv(\"/home/mcq/GitHub/aes2/submission_1.csv\")\n",
    "# fb_oof.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "419e4e89",
   "metadata": {
    "_cell_guid": "a9d7b7a4-5a2e-4988-b77f-d35d47f8274b",
    "_uuid": "386d6966-0a46-4430-a839-5ca35108a1b5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T20:09:38.895230Z",
     "iopub.status.busy": "2024-06-12T20:09:38.894523Z",
     "iopub.status.idle": "2024-06-12T20:09:54.557883Z",
     "shell.execute_reply": "2024-06-12T20:09:54.557019Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 15.678019,
     "end_time": "2024-06-12T20:09:54.560169",
     "exception": false,
     "start_time": "2024-06-12T20:09:38.882150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd \n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification, \n",
    "    Trainer, \n",
    "    TrainingArguments, \n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import Dataset\n",
    "from glob import glob\n",
    "import gc\n",
    "import torch\n",
    "from scipy.special import softmax\n",
    "\n",
    "MAX_LENGTH = 1024\n",
    "TEST_DATA_PATH = \"/home/mcq/GitHub/aes2/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv\"\n",
    "MODEL_PATH = '/home/mcq/GitHub/aes2/kaggle/input/aes2-400-20240419134941/*/*'\n",
    "EVAL_BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dff748",
   "metadata": {
    "_cell_guid": "d740b6a0-5cc1-44b3-9c46-f72e97030a8b",
    "_uuid": "74e7c8f3-a760-48a7-8598-4ca0eb5affa5",
    "papermill": {
     "duration": 0.011205,
     "end_time": "2024-06-12T20:09:54.583084",
     "exception": false,
     "start_time": "2024-06-12T20:09:54.571879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Deberta Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7889875",
   "metadata": {
    "_cell_guid": "189aa061-7a12-4c4e-8bde-fd4bf6f67b31",
    "_uuid": "b74ca64f-e4cf-441b-a861-a99df5569753",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T20:09:54.607920Z",
     "iopub.status.busy": "2024-06-12T20:09:54.607227Z",
     "iopub.status.idle": "2024-06-12T20:09:54.617502Z",
     "shell.execute_reply": "2024-06-12T20:09:54.616590Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.024934,
     "end_time": "2024-06-12T20:09:54.619441",
     "exception": false,
     "start_time": "2024-06-12T20:09:54.594507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_deberta_predicted_score(df_test = None):\n",
    "    models = glob(MODEL_PATH)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(models[0])\n",
    "\n",
    "    def tokenize(sample):\n",
    "        return tokenizer(sample['full_text'], max_length=MAX_LENGTH, truncation=True)\n",
    "    if df_test is None:\n",
    "        df_test = pd.read_csv(TEST_DATA_PATH)\n",
    "    ds = Dataset.from_pandas(df_test).map(tokenize).remove_columns(['essay_id', 'full_text'])\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        \".\", \n",
    "        per_device_eval_batch_size=EVAL_BATCH_SIZE, \n",
    "        report_to=\"none\"\n",
    "    )\n",
    "\n",
    "    predictions = []\n",
    "    for model in models:\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model)\n",
    "        trainer = Trainer(\n",
    "            model=model, \n",
    "            args=args, \n",
    "            data_collator=DataCollatorWithPadding(tokenizer), \n",
    "            tokenizer=tokenizer\n",
    "        )\n",
    "\n",
    "        preds = trainer.predict(ds).predictions\n",
    "        predictions.append(softmax(preds, axis=-1))  \n",
    "        del model, trainer\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    predicted_score = 0.\n",
    "\n",
    "    for p in predictions:\n",
    "        predicted_score += p\n",
    "\n",
    "    predicted_score /= len(predictions)\n",
    "    df_test['score'] = predicted_score.argmax(-1) + 1\n",
    "    df_test.head()\n",
    "    df_test[['essay_id', 'score']].to_csv('submission1.csv', index=False)\n",
    "    return predicted_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ae3b17",
   "metadata": {
    "_cell_guid": "84bdfa63-abcf-40cc-87e0-9ebbc2d6289f",
    "_uuid": "dfba2296-658a-41de-8a6a-4f16c6fd4b91",
    "papermill": {
     "duration": 0.01167,
     "end_time": "2024-06-12T20:09:54.642553",
     "exception": false,
     "start_time": "2024-06-12T20:09:54.630883",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"color:white;display:fill;border-radius:5px;background-color:seaGreen;text-align:center;letter-spacing:0.1px;overflow:hidden;padding:20px;color:white;overflow:hidden;margin:0;font-size:100%\">▶️ Prize feedback ◀️</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b49edd6",
   "metadata": {
    "_cell_guid": "4d30470f-c00f-405e-b7b3-b9554d4c97a3",
    "_uuid": "499980b5-f145-4ab0-9eed-b4b8be1dd5ed",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T20:09:54.666566Z",
     "iopub.status.busy": "2024-06-12T20:09:54.666190Z",
     "iopub.status.idle": "2024-06-12T20:09:54.672190Z",
     "shell.execute_reply": "2024-06-12T20:09:54.671333Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.020292,
     "end_time": "2024-06-12T20:09:54.674142",
     "exception": false,
     "start_time": "2024-06-12T20:09:54.653850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_fb3_predicted(df_test = None):\n",
    "    import pandas as pd\n",
    "    import fb3_deberta_family_inference_9_28_updated\n",
    "\n",
    "    if df_test is None:\n",
    "        df_test = pd.read_csv(TEST_DATA_PATH)\n",
    "    if len(df_test) < 10:\n",
    "        fb3_predicted = fb3_deberta_family_inference_9_28_updated.predict_chunk(\n",
    "            df_test.rename(columns={\"essay_id\": \"text_id\"})\n",
    "        )\n",
    "    else:\n",
    "        fb3_predicted = fb3_deberta_family_inference_9_28_updated.predict(\n",
    "            df_test.rename(columns={\"essay_id\": \"text_id\"})\n",
    "        )\n",
    "    return fb3_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b8f1d9",
   "metadata": {
    "_cell_guid": "bba206a5-738d-4ad7-878d-21c25dc3238e",
    "_uuid": "961469ab-412b-4a26-92cb-ad0122ebe6fb",
    "papermill": {
     "duration": 0.011696,
     "end_time": "2024-06-12T20:09:54.697072",
     "exception": false,
     "start_time": "2024-06-12T20:09:54.685376",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"color:white;display:fill;border-radius:5px;background-color:seaGreen;text-align:center;letter-spacing:0.1px;overflow:hidden;padding:20px;color:white;overflow:hidden;margin:0;font-size:100%\">▶️ 15 fold LGBM ◀️</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7736143",
   "metadata": {
    "_cell_guid": "1471da00-2230-4578-917b-5c17335b6ae8",
    "_uuid": "091558bd-fc46-4b1b-b56e-82f1c5f4cb04",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T20:09:54.721986Z",
     "iopub.status.busy": "2024-06-12T20:09:54.721606Z",
     "iopub.status.idle": "2024-06-12T20:09:59.700669Z",
     "shell.execute_reply": "2024-06-12T20:09:59.699850Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 4.994328,
     "end_time": "2024-06-12T20:09:59.702972",
     "exception": false,
     "start_time": "2024-06-12T20:09:54.708644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re\n",
    "import spacy\n",
    "import string\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier,BaggingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from lightgbm import log_evaluation, early_stopping\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import polars as pl\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ffb46f",
   "metadata": {
    "_cell_guid": "6a62fa12-a90c-49cd-9635-ff92f8850359",
    "_uuid": "89158f98-4e81-4a3a-b1ec-3532a6a98c14",
    "papermill": {
     "duration": 0.012241,
     "end_time": "2024-06-12T20:09:59.728109",
     "exception": false,
     "start_time": "2024-06-12T20:09:59.715868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Features engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3338bf17",
   "metadata": {
    "_cell_guid": "8baf973d-b08a-4a08-bca1-71cad689acdd",
    "_uuid": "0b71eea3-35ea-441c-aa61-0fcdfd0cfee8",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T20:09:59.753117Z",
     "iopub.status.busy": "2024-06-12T20:09:59.752431Z",
     "iopub.status.idle": "2024-06-12T20:09:59.761506Z",
     "shell.execute_reply": "2024-06-12T20:09:59.760513Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.023618,
     "end_time": "2024-06-12T20:09:59.763417",
     "exception": false,
     "start_time": "2024-06-12T20:09:59.739799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_spelling_errors(text):\n",
    "    doc = nlp(text)\n",
    "    lemmatized_tokens = [token.lemma_.lower() for token in doc]\n",
    "    spelling_errors = sum(1 for token in lemmatized_tokens if token not in english_vocab)\n",
    "    return spelling_errors\n",
    "\n",
    "def removeHTML(x):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',x)\n",
    "def dataPreprocessing(x):\n",
    "    # Convert words to lowercase\n",
    "    x = x.lower()\n",
    "    # Remove HTML\n",
    "    x = removeHTML(x)\n",
    "    # Delete strings starting with @\n",
    "    x = re.sub(\"@\\w+\", '',x)\n",
    "    # Delete Numbers\n",
    "    x = re.sub(\"'\\d+\", '',x)\n",
    "    x = re.sub(\"\\d+\", '',x)\n",
    "    # Delete URL\n",
    "    x = re.sub(\"http\\w+\", '',x)\n",
    "    # Replace consecutive empty spaces with a single space character\n",
    "    x = re.sub(r\"\\s+\", \" \", x)\n",
    "    # Replace consecutive commas and periods with one comma and period character\n",
    "    x = re.sub(r\"\\.+\", \".\", x)\n",
    "    x = re.sub(r\"\\,+\", \",\", x)\n",
    "    # Remove empty characters at the beginning and end\n",
    "    x = x.strip()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce03318",
   "metadata": {
    "_cell_guid": "369e9275-25c5-43b2-9853-e489c5b306b9",
    "_uuid": "72674984-7482-4bb2-ae79-f204a2951109",
    "papermill": {
     "duration": 0.011209,
     "end_time": "2024-06-12T20:09:59.786179",
     "exception": false,
     "start_time": "2024-06-12T20:09:59.774970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Paragraph Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74aa94b7",
   "metadata": {
    "_cell_guid": "fdf24e8f-7e8f-4d8a-9f0d-4e808bd8b05d",
    "_uuid": "9cece4a5-82f9-44ac-ab4b-cdcfa922eeab",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T20:09:59.811174Z",
     "iopub.status.busy": "2024-06-12T20:09:59.810782Z",
     "iopub.status.idle": "2024-06-12T20:09:59.827981Z",
     "shell.execute_reply": "2024-06-12T20:09:59.827243Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.032012,
     "end_time": "2024-06-12T20:09:59.829855",
     "exception": false,
     "start_time": "2024-06-12T20:09:59.797843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# paragraph features\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"\n",
    "    Remove all punctuation from the input text.\n",
    "    \n",
    "    Args:\n",
    "    - text (str): The input text.\n",
    "    \n",
    "    Returns:\n",
    "    - str: The text with punctuation removed.\n",
    "    \"\"\"\n",
    "    # string.punctuation\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)\n",
    "\n",
    "def Paragraph_Preprocess(tmp):\n",
    "    # Expand the paragraph list into several lines of data\n",
    "    tmp = tmp.explode('paragraph')\n",
    "    # Paragraph preprocessing\n",
    "    tmp = tmp.with_columns(pl.col('paragraph').map_elements(dataPreprocessing))\n",
    "    tmp = tmp.with_columns(pl.col('paragraph').map_elements(remove_punctuation).alias('paragraph_no_pinctuation'))\n",
    "    tmp = tmp.with_columns(pl.col('paragraph_no_pinctuation').map_elements(count_spelling_errors).alias(\"paragraph_error_num\"))\n",
    "    # Calculate the length of each paragraph\n",
    "    tmp = tmp.with_columns(pl.col('paragraph').map_elements(lambda x: len(x)).alias(\"paragraph_len\"))\n",
    "    # Calculate the number of sentences and words in each paragraph\n",
    "    tmp = tmp.with_columns(pl.col('paragraph').map_elements(lambda x: len(x.split('.'))).alias(\"paragraph_sentence_cnt\"),\n",
    "                    pl.col('paragraph').map_elements(lambda x: len(x.split(' '))).alias(\"paragraph_word_cnt\"),)\n",
    "    return tmp\n",
    "# feature_eng\n",
    "\n",
    "def Paragraph_Eng(train_tmp):\n",
    "    num_list = [0, 50,75,100,125,150,175,200,250,300,350,400,500,600]\n",
    "    num_list2 = [0, 50,75,100,125,150,175,200,250,300,350,400,500,600,700]\n",
    "    aggs = [\n",
    "        # Count the number of paragraph lengths greater than and less than the i-value\n",
    "        *[pl.col('paragraph').filter(pl.col('paragraph_len') >= i).count().alias(f\"paragraph_{i}_cnt\") for i in [0, 50,75,100,125,150,175,200,250,300,350,400,500,600,700] ], \n",
    "        *[pl.col('paragraph').filter(pl.col('paragraph_len') <= i).count().alias(f\"paragraph_{i}_cnt\") for i in [25,49]], \n",
    "        # other\n",
    "        *[pl.col(fea).max().alias(f\"{fea}_max\") for fea in paragraph_fea2],\n",
    "        *[pl.col(fea).mean().alias(f\"{fea}_mean\") for fea in paragraph_fea2],\n",
    "        *[pl.col(fea).min().alias(f\"{fea}_min\") for fea in paragraph_fea2],\n",
    "        *[pl.col(fea).sum().alias(f\"{fea}_sum\") for fea in paragraph_fea2],\n",
    "        *[pl.col(fea).first().alias(f\"{fea}_first\") for fea in paragraph_fea2],\n",
    "        *[pl.col(fea).last().alias(f\"{fea}_last\") for fea in paragraph_fea2],\n",
    "        *[pl.col(fea).kurtosis().alias(f\"{fea}_kurtosis\") for fea in paragraph_fea2],\n",
    "        *[pl.col(fea).quantile(0.25).alias(f\"{fea}_q1\") for fea in paragraph_fea2],  \n",
    "        *[pl.col(fea).quantile(0.75).alias(f\"{fea}_q3\") for fea in paragraph_fea2],  \n",
    "        ]\n",
    "    \n",
    "    df = train_tmp.group_by(['essay_id'], maintain_order=True).agg(aggs).sort(\"essay_id\")\n",
    "    df = df.to_pandas()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda4d723",
   "metadata": {
    "_cell_guid": "4879356c-8a44-42c3-bcf0-75e8cce418bc",
    "_uuid": "36ec57e4-cc3a-4d02-8f82-645dd5c87d73",
    "papermill": {
     "duration": 0.011372,
     "end_time": "2024-06-12T20:09:59.852834",
     "exception": false,
     "start_time": "2024-06-12T20:09:59.841462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sentence Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f751417",
   "metadata": {
    "_cell_guid": "6f1b1cb3-7041-4d1a-898f-e0fd6fd4388a",
    "_uuid": "4fb7f742-7e19-423d-8e44-c159da04817a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T20:09:59.877755Z",
     "iopub.status.busy": "2024-06-12T20:09:59.877004Z",
     "iopub.status.idle": "2024-06-12T20:09:59.891015Z",
     "shell.execute_reply": "2024-06-12T20:09:59.890074Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.028817,
     "end_time": "2024-06-12T20:09:59.892994",
     "exception": false,
     "start_time": "2024-06-12T20:09:59.864177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sentence feature\n",
    "def Sentence_Preprocess(tmp):\n",
    "    # Preprocess full_text and use periods to segment sentences in the text\n",
    "    tmp = tmp.with_columns(pl.col('full_text').map_elements(dataPreprocessing).str.split(by=\".\").alias(\"sentence\"))\n",
    "    tmp = tmp.explode('sentence')\n",
    "    # Calculate the length of a sentence\n",
    "    tmp = tmp.with_columns(pl.col('sentence').map_elements(lambda x: len(x)).alias(\"sentence_len\"))\n",
    "    # Filter out the portion of data with a sentence length greater than 15\n",
    "    tmp = tmp.filter(pl.col('sentence_len')>=15)\n",
    "    # Count the number of words in each sentence\n",
    "    tmp = tmp.with_columns(pl.col('sentence').map_elements(lambda x: len(x.split(' '))).alias(\"sentence_word_cnt\"))\n",
    "    \n",
    "    return tmp\n",
    "# feature_eng\n",
    "sentence_fea = ['sentence_len','sentence_word_cnt']\n",
    "def Sentence_Eng(train_tmp):\n",
    "    aggs = [\n",
    "        # Count the number of sentences with a length greater than i\n",
    "        *[pl.col('sentence').filter(pl.col('sentence_len') >= i).count().alias(f\"sentence_{i}_cnt\") for i in [0,15,50,100,150,200,250,300] ], \n",
    "        *[pl.col('sentence').filter(pl.col('sentence_len') <= i).count().alias(f\"sentence_<{i}_cnt\") for i in [15,50] ], \n",
    "        # other\n",
    "        *[pl.col(fea).max().alias(f\"{fea}_max\") for fea in sentence_fea],\n",
    "        *[pl.col(fea).mean().alias(f\"{fea}_mean\") for fea in sentence_fea],\n",
    "        *[pl.col(fea).min().alias(f\"{fea}_min\") for fea in sentence_fea],\n",
    "        *[pl.col(fea).sum().alias(f\"{fea}_sum\") for fea in sentence_fea],\n",
    "        *[pl.col(fea).first().alias(f\"{fea}_first\") for fea in sentence_fea],\n",
    "        *[pl.col(fea).last().alias(f\"{fea}_last\") for fea in sentence_fea],\n",
    "        *[pl.col(fea).kurtosis().alias(f\"{fea}_kurtosis\") for fea in sentence_fea],\n",
    "        *[pl.col(fea).quantile(0.25).alias(f\"{fea}_q1\") for fea in sentence_fea], \n",
    "        *[pl.col(fea).quantile(0.75).alias(f\"{fea}_q3\") for fea in sentence_fea], \n",
    "        ]\n",
    "    df = train_tmp.group_by(['essay_id'], maintain_order=True).agg(aggs).sort(\"essay_id\")\n",
    "    df = df.to_pandas()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3396c4fc",
   "metadata": {
    "_cell_guid": "1d85d5f0-e30e-479a-b316-8945342441cf",
    "_uuid": "5b5d6da0-72f5-4f28-aa12-fac74716ab2e",
    "papermill": {
     "duration": 0.011762,
     "end_time": "2024-06-12T20:09:59.916449",
     "exception": false,
     "start_time": "2024-06-12T20:09:59.904687",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Word Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76a492b4",
   "metadata": {
    "_cell_guid": "4734ab5a-ce76-4264-ac46-5d4fed64cbfc",
    "_uuid": "f7912bb9-bfc0-4a2c-b0e0-0d6b4f89d0d7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T20:09:59.941683Z",
     "iopub.status.busy": "2024-06-12T20:09:59.940997Z",
     "iopub.status.idle": "2024-06-12T20:09:59.951169Z",
     "shell.execute_reply": "2024-06-12T20:09:59.950217Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.025404,
     "end_time": "2024-06-12T20:09:59.953279",
     "exception": false,
     "start_time": "2024-06-12T20:09:59.927875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# word feature\n",
    "def Word_Preprocess(tmp):\n",
    "    # Preprocess full_text and use spaces to separate words from the text\n",
    "    tmp = tmp.with_columns(pl.col('full_text').map_elements(dataPreprocessing).str.split(by=\" \").alias(\"word\"))\n",
    "    tmp = tmp.explode('word')\n",
    "    # Calculate the length of each word\n",
    "    tmp = tmp.with_columns(pl.col('word').map_elements(lambda x: len(x)).alias(\"word_len\"))\n",
    "    # Delete data with a word length of 0\n",
    "    tmp = tmp.filter(pl.col('word_len')!=0)\n",
    "    \n",
    "    return tmp\n",
    "# feature_eng\n",
    "def Word_Eng(train_tmp):\n",
    "    aggs = [\n",
    "        # Count the number of words with a length greater than i+1\n",
    "        *[pl.col('word').filter(pl.col('word_len') >= i+1).count().alias(f\"word_{i+1}_cnt\") for i in range(15) ], \n",
    "        # other\n",
    "        pl.col('word_len').max().alias(f\"word_len_max\"),\n",
    "        pl.col('word_len').mean().alias(f\"word_len_mean\"),\n",
    "        pl.col('word_len').std().alias(f\"word_len_std\"),\n",
    "        pl.col('word_len').quantile(0.25).alias(f\"word_len_q1\"),\n",
    "        pl.col('word_len').quantile(0.50).alias(f\"word_len_q2\"),\n",
    "        pl.col('word_len').quantile(0.75).alias(f\"word_len_q3\"),\n",
    "        ]\n",
    "    df = train_tmp.group_by(['essay_id'], maintain_order=True).agg(aggs).sort(\"essay_id\")\n",
    "    df = df.to_pandas()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42635ada",
   "metadata": {
    "_cell_guid": "3bdc96d9-b361-4e84-8e03-83127df80d2e",
    "_uuid": "e08d75f2-f879-4131-99d8-4f6470119bcc",
    "papermill": {
     "duration": 0.011603,
     "end_time": "2024-06-12T20:09:59.976394",
     "exception": false,
     "start_time": "2024-06-12T20:09:59.964791",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Set up loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "522e6ead",
   "metadata": {
    "_cell_guid": "821536c8-bb3d-46f7-9c9c-2f4e105aaa06",
    "_uuid": "f8915170-82b5-4d9b-90bc-d54003b30b97",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T20:10:00.001537Z",
     "iopub.status.busy": "2024-06-12T20:10:00.000793Z",
     "iopub.status.idle": "2024-06-12T20:10:00.009969Z",
     "shell.execute_reply": "2024-06-12T20:10:00.009028Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.023896,
     "end_time": "2024-06-12T20:10:00.011966",
     "exception": false,
     "start_time": "2024-06-12T20:09:59.988070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# idea from https://www.kaggle.com/code/rsakata/optimize-qwk-by-lgb/notebook#QWK-objective\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    if isinstance(y_pred, xgb.QuantileDMatrix):\n",
    "        # XGB\n",
    "        y_true, y_pred = y_pred, y_true\n",
    "\n",
    "        y_true = (y_true.get_label() + a).round()\n",
    "        y_pred = (y_pred + a).clip(1, 6).round()\n",
    "        qwk = cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n",
    "        return 'QWK', qwk\n",
    "\n",
    "    else:\n",
    "        # For lgb\n",
    "        y_true = y_true + a\n",
    "        y_pred = (y_pred + a).clip(1, 6).round()\n",
    "        qwk = cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n",
    "        return 'QWK', qwk, True\n",
    "def qwk_obj(y_true, y_pred):\n",
    "    labels = y_true + a\n",
    "    preds = y_pred + a\n",
    "    preds = preds.clip(1, 6)\n",
    "    f = 1/2*np.sum((preds-labels)**2)\n",
    "    g = 1/2*np.sum((preds-a)**2+b)\n",
    "    df = preds - labels\n",
    "    dg = preds - a\n",
    "    grad = (df/g - f*dg/g**2)*len(labels)\n",
    "    hess = np.ones(len(labels))\n",
    "    return grad, hess\n",
    "\n",
    "a = 2.998\n",
    "b = 1.092"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c396ea",
   "metadata": {
    "_cell_guid": "63718f1d-47da-49ca-b3ea-b67ac39bd6be",
    "_uuid": "0cc6689a-dc56-495b-ac1f-8cf5e57e07eb",
    "papermill": {
     "duration": 0.011891,
     "end_time": "2024-06-12T20:10:00.035218",
     "exception": false,
     "start_time": "2024-06-12T20:10:00.023327",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ae60e44",
   "metadata": {
    "_cell_guid": "6d8f3ca1-bb6c-46fe-83ae-b4fe469b6685",
    "_uuid": "0e681e5e-3168-43e5-98c3-fb280da77643",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T20:10:00.060741Z",
     "iopub.status.busy": "2024-06-12T20:10:00.060033Z",
     "iopub.status.idle": "2024-06-12T20:10:00.072268Z",
     "shell.execute_reply": "2024-06-12T20:10:00.071341Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.02696,
     "end_time": "2024-06-12T20:10:00.074161",
     "exception": false,
     "start_time": "2024-06-12T20:10:00.047201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_select_wrapper():\n",
    "    \"\"\"\n",
    "    lgm\n",
    "    :param train\n",
    "    :param test\n",
    "    :return\n",
    "    \"\"\"\n",
    "    # Part 1.\n",
    "    print('feature_select_wrapper...')\n",
    "    features = feature_names\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    fse = pd.Series(0, index=features)\n",
    "         \n",
    "    for train_index, test_index in skf.split(X, y_split):\n",
    "\n",
    "        X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
    "        y_train_fold, y_test_fold, y_test_fold_int = y[train_index], y[test_index], y_split[test_index]\n",
    "\n",
    "        model = lgb.LGBMRegressor(\n",
    "                    objective = qwk_obj,\n",
    "                    metrics = 'None',\n",
    "                    learning_rate = 0.05,\n",
    "                    max_depth = 5,\n",
    "                    num_leaves = 10,\n",
    "                    colsample_bytree=0.3,\n",
    "                    reg_alpha = 0.7,\n",
    "                    reg_lambda = 0.1,\n",
    "                    n_estimators=700,\n",
    "                    random_state=412,\n",
    "                    extra_trees=True,\n",
    "                    class_weight='balanced',\n",
    "                    verbosity = - 1)\n",
    "\n",
    "        predictor = model.fit(X_train_fold,\n",
    "                              y_train_fold,\n",
    "                              eval_names=['train', 'valid'],\n",
    "                              eval_set=[(X_train_fold, y_train_fold), (X_test_fold, y_test_fold)],\n",
    "                              eval_metric=quadratic_weighted_kappa,\n",
    "                              callbacks=callbacks)\n",
    "        models.append(predictor)\n",
    "        predictions_fold = predictor.predict(X_test_fold)\n",
    "        predictions_fold = predictions_fold + a\n",
    "        predictions_fold = predictions_fold.clip(1, 6).round()\n",
    "        predictions.append(predictions_fold)\n",
    "        f1_fold = f1_score(y_test_fold_int, predictions_fold, average='weighted')\n",
    "        f1_scores.append(f1_fold)\n",
    "\n",
    "        kappa_fold = cohen_kappa_score(y_test_fold_int, predictions_fold, weights='quadratic')\n",
    "        kappa_scores.append(kappa_fold)\n",
    "\n",
    "#         cm = confusion_matrix(y_test_fold_int, predictions_fold, labels=[x for x in range(1,7)])\n",
    "\n",
    "#         disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "#                                       display_labels=[x for x in range(1,7)])\n",
    "#         disp.plot()\n",
    "#         plt.show()\n",
    "        print(f'F1 score across fold: {f1_fold}')\n",
    "        print(f'Cohen kappa score across fold: {kappa_fold}')\n",
    "        feature_importances = predictor.feature_importances_[:len(features)] # 不知道为什么predictor.feature_importances_会比features还长所以加这么一句强行使其一致\n",
    "        fse += pd.Series(feature_importances, features)\n",
    "#         if ENABLE_DONT_WASTE_YOUR_RUN_TIME:\n",
    "#             break\n",
    "    with open(\"fse.pickle\", \"wb\") as f:\n",
    "        pickle.dump(fse, f)\n",
    "    \n",
    "    # Part 4.\n",
    "    feature_select = fse.sort_values(ascending=False).index.tolist()[:13000]\n",
    "    print('done')\n",
    "    return feature_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a9c011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add2_feats = pd.read_pickle('/home/mcq/GitHub/aes2/train_data/add2-feat.pkl')\n",
    "# add2_feats.head(5)\n",
    "# for i in range(2):\n",
    "#     train_feats[f'argument_{i}'] = train_feats_argument.iloc[:, i]\n",
    "# c = train_feats.columns[~train_feats.columns.isin(feature_names)]\n",
    "# train_feats = train_feats.drop['essay_id','score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00545480",
   "metadata": {
    "papermill": {
     "duration": 0.011228,
     "end_time": "2024-06-12T20:10:00.096998",
     "exception": false,
     "start_time": "2024-06-12T20:10:00.085770",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 跑基础特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b76f39f8",
   "metadata": {
    "_cell_guid": "bfd11147-0824-4612-aebd-c689e1ef73d9",
    "_uuid": "d0f49ce6-fc11-460b-8efe-957bda92c090",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T20:10:00.122745Z",
     "iopub.status.busy": "2024-06-12T20:10:00.122096Z",
     "iopub.status.idle": "2024-06-12T20:55:28.808878Z",
     "shell.execute_reply": "2024-06-12T20:55:28.807793Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2728.70395,
     "end_time": "2024-06-12T20:55:28.812623",
     "exception": false,
     "start_time": "2024-06-12T20:10:00.108673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>essay_id</th><th>full_text</th><th>score</th><th>paragraph</th></tr><tr><td>str</td><td>str</td><td>i64</td><td>list[str]</td></tr></thead><tbody><tr><td>&quot;000d118&quot;</td><td>&quot;Many people have car where the…</td><td>3</td><td>[&quot;Many people have car where they live. The thing they don&#x27;t know is that when you use a car alot of thing can happen like you can get in accidet or the smoke that the car has is bad to breath on if someone is walk but in VAUBAN,Germany they dont have that proble because 70 percent of vauban&#x27;s families do not own cars,and 57 percent sold a car to move there. Street parkig ,driveways and home garages are forbidden on the outskirts of freiburd that near the French and Swiss borders. You probaly won&#x27;t see a car in Vauban&#x27;s streets because they are completely &quot;car free&quot; but If some that lives in VAUBAN that owns a car ownership is allowed,but there are only two places that you can park a large garages at the edge of the development,where a car owner buys a space but it not cheap to buy one they sell the space for you car for $40,000 along with a home. The vauban people completed this in 2006 ,they said that this an example of a growing trend in Europe,The untile states and some where else are suburban life from auto use this is called &quot;smart planning&quot;. The current efforts to drastically reduce greenhouse gas emissions from tailes the passengee cars are responsible for 12 percent of greenhouse gas emissions in Europe and up to 50 percent in some car intensive in the United States. I honeslty think that good idea that they did that is Vaudan because that makes cities denser and better for walking and in VAUBAN there are 5,500 residents within a rectangular square mile. In the artical David Gold berg said that &quot;All of our development since World war 2 has been centered on the cars,and that will have to change&quot; and i think that was very true what David Gold said because alot thing we need cars to do we can go anyway were with out cars beacuse some people are a very lazy to walk to place thats why they alot of people use car and i think that it was a good idea that that they did that in VAUBAN so people can see how we really don&#x27;t need car to go to place from place because we can walk from were we need to go or we can ride bycles with out the use of a car. It good that they are doing that if you thik about your help the earth in way and thats a very good thing to. In the United states ,the Environmental protection Agency is promoting what is called &quot;car reduced&quot;communtunties,and the legislators are starting to act,if cautiously. Maany experts expect pubic transport serving suburbs to play a much larger role in a new six years federal transportation bill to approved this year. In previous bill,80 percent of appropriations have by law gone to highways and only 20 percent to other transports. There many good reason why they should do this.    &quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 4)\n",
       "┌──────────┬─────────────────────────────────┬───────┬─────────────────────────────────┐\n",
       "│ essay_id ┆ full_text                       ┆ score ┆ paragraph                       │\n",
       "│ ---      ┆ ---                             ┆ ---   ┆ ---                             │\n",
       "│ str      ┆ str                             ┆ i64   ┆ list[str]                       │\n",
       "╞══════════╪═════════════════════════════════╪═══════╪═════════════════════════════════╡\n",
       "│ 000d118  ┆ Many people have car where the… ┆ 3     ┆ [\"Many people have car where t… │\n",
       "└──────────┴─────────────────────────────────┴───────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [  \n",
    "    (\n",
    "        pl.col(\"full_text\").str.split(by=\"\\n\\n\").alias(\"paragraph\")\n",
    "    ),\n",
    "]\n",
    "PATH = \"kaggle/input/learning-agency-lab-automated-essay-scoring-2/\"\n",
    "paragraph_fea = ['paragraph_len','paragraph_sentence_cnt','paragraph_word_cnt']\n",
    "paragraph_fea2 = ['paragraph_error_num'] + paragraph_fea\n",
    "\n",
    "# # Load training and testing sets, while using \\ n \\ n character segmentation to list and renaming to paragraph for full_text data\n",
    "# data1 = pd.read_csv(PATH + \"train.csv\")\n",
    "# # #data1 = pd.read_csv(PATHS.train_path)\n",
    "# data2 = pd.read_csv('/home/mcq/GitHub/aes2/train_data/persuade_2.0.csv')\n",
    "# data2=data2[['essay_id_comp','full_text','holistic_essay_score']].rename(columns={'essay_id_comp':'essay_id','holistic_essay_score':'score'})\n",
    "\n",
    "# train_pd=pd.concat([data1,data2],axis=0)\n",
    "# train_pd=train_pd.drop_duplicates(subset=['full_text'],keep='first').reset_index(drop=True)\n",
    "\n",
    "# train = pl.from_pandas(train_pd).with_columns(columns)\n",
    "# Load training and testing sets using polars\n",
    "# data1 = pl.read_csv(PATH + \"train.csv\")\n",
    "# data2 = pl.read_csv('/home/mcq/GitHub/aes2/train_data/persuade_2.0.csv')\n",
    "\n",
    "# # Select and rename columns in data2\n",
    "# data2 = data2.select([\n",
    "#     pl.col('essay_id_comp').alias('essay_id'),\n",
    "#     pl.col('full_text'),\n",
    "#     pl.col('holistic_essay_score').alias('score')\n",
    "# ])\n",
    "\n",
    "# # Concatenate the dataframes\n",
    "# train = pl.concat([data1, data2])\n",
    "\n",
    "# # Drop duplicates and reset index\n",
    "# train = train.unique(subset=['full_text']).with_row_count('index').with_columns(columns)\n",
    "train_df = pd.read_csv(PATH + \"train.csv\")\n",
    "#data1 = pd.read_csv(PATHS.train_path)\n",
    "persuade = pd.read_csv('/home/mcq/GitHub/aes2/train_data/persuade_2.0.csv')\n",
    "persuade[\"label\"] =  persuade[\"prompt_name\"].astype(\"category\").cat.codes\n",
    "intersection = pd.merge(train_df, persuade, on=\"full_text\", how=\"inner\")[[\"essay_id\", \"full_text\", \"score\", \"prompt_name\",\"label\"]].reset_index(drop=True)\n",
    "persuade.rename(columns={'essay_id_comp': 'essay_id'}, inplace=True)\n",
    "persuade.rename(columns={'holistic_essay_score': 'score'}, inplace=True)\n",
    "\n",
    "difference = train_df[~train_df[\"essay_id\"].isin(intersection[\"essay_id\"])].reset_index(drop=True)\n",
    "\n",
    "difference1 = persuade[~persuade[\"essay_id\"].isin(intersection[\"essay_id\"])].reset_index(drop=True)\n",
    "difference1 = difference1.iloc[:, :3] \n",
    "skf_train = pd.concat([train_df, difference1], axis=0, ignore_index=True) \n",
    "### skf_train就是加过额外数据集的train了， \n",
    "\n",
    "\n",
    "\n",
    "difference2 = persuade[~persuade[\"essay_id\"].isin(intersection[\"essay_id\"])].reset_index(drop=True)\n",
    "\n",
    "mask = difference2['label'].isin([1,  5 , 0 , 7 , 6 , 8 ,14])\n",
    "df_dropped = difference2[~mask]\n",
    "GFX_add7 = difference2[~difference2[\"essay_id\"].isin(df_dropped[\"essay_id\"])].reset_index(drop=True)\n",
    "##GFX_add7长度为12873，是在7个topic之内的点\n",
    "\n",
    "GKF_train = df_dropped ###长度为13121,是topic之外的点\n",
    "GKF_train = GKF_train.iloc[:, :3]  ##数据规范化处理\n",
    "\n",
    "topic = pd.read_pickle(\"/home/mcq/GitHub/aes2/train_data/base_skf_feat/category-feat.pkl\")\n",
    "groups_1= topic['topic'] ## 读取一万七的topic\n",
    "\n",
    "groups_2 = GFX_add7['label'] ##读取额外的topic\n",
    "groups = pd.concat([groups_1, groups_2], axis=0, ignore_index=True)\n",
    "\n",
    "GFX_add7 = GFX_add7.iloc[:, :3]\n",
    "\n",
    "train_2 = pd.concat([train_df, GFX_add7], axis=0, ignore_index=True) ###把额外的7个topic之内的代码整合进原有的数据集，这里的代码结构和train一样\n",
    "train_2 = train_2[train_2['essay_id'] != '1.51E+11'] # Pandas\n",
    "train = pl.from_pandas(train_2).with_columns(columns) # Polars\n",
    "\n",
    "\n",
    "# data2 = pd.read_csv('/home/mcq/GitHub/aes2/train_data/persuade_2.0.csv')\n",
    "# data2=data2[['essay_id_comp','full_text','holistic_essay_score']].rename(columns={'essay_id_comp':'essay_id','holistic_essay_score':'score'})\n",
    "\n",
    "# train=pd.concat([data1,data2],axis=0)\n",
    "# train=train.drop_duplicates(subset=['full_text'],keep='first').reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train2 = pl.read_csv(PATH + \"persuade_2.0.csv\").with_columns(columns)\n",
    "# train = combined_train = pl.concat([train1, train2])\n",
    "test = pl.read_csv(PATH + \"test.csv\").with_columns(columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TfidfVectorizer parameter\n",
    "vectorizer = TfidfVectorizer(\n",
    "            tokenizer=lambda x: x,\n",
    "            preprocessor=lambda x: x,\n",
    "            token_pattern=None,\n",
    "            strip_accents='unicode',\n",
    "            analyzer = 'word',\n",
    "            ngram_range=(3,6),\n",
    "            min_df=0.05,\n",
    "            max_df=0.95,\n",
    "            sublinear_tf=True,\n",
    ")\n",
    "vectorizer.fit([i for i in train['full_text']])\n",
    "\n",
    "vectorizer_cnt = CountVectorizer(\n",
    "            tokenizer=lambda x: x,\n",
    "            preprocessor=lambda x: x,\n",
    "            token_pattern=None,\n",
    "            strip_accents='unicode',\n",
    "            analyzer = 'word',\n",
    "            ngram_range=(2,3),\n",
    "            min_df=0.10,\n",
    "            max_df=0.85,\n",
    ")\n",
    "vectorizer_cnt.fit([i for i in train['full_text']])\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "with open('/home/mcq/GitHub/aes2/kaggle/input/english-word-hx/words.txt', 'r') as file:\n",
    "    english_vocab = set(word.strip().lower() for word in file)\n",
    "\n",
    "# Display the first sample data in the training set\n",
    "train.head(1)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2b04a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30178, 3)\n",
      "(13121, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_2.shape)\n",
    "GKF_train = GKF_train[GKF_train['essay_id'] != '1.51E+11']\n",
    "print(GKF_train.shape)\n",
    "\n",
    "with open(\"/home/mcq/GitHub/aes2/train_data/train_2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_2, f)\n",
    "\n",
    "with open(\"/home/mcq/GitHub/aes2/train_data/GKF_train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(GKF_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b29c6144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_feats_id = train_feats.iloc[:,0]\n",
    "# train_id = train.to_pandas().iloc[:,0]\n",
    "# set_train_feats_id = set(train_feats_id)\n",
    "# set_train_id = set(train_id)\n",
    "\n",
    "# # 找到不同的值\n",
    "# diff_1 = set_train_feats_id.difference(set_train_id)\n",
    "# diff_2 = set_train_id.difference(set_train_feats_id)\n",
    "\n",
    "# # 合并结果\n",
    "# diff = diff_1.union(diff_2)\n",
    "\n",
    "# # 打印不同的值\n",
    "# print(\"不同的值:\\n\", diff)\n",
    "\n",
    "# difference = set(train_id).difference(set(train_feats_id))\n",
    "# print(difference)\n",
    "\n",
    "\n",
    "# # 找出重复值\n",
    "# duplicates = train_id[train_id.duplicated()]\n",
    "\n",
    "# # 只显示唯一的重复值\n",
    "# unique_duplicates = duplicates.unique()\n",
    "\n",
    "# print(\"唯一的重复值：\")\n",
    "# print(unique_duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "251cc302",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173943/1952907439.py:20: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  tmp = tmp.with_columns(pl.col('paragraph').map_elements(dataPreprocessing))\n",
      "/tmp/ipykernel_173943/1952907439.py:21: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  tmp = tmp.with_columns(pl.col('paragraph').map_elements(remove_punctuation).alias('paragraph_no_pinctuation'))\n",
      "/tmp/ipykernel_173943/1952907439.py:22: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  tmp = tmp.with_columns(pl.col('paragraph_no_pinctuation').map_elements(count_spelling_errors).alias(\"paragraph_error_num\"))\n",
      "/tmp/ipykernel_173943/1952907439.py:24: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  tmp = tmp.with_columns(pl.col('paragraph').map_elements(lambda x: len(x)).alias(\"paragraph_len\"))\n",
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Number:  53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "/tmp/ipykernel_173943/1351511948.py:7: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  tmp = tmp.with_columns(pl.col('sentence').map_elements(lambda x: len(x)).alias(\"sentence_len\"))\n",
      "/tmp/ipykernel_173943/1351511948.py:11: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  tmp = tmp.with_columns(pl.col('sentence').map_elements(lambda x: len(x.split(' '))).alias(\"sentence_word_cnt\"))\n",
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "/tmp/ipykernel_173943/3587845190.py:7: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  tmp = tmp.with_columns(pl.col('word').map_elements(lambda x: len(x)).alias(\"word_len\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Number:  102\n",
      "Features Number:  19773\n",
      "Features Number:  21952\n",
      "Features Number:  21952\n",
      "train_feats.shape=(30178, 21954)\n"
     ]
    }
   ],
   "source": [
    "tmp = Paragraph_Preprocess(train)\n",
    "train_feats = Paragraph_Eng(tmp)\n",
    "\n",
    "# train_feats['score'] = train['score']\n",
    "# # Obtain feature names\n",
    "# feature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\n",
    "# print('Features Number: ',len(feature_names))\n",
    "# train_feats.head(3)\n",
    "\n",
    "tmp = Sentence_Preprocess(train)\n",
    "train_feats = train_feats.merge(Sentence_Eng(tmp), on='essay_id', how='left')\n",
    "\n",
    "tmp = Word_Preprocess(train)\n",
    "train_feats = train_feats.merge(Word_Eng(tmp), on='essay_id', how='left')\n",
    "\n",
    "\n",
    "# feature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\n",
    "# print('Features Number: ',len(feature_names))\n",
    "# train_feats.head(3)\n",
    "\n",
    "\n",
    "    # TF-IDF\n",
    "train_tfid = vectorizer.transform([i for i in train['full_text']])\n",
    "# Convert to array\n",
    "dense_matrix = train_tfid.toarray()\n",
    "# Convert to dataframe\n",
    "df = pd.DataFrame(dense_matrix)\n",
    "# rename features\n",
    "tfid_columns = [ f'tfid_{i}' for i in range(len(df.columns))]\n",
    "df.columns = tfid_columns\n",
    "df['essay_id'] = train_feats['essay_id']\n",
    "# Merge the newly generated feature data with the previously generated feature data\n",
    "train_feats = train_feats.merge(df, on='essay_id', how='left')\n",
    "\n",
    "# feature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\n",
    "# print('Features Number: ',len(feature_names))\n",
    "# train_feats.head(3)\n",
    "\n",
    "# Count\n",
    "train_tfid = vectorizer_cnt.transform([i for i in train['full_text']])\n",
    "dense_matrix = train_tfid.toarray()\n",
    "df = pd.DataFrame(dense_matrix)\n",
    "tfid_columns = [ f'tfid_cnt_{i}' for i in range(len(df.columns))]\n",
    "df.columns = tfid_columns\n",
    "df['essay_id'] = train_feats['essay_id']\n",
    "train_feats = train_feats.merge(df, on='essay_id', how='left')\n",
    "\n",
    "# feature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\n",
    "# print('Features Number: ',len(feature_names))\n",
    "# train_feats.head(3)\n",
    "\n",
    "# add Deberta predictions to LGBM as features\n",
    "# deberta_oof = joblib.load('/home/mcq/GitHub/aes2/kaggle/input/aes2-400-20240419134941/oof.pkl')\n",
    "# print(deberta_oof.shape, train_feats.shape)\n",
    "\n",
    "# for i in range(6):\n",
    "#     train_feats[f'deberta_oof_{i}'] = deberta_oof[:, i]\n",
    "\n",
    "feature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\n",
    "print('Features Number: ', len(feature_names))    \n",
    "\n",
    "print(f\"{train_feats.shape=}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d3979f",
   "metadata": {},
   "source": [
    "# 载入基础特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb7a23e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存入基础特征\n",
    "with open(\"/home/mcq/GitHub/aes2/train_data/basic_feats.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_feats, f)\n",
    "with open(\"/home/mcq/GitHub/aes2/train_data/basic_feature_names.pkl\", \"wb\") as f:\n",
    "    pickle.dump(feature_names, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71511c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Number:  21952\n",
      "train_feats.shape=(30178, 21954)\n"
     ]
    }
   ],
   "source": [
    "# 载入基础特征\n",
    "feature_names = list()\n",
    "with open(\"/home/mcq/GitHub/aes2/train_data/basic_feats.pkl\", \"rb\") as f:\n",
    "    train_feats = pickle.load(f)\n",
    "feature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\n",
    "print('Features Number: ', len(feature_names)) \n",
    "print(f\"{train_feats.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b9d53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fb_oof_0 = pd.read_csv(\"/home/mcq/GitHub/aes2/train_data/fb3_feat_0.csv\")\n",
    "# fb_oof_0.columns = fb_oof_0.columns + '_0'\n",
    "# train_feats = pd.merge(train_feats, fb_oof_0, left_on=\"essay_id\", right_on=\"text_id_0\").drop(\"text_id_0\", axis=1)\n",
    "# feature_names += list(fb_oof_0.columns.drop(\"text_id_0\"))\n",
    "# fb_oof_1 = pd.read_csv(\"/home/mcq/GitHub/aes2/train_data/fb3_feat_1.csv\")\n",
    "# fb_oof_1.columns = fb_oof_1.columns + '_1'\n",
    "# train_feats = pd.merge(train_feats, fb_oof_1, left_on=\"essay_id\", right_on=\"text_id_1\").drop(\"text_id_1\", axis=1)\n",
    "# feature_names += list(fb_oof_1.columns.drop(\"text_id_1\"))\n",
    "\n",
    "# fb_oof_2 = pd.read_csv(\"/home/mcq/GitHub/aes2/train_data/fb3_feat_2.csv\")\n",
    "# fb_oof_2.columns = fb_oof_2.columns + '_2'\n",
    "# train_feats = pd.merge(train_feats, fb_oof_2, left_on=\"essay_id\", right_on=\"text_id_2\").drop(\"text_id_2\", axis=1)\n",
    "# feature_names += list(fb_oof_2.columns.drop(\"text_id_2\"))\n",
    "# print('Features Number: ', len(feature_names)) \n",
    "# print(f\"{train_feats.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d684e161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_feats_argument = pd.read_pickle('/home/mcq/GitHub/aes2/train_data/argument-feat.pkl')\n",
    "# for i in range(2):\n",
    "#     train_feats[f'argument_{i}'] = train_feats_argument.iloc[:, i]\n",
    "#     feature_names += list([f'argument_{i}'])\n",
    "\n",
    "\n",
    "\n",
    "# # add2_feats = pd.read_pickle('/home/mcq/GitHub/aes2/train_data/add2-feat.pkl')\n",
    "# # # add2_feats = add2_feats.drop(columns=['paragraph_processed'])\n",
    "# # train_feats = pd.concat([train_feats, add2_feats], axis = 1)\n",
    "# # feature_names += list(add2_feats.columns)\n",
    "# print('Train Feats:', train_feats.shape)\n",
    "# print('All Feature Names: ',len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25967276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category_feat = pd.read_pickle('/home/mcq/GitHub/aes2/train_data/category-feat.pkl')\n",
    "# train_feats = pd.merge(train_feats, category_feat, on=\"essay_id\",how='inner')\n",
    "# feature_names += list(category_feat.columns.drop('essay_id'))\n",
    "# print('Train Feats:', train_feats.shape)\n",
    "# print('All Feature Names: ',len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5db953d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizers.__version__: 0.19.1\n",
      "transformers.__version__: 4.41.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f5c959a36f4a44ba27fe1f3c11c5c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30178 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import argument_classifier\n",
    "import topicfeaturesmall\n",
    "\n",
    "predicted_score = get_deberta_predicted_score(train_2)\n",
    "with open(\"/home/mcq/GitHub/aes2/train_data/deberta_feats.pkl\", \"wb\") as f:\n",
    "    pickle.dump(predicted_score, f)\n",
    "for i in range(6):\n",
    "    train_feats[f'deberta_oof_{i}'] = predicted_score[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dc9925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizers.__version__: 0.19.1\n",
      "transformers.__version__: 4.41.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model: microsoft/deberta-v3-base Score: 0.4590  Scores: [0.4927071121286561, 0.44975919653806296, 0.41900989606208666, 0.46100316932040336, 0.47875430698135113, 0.4529461925915486]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    000d118\n",
      "1    000fe60\n",
      "2    001ab80\n",
      "3    001bdc0\n",
      "4    002ba53\n",
      "Name: text_id, dtype: object\n",
      "0    000d118\n",
      "1    000fe60\n",
      "2    001ab80\n",
      "3    001bdc0\n",
      "4    002ba53\n",
      "Name: text_id, dtype: object\n",
      "CustomModel(\n",
      "  (model): DebertaV2Model(\n",
      "    (embeddings): DebertaV2Embeddings(\n",
      "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "      (dropout): StableDropout()\n",
      "    )\n",
      "    (encoder): DebertaV2Encoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rel_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (pool): MeanPooling()\n",
      "  (fc): Linear(in_features=768, out_features=6, bias=True)\n",
      ")\n",
      "/home/mcq/GitHub/aes2/kaggle/input/fb3models/0913-deberta-v3-base-FGM/microsoft-deberta-v3-base_fold0_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5381e640c3154da68beaf6fa00353eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2ce625f\n",
      "1    2ce7f8d\n",
      "2    2ce9900\n",
      "3    2cf189d\n",
      "4    2cf20ff\n",
      "Name: text_id, dtype: object\n",
      "0    2ce625f\n",
      "1    2ce7f8d\n",
      "2    2ce9900\n",
      "3    2cf189d\n",
      "4    2cf20ff\n",
      "Name: text_id, dtype: object\n",
      "CustomModel(\n",
      "  (model): DebertaV2Model(\n",
      "    (embeddings): DebertaV2Embeddings(\n",
      "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "      (dropout): StableDropout()\n",
      "    )\n",
      "    (encoder): DebertaV2Encoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rel_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (pool): MeanPooling()\n",
      "  (fc): Linear(in_features=768, out_features=6, bias=True)\n",
      ")\n",
      "/home/mcq/GitHub/aes2/kaggle/input/fb3models/0913-deberta-v3-base-FGM/microsoft-deberta-v3-base_fold0_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e30024c140f3402fb7dcba280c5e1afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5a6ac21\n",
      "1    5a7063a\n",
      "2    5a72fcc\n",
      "3    5a730aa\n",
      "4    5a79f2d\n",
      "Name: text_id, dtype: object\n",
      "0    5a6ac21\n",
      "1    5a7063a\n",
      "2    5a72fcc\n",
      "3    5a730aa\n",
      "4    5a79f2d\n",
      "Name: text_id, dtype: object\n",
      "CustomModel(\n",
      "  (model): DebertaV2Model(\n",
      "    (embeddings): DebertaV2Embeddings(\n",
      "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "      (dropout): StableDropout()\n",
      "    )\n",
      "    (encoder): DebertaV2Encoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rel_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (pool): MeanPooling()\n",
      "  (fc): Linear(in_features=768, out_features=6, bias=True)\n",
      ")\n",
      "/home/mcq/GitHub/aes2/kaggle/input/fb3models/0913-deberta-v3-base-FGM/microsoft-deberta-v3-base_fold0_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46faeab822164fb38bcded2aed40eca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    85d6bbe\n",
      "1    85dd935\n",
      "2    85dedad\n",
      "3    85e497c\n",
      "4    85ec1a2\n",
      "Name: text_id, dtype: object\n",
      "0    85d6bbe\n",
      "1    85dd935\n",
      "2    85dedad\n",
      "3    85e497c\n",
      "4    85ec1a2\n",
      "Name: text_id, dtype: object\n",
      "CustomModel(\n",
      "  (model): DebertaV2Model(\n",
      "    (embeddings): DebertaV2Embeddings(\n",
      "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "      (dropout): StableDropout()\n",
      "    )\n",
      "    (encoder): DebertaV2Encoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rel_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (pool): MeanPooling()\n",
      "  (fc): Linear(in_features=768, out_features=6, bias=True)\n",
      ")\n",
      "/home/mcq/GitHub/aes2/kaggle/input/fb3models/0913-deberta-v3-base-FGM/microsoft-deberta-v3-base_fold0_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed0fee8e0754df2845aa8b1e53e5c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    b15e5d1\n",
      "1    b15e94d\n",
      "2    b15efce\n",
      "3    b160aea\n",
      "4    b160f34\n",
      "Name: text_id, dtype: object\n",
      "0    b15e5d1\n",
      "1    b15e94d\n",
      "2    b15efce\n",
      "3    b160aea\n",
      "4    b160f34\n",
      "Name: text_id, dtype: object\n",
      "CustomModel(\n",
      "  (model): DebertaV2Model(\n",
      "    (embeddings): DebertaV2Embeddings(\n",
      "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "      (dropout): StableDropout()\n",
      "    )\n",
      "    (encoder): DebertaV2Encoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rel_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (pool): MeanPooling()\n",
      "  (fc): Linear(in_features=768, out_features=6, bias=True)\n",
      ")\n",
      "/home/mcq/GitHub/aes2/kaggle/input/fb3models/0913-deberta-v3-base-FGM/microsoft-deberta-v3-base_fold0_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5294359b10bb4d6a8834fb99837bd28c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    de106b0\n",
      "1    de1769c\n",
      "2    de18382\n",
      "3    de1b341\n",
      "4    de1fddb\n",
      "Name: text_id, dtype: object\n",
      "0    de106b0\n",
      "1    de1769c\n",
      "2    de18382\n",
      "3    de1b341\n",
      "4    de1fddb\n",
      "Name: text_id, dtype: object\n",
      "CustomModel(\n",
      "  (model): DebertaV2Model(\n",
      "    (embeddings): DebertaV2Embeddings(\n",
      "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "      (dropout): StableDropout()\n",
      "    )\n",
      "    (encoder): DebertaV2Encoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rel_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (pool): MeanPooling()\n",
      "  (fc): Linear(in_features=768, out_features=6, bias=True)\n",
      ")\n",
      "/home/mcq/GitHub/aes2/kaggle/input/fb3models/0913-deberta-v3-base-FGM/microsoft-deberta-v3-base_fold0_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20da96bfe07949f9bb1fcbb7f7e56df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5E959DC2C7CD\n",
      "1    27FC144243A6\n",
      "2    4521F44AD595\n",
      "3    C74CBEFD0B9E\n",
      "4    894216DF1149\n",
      "Name: text_id, dtype: object\n",
      "0    5E959DC2C7CD\n",
      "1    27FC144243A6\n",
      "2    4521F44AD595\n",
      "3    C74CBEFD0B9E\n",
      "4    894216DF1149\n",
      "Name: text_id, dtype: object\n",
      "CustomModel(\n",
      "  (model): DebertaV2Model(\n",
      "    (embeddings): DebertaV2Embeddings(\n",
      "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "      (dropout): StableDropout()\n",
      "    )\n",
      "    (encoder): DebertaV2Encoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rel_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (pool): MeanPooling()\n",
      "  (fc): Linear(in_features=768, out_features=6, bias=True)\n",
      ")\n",
      "/home/mcq/GitHub/aes2/kaggle/input/fb3models/0913-deberta-v3-base-FGM/microsoft-deberta-v3-base_fold0_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332bb2d1a0f0468b84e486f96a24f988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2C118DE08B88\n",
      "1    CD4B9F6B311B\n",
      "2    3FC1377C323B\n",
      "3    0E1E5C1FCE2F\n",
      "4    43E52415FDFE\n",
      "Name: text_id, dtype: object\n",
      "0    2C118DE08B88\n",
      "1    CD4B9F6B311B\n",
      "2    3FC1377C323B\n",
      "3    0E1E5C1FCE2F\n",
      "4    43E52415FDFE\n",
      "Name: text_id, dtype: object\n",
      "CustomModel(\n",
      "  (model): DebertaV2Model(\n",
      "    (embeddings): DebertaV2Embeddings(\n",
      "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "      (dropout): StableDropout()\n",
      "    )\n",
      "    (encoder): DebertaV2Encoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rel_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (pool): MeanPooling()\n",
      "  (fc): Linear(in_features=768, out_features=6, bias=True)\n",
      ")\n",
      "/home/mcq/GitHub/aes2/kaggle/input/fb3models/0913-deberta-v3-base-FGM/microsoft-deberta-v3-base_fold0_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e58823aa89c4dd8ad9770f9c330a907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1111156C5EB8\n",
      "1    5C2B6A9275A3\n",
      "2    7AA2C0834BE1\n",
      "3    CFC1F5729C6D\n",
      "4    3DA49C7B4B14\n",
      "Name: text_id, dtype: object\n",
      "0    1111156C5EB8\n",
      "1    5C2B6A9275A3\n",
      "2    7AA2C0834BE1\n",
      "3    CFC1F5729C6D\n",
      "4    3DA49C7B4B14\n",
      "Name: text_id, dtype: object\n",
      "CustomModel(\n",
      "  (model): DebertaV2Model(\n",
      "    (embeddings): DebertaV2Embeddings(\n",
      "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "      (dropout): StableDropout()\n",
      "    )\n",
      "    (encoder): DebertaV2Encoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rel_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (pool): MeanPooling()\n",
      "  (fc): Linear(in_features=768, out_features=6, bias=True)\n",
      ")\n",
      "/home/mcq/GitHub/aes2/kaggle/input/fb3models/0913-deberta-v3-base-FGM/microsoft-deberta-v3-base_fold0_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8100ed9f66046f295a1f31c01d0938a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    7D36939006E9\n",
      "1    48F2F2876E3D\n",
      "2    6D1EF2E394FB\n",
      "3    2945D26BEE91\n",
      "4    BDA453D8E1C7\n",
      "Name: text_id, dtype: object\n",
      "0    7D36939006E9\n",
      "1    48F2F2876E3D\n",
      "2    6D1EF2E394FB\n",
      "3    2945D26BEE91\n",
      "4    BDA453D8E1C7\n",
      "Name: text_id, dtype: object\n",
      "CustomModel(\n",
      "  (model): DebertaV2Model(\n",
      "    (embeddings): DebertaV2Embeddings(\n",
      "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "      (dropout): StableDropout()\n",
      "    )\n",
      "    (encoder): DebertaV2Encoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rel_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (pool): MeanPooling()\n",
      "  (fc): Linear(in_features=768, out_features=6, bias=True)\n",
      ")\n",
      "/home/mcq/GitHub/aes2/kaggle/input/fb3models/0913-deberta-v3-base-FGM/microsoft-deberta-v3-base_fold0_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2375b5a7d2a4eb49f614b9b5aa803c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fb3_predicted = get_fb3_predicted(train_2)\n",
    "# fb3_predicted.shape\n",
    "with open(\"/home/mcq/GitHub/aes2/train_data/fb3_feats.pkl\", \"wb\") as f:\n",
    "    pickle.dump(fb3_predicted, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb28f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc17de0b6af24b08ae6421ab45da54b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30178 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "argument_predicted = argument_classifier.predict_chunk(train_2)\n",
    "\n",
    "with open(\"/home/mcq/GitHub/aes2/train_data/aargument_feats.pkl\", \"wb\") as f:\n",
    "    pickle.dump(argument_predicted, f)\n",
    "\n",
    "for i in range(2):\n",
    "    train_feats[f'argument_{i}'] = argument_predicted.iloc[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c31493",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats = pd.merge(\n",
    "    train_feats,\n",
    "    fb3_predicted,\n",
    "    left_on=\"essay_id\",\n",
    "    right_on=\"text_id\"\n",
    ").drop(\"text_id\", axis=1)\n",
    "\n",
    "# Features number\n",
    "feature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2c0398",
   "metadata": {},
   "source": [
    "# 读取所有train feats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c69d051f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Number:  21913\n",
      "train_feats.shape=(30178, 21914)\n"
     ]
    }
   ],
   "source": [
    "with open(\"/home/mcq/GitHub/aes2/train_data/train_feats.pkl\", \"rb\") as f:\n",
    "    train_feats = pickle.load(f)\n",
    "feature_names = list(filter(lambda x: x not in ['essay_id','score'], train_feats.columns))\n",
    "print('Features Number: ', len(feature_names)) \n",
    "print(f\"{train_feats.shape=}\")\n",
    "with open(\"/home/mcq/GitHub/aes2/train_data/y.pkl\", \"rb\") as f:\n",
    "    y = pickle.load(f)\n",
    "with open(\"/home/mcq/GitHub/aes2/train_data/y_split.pkl\", \"rb\") as f:\n",
    "    y_split = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327f60fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ttc = train_feats.select_dtypes(include=['object']).columns\n",
    "# train_feats= train_feats.drop(columns=['essay_id', 'paragraph_processed'])\n",
    "# rmv = ['essay_id', 'paragraph_processed']\n",
    "# feature_names = [col for col in feature_names if col not in rmv]\n",
    "# train_feats = train_feats.drop('essay_id')\n",
    "# feature_names = feature_names.drop(['essay_id','paragraph_processed'])\n",
    "# print('Train Feats:', train_feats.shape)\n",
    "# print('All Feature Names: ',len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aab39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the 'text' column to string type and assigning to X\n",
    "X = train_feats[feature_names].astype(np.float32).values\n",
    "\n",
    "# Converting the 'score' column to integer type and assigning to y\n",
    "y_split = train_feats['score'].astype(int).values\n",
    "y = train_feats['score'].astype(np.float32).values-a\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c2c0548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_select_wrapper...\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Using self-defined objective function\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "[25]\ttrain's QWK: 0.808265\tvalid's QWK: 0.81157\n",
      "[50]\ttrain's QWK: 0.873475\tvalid's QWK: 0.87614\n",
      "[75]\ttrain's QWK: 0.88674\tvalid's QWK: 0.890012\n",
      "[100]\ttrain's QWK: 0.890722\tvalid's QWK: 0.892374\n",
      "[125]\ttrain's QWK: 0.893974\tvalid's QWK: 0.896185\n",
      "[150]\ttrain's QWK: 0.897196\tvalid's QWK: 0.898985\n",
      "[175]\ttrain's QWK: 0.900718\tvalid's QWK: 0.901184\n",
      "[200]\ttrain's QWK: 0.902589\tvalid's QWK: 0.902617\n",
      "[225]\ttrain's QWK: 0.904201\tvalid's QWK: 0.903739\n",
      "[250]\ttrain's QWK: 0.906476\tvalid's QWK: 0.904127\n",
      "[275]\ttrain's QWK: 0.90816\tvalid's QWK: 0.905263\n",
      "[300]\ttrain's QWK: 0.909971\tvalid's QWK: 0.906168\n",
      "[325]\ttrain's QWK: 0.911227\tvalid's QWK: 0.906088\n",
      "[350]\ttrain's QWK: 0.913007\tvalid's QWK: 0.907161\n",
      "[375]\ttrain's QWK: 0.914289\tvalid's QWK: 0.907619\n",
      "[400]\ttrain's QWK: 0.915972\tvalid's QWK: 0.908259\n",
      "[425]\ttrain's QWK: 0.917942\tvalid's QWK: 0.908676\n",
      "[450]\ttrain's QWK: 0.919123\tvalid's QWK: 0.909081\n",
      "[475]\ttrain's QWK: 0.920194\tvalid's QWK: 0.909767\n",
      "[500]\ttrain's QWK: 0.921271\tvalid's QWK: 0.910278\n",
      "[525]\ttrain's QWK: 0.922702\tvalid's QWK: 0.910678\n",
      "[550]\ttrain's QWK: 0.923821\tvalid's QWK: 0.911326\n",
      "[575]\ttrain's QWK: 0.924993\tvalid's QWK: 0.911386\n",
      "[600]\ttrain's QWK: 0.925978\tvalid's QWK: 0.911725\n",
      "[625]\ttrain's QWK: 0.926954\tvalid's QWK: 0.912856\n",
      "[650]\ttrain's QWK: 0.927944\tvalid's QWK: 0.913671\n",
      "[675]\ttrain's QWK: 0.928956\tvalid's QWK: 0.913968\n",
      "[700]\ttrain's QWK: 0.930036\tvalid's QWK: 0.913523\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[671]\ttrain's QWK: 0.92888\tvalid's QWK: 0.914115\n",
      "Evaluated only: QWK\n",
      "F1 score across fold: 0.8154298554777031\n",
      "Cohen kappa score across fold: 0.9141154977153987\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Using self-defined objective function\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "[25]\ttrain's QWK: 0.826706\tvalid's QWK: 0.817193\n",
      "[50]\ttrain's QWK: 0.874987\tvalid's QWK: 0.858926\n",
      "[75]\ttrain's QWK: 0.890802\tvalid's QWK: 0.878368\n",
      "[100]\ttrain's QWK: 0.895763\tvalid's QWK: 0.882658\n",
      "[125]\ttrain's QWK: 0.898634\tvalid's QWK: 0.884651\n",
      "[150]\ttrain's QWK: 0.900666\tvalid's QWK: 0.885641\n",
      "[175]\ttrain's QWK: 0.903551\tvalid's QWK: 0.887476\n",
      "[200]\ttrain's QWK: 0.905358\tvalid's QWK: 0.889699\n",
      "[225]\ttrain's QWK: 0.907159\tvalid's QWK: 0.890339\n",
      "[250]\ttrain's QWK: 0.908459\tvalid's QWK: 0.890996\n",
      "[275]\ttrain's QWK: 0.910179\tvalid's QWK: 0.892146\n",
      "[300]\ttrain's QWK: 0.911558\tvalid's QWK: 0.892857\n",
      "[325]\ttrain's QWK: 0.913104\tvalid's QWK: 0.893925\n",
      "[350]\ttrain's QWK: 0.914344\tvalid's QWK: 0.89352\n",
      "[375]\ttrain's QWK: 0.915583\tvalid's QWK: 0.895134\n",
      "[400]\ttrain's QWK: 0.917028\tvalid's QWK: 0.895466\n",
      "[425]\ttrain's QWK: 0.918893\tvalid's QWK: 0.896792\n",
      "[450]\ttrain's QWK: 0.9202\tvalid's QWK: 0.897145\n",
      "[475]\ttrain's QWK: 0.92189\tvalid's QWK: 0.898689\n",
      "[500]\ttrain's QWK: 0.923153\tvalid's QWK: 0.899256\n",
      "[525]\ttrain's QWK: 0.924169\tvalid's QWK: 0.899752\n",
      "[550]\ttrain's QWK: 0.925348\tvalid's QWK: 0.900132\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[575]\ttrain's QWK: 0.926725\tvalid's QWK: 0.901438\n",
      "[600]\ttrain's QWK: 0.927893\tvalid's QWK: 0.901886\n",
      "[625]\ttrain's QWK: 0.928797\tvalid's QWK: 0.902119\n",
      "[650]\ttrain's QWK: 0.929865\tvalid's QWK: 0.902207\n",
      "[675]\ttrain's QWK: 0.93098\tvalid's QWK: 0.902362\n",
      "[700]\ttrain's QWK: 0.932095\tvalid's QWK: 0.90321\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[696]\ttrain's QWK: 0.931896\tvalid's QWK: 0.90326\n",
      "Evaluated only: QWK\n",
      "F1 score across fold: 0.7938141691798312\n",
      "Cohen kappa score across fold: 0.9032602384524461\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Using self-defined objective function\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "[25]\ttrain's QWK: 0.820839\tvalid's QWK: 0.819369\n",
      "[50]\ttrain's QWK: 0.874255\tvalid's QWK: 0.871574\n",
      "[75]\ttrain's QWK: 0.887324\tvalid's QWK: 0.884552\n",
      "[100]\ttrain's QWK: 0.89288\tvalid's QWK: 0.888123\n",
      "[125]\ttrain's QWK: 0.896071\tvalid's QWK: 0.889785\n",
      "[150]\ttrain's QWK: 0.900036\tvalid's QWK: 0.894787\n",
      "[175]\ttrain's QWK: 0.901856\tvalid's QWK: 0.896459\n",
      "[200]\ttrain's QWK: 0.903823\tvalid's QWK: 0.898794\n",
      "[225]\ttrain's QWK: 0.905301\tvalid's QWK: 0.899357\n",
      "[250]\ttrain's QWK: 0.907981\tvalid's QWK: 0.899982\n",
      "[275]\ttrain's QWK: 0.909084\tvalid's QWK: 0.900923\n",
      "[300]\ttrain's QWK: 0.910576\tvalid's QWK: 0.900756\n",
      "[325]\ttrain's QWK: 0.912103\tvalid's QWK: 0.901548\n",
      "[350]\ttrain's QWK: 0.913333\tvalid's QWK: 0.902138\n",
      "[375]\ttrain's QWK: 0.914861\tvalid's QWK: 0.903159\n",
      "[400]\ttrain's QWK: 0.915695\tvalid's QWK: 0.903524\n",
      "[425]\ttrain's QWK: 0.916918\tvalid's QWK: 0.905065\n",
      "[450]\ttrain's QWK: 0.91831\tvalid's QWK: 0.905724\n",
      "[475]\ttrain's QWK: 0.919668\tvalid's QWK: 0.905831\n",
      "[500]\ttrain's QWK: 0.920594\tvalid's QWK: 0.906814\n",
      "[525]\ttrain's QWK: 0.921943\tvalid's QWK: 0.907509\n",
      "[550]\ttrain's QWK: 0.923627\tvalid's QWK: 0.908272\n",
      "[575]\ttrain's QWK: 0.924618\tvalid's QWK: 0.908147\n",
      "[600]\ttrain's QWK: 0.925927\tvalid's QWK: 0.909613\n",
      "[625]\ttrain's QWK: 0.927281\tvalid's QWK: 0.910067\n",
      "[650]\ttrain's QWK: 0.928523\tvalid's QWK: 0.910762\n",
      "[675]\ttrain's QWK: 0.929599\tvalid's QWK: 0.910931\n",
      "[700]\ttrain's QWK: 0.930945\tvalid's QWK: 0.911365\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[699]\ttrain's QWK: 0.93087\tvalid's QWK: 0.911435\n",
      "Evaluated only: QWK\n",
      "F1 score across fold: 0.80932367732052\n",
      "Cohen kappa score across fold: 0.9114346201691563\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Using self-defined objective function\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "[25]\ttrain's QWK: 0.817606\tvalid's QWK: 0.821476\n",
      "[50]\ttrain's QWK: 0.872695\tvalid's QWK: 0.879766\n",
      "[75]\ttrain's QWK: 0.886956\tvalid's QWK: 0.891543\n",
      "[100]\ttrain's QWK: 0.891721\tvalid's QWK: 0.895024\n",
      "[125]\ttrain's QWK: 0.89575\tvalid's QWK: 0.897792\n",
      "[150]\ttrain's QWK: 0.897325\tvalid's QWK: 0.898654\n",
      "[175]\ttrain's QWK: 0.900459\tvalid's QWK: 0.900032\n",
      "[200]\ttrain's QWK: 0.903027\tvalid's QWK: 0.902243\n",
      "[225]\ttrain's QWK: 0.904606\tvalid's QWK: 0.903081\n",
      "[250]\ttrain's QWK: 0.90639\tvalid's QWK: 0.904061\n",
      "[275]\ttrain's QWK: 0.907927\tvalid's QWK: 0.904602\n",
      "[300]\ttrain's QWK: 0.909512\tvalid's QWK: 0.905763\n",
      "[325]\ttrain's QWK: 0.910693\tvalid's QWK: 0.905979\n",
      "[350]\ttrain's QWK: 0.912389\tvalid's QWK: 0.907339\n",
      "[375]\ttrain's QWK: 0.91375\tvalid's QWK: 0.907538\n",
      "[400]\ttrain's QWK: 0.915037\tvalid's QWK: 0.907593\n",
      "[425]\ttrain's QWK: 0.916238\tvalid's QWK: 0.908517\n",
      "[450]\ttrain's QWK: 0.917572\tvalid's QWK: 0.908915\n",
      "[475]\ttrain's QWK: 0.91859\tvalid's QWK: 0.909743\n",
      "[500]\ttrain's QWK: 0.919735\tvalid's QWK: 0.910541\n",
      "[525]\ttrain's QWK: 0.921235\tvalid's QWK: 0.91162\n",
      "[550]\ttrain's QWK: 0.92212\tvalid's QWK: 0.911754\n",
      "[575]\ttrain's QWK: 0.923286\tvalid's QWK: 0.911983\n",
      "[600]\ttrain's QWK: 0.924832\tvalid's QWK: 0.912345\n",
      "[625]\ttrain's QWK: 0.926152\tvalid's QWK: 0.913046\n",
      "[650]\ttrain's QWK: 0.927174\tvalid's QWK: 0.913598\n",
      "[675]\ttrain's QWK: 0.928396\tvalid's QWK: 0.914394\n",
      "[700]\ttrain's QWK: 0.929295\tvalid's QWK: 0.914428\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[700]\ttrain's QWK: 0.929295\tvalid's QWK: 0.914428\n",
      "Evaluated only: QWK\n",
      "F1 score across fold: 0.8174386749369343\n",
      "Cohen kappa score across fold: 0.9144280747057828\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=5) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=32) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Using self-defined objective function\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "[25]\ttrain's QWK: 0.810826\tvalid's QWK: 0.80081\n",
      "[50]\ttrain's QWK: 0.864715\tvalid's QWK: 0.85673\n",
      "[75]\ttrain's QWK: 0.883221\tvalid's QWK: 0.878704\n",
      "[100]\ttrain's QWK: 0.889881\tvalid's QWK: 0.88292\n",
      "[125]\ttrain's QWK: 0.89325\tvalid's QWK: 0.88621\n",
      "[150]\ttrain's QWK: 0.89567\tvalid's QWK: 0.888852\n",
      "[175]\ttrain's QWK: 0.898135\tvalid's QWK: 0.891027\n",
      "[200]\ttrain's QWK: 0.90064\tvalid's QWK: 0.891905\n",
      "[225]\ttrain's QWK: 0.902566\tvalid's QWK: 0.893131\n",
      "[250]\ttrain's QWK: 0.904804\tvalid's QWK: 0.894425\n",
      "[275]\ttrain's QWK: 0.906805\tvalid's QWK: 0.895022\n",
      "[300]\ttrain's QWK: 0.90805\tvalid's QWK: 0.895704\n",
      "[325]\ttrain's QWK: 0.90971\tvalid's QWK: 0.897467\n",
      "[350]\ttrain's QWK: 0.91163\tvalid's QWK: 0.899217\n",
      "[375]\ttrain's QWK: 0.913158\tvalid's QWK: 0.899764\n",
      "[400]\ttrain's QWK: 0.915442\tvalid's QWK: 0.900752\n",
      "[425]\ttrain's QWK: 0.917\tvalid's QWK: 0.901009\n",
      "[450]\ttrain's QWK: 0.918487\tvalid's QWK: 0.902043\n",
      "[475]\ttrain's QWK: 0.920406\tvalid's QWK: 0.902985\n",
      "[500]\ttrain's QWK: 0.92186\tvalid's QWK: 0.903151\n",
      "[525]\ttrain's QWK: 0.923484\tvalid's QWK: 0.904105\n",
      "[550]\ttrain's QWK: 0.924277\tvalid's QWK: 0.904248\n",
      "[575]\ttrain's QWK: 0.925406\tvalid's QWK: 0.904652\n",
      "[600]\ttrain's QWK: 0.926345\tvalid's QWK: 0.905004\n",
      "[625]\ttrain's QWK: 0.927507\tvalid's QWK: 0.904913\n",
      "[650]\ttrain's QWK: 0.928579\tvalid's QWK: 0.905618\n",
      "[675]\ttrain's QWK: 0.929624\tvalid's QWK: 0.906281\n",
      "[700]\ttrain's QWK: 0.931189\tvalid's QWK: 0.907612\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[699]\ttrain's QWK: 0.931167\tvalid's QWK: 0.907612\n",
      "Evaluated only: QWK\n",
      "F1 score across fold: 0.8063454916841044\n",
      "Cohen kappa score across fold: 0.9076120112039784\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "f1_scores = []\n",
    "kappa_scores = []\n",
    "models = []\n",
    "predictions = []\n",
    "callbacks = [log_evaluation(period=25), early_stopping(stopping_rounds=75,first_metric_only=True)]\n",
    "\n",
    "feature_select = feature_select_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "052e0624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Select Number:  13000\n"
     ]
    }
   ],
   "source": [
    "X = train_feats[feature_select].astype(np.float32).values\n",
    "\n",
    "print('Features Select Number: ', len(feature_select))\n",
    "\n",
    "with open(\"/home/mcq/GitHub/aes2/train_data/train_feats.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_feats, f)\n",
    "with open(\"/home/mcq/GitHub/aes2/train_data/feature_select.pkl\", \"wb\") as f:\n",
    "    pickle.dump(feature_select, f)\n",
    "with open(\"/home/mcq/GitHub/aes2/train_data/X.pkl\", \"wb\") as f:\n",
    "    pickle.dump(X, f)\n",
    "with open(\"/home/mcq/GitHub/aes2/train_data/y.pkl\", \"wb\") as f:\n",
    "    pickle.dump(y, f)\n",
    "with open(\"/home/mcq/GitHub/aes2/train_data/y_split.pkl\", \"wb\") as f:\n",
    "    pickle.dump(y_split, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d49fce",
   "metadata": {
    "_cell_guid": "35f37718-bb2f-40d8-b192-ae9f45e64a3a",
    "_uuid": "8df71240-f1a0-48ce-abb2-007be4ca6951",
    "papermill": {
     "duration": 0.044453,
     "end_time": "2024-06-12T20:55:28.904813",
     "exception": false,
     "start_time": "2024-06-12T20:55:28.860360",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4254de96",
   "metadata": {
    "_cell_guid": "b4c35849-219e-4eb1-9cb1-2ad7c3865483",
    "_uuid": "a2de1696-4ab4-4869-8ce8-35bade6d3a96",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T20:55:28.998544Z",
     "iopub.status.busy": "2024-06-12T20:55:28.997737Z",
     "iopub.status.idle": "2024-06-12T20:57:21.877903Z",
     "shell.execute_reply": "2024-06-12T20:57:21.876882Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 112.929068,
     "end_time": "2024-06-12T20:57:21.880372",
     "exception": false,
     "start_time": "2024-06-12T20:55:28.951304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78023e00362f43b1b849c26a6641e8ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    000d118\n",
      "1    000fe60\n",
      "2    001ab80\n",
      "Name: text_id, dtype: object\n",
      "0    000d118\n",
      "1    000fe60\n",
      "2    001ab80\n",
      "Name: text_id, dtype: object\n",
      "CustomModel(\n",
      "  (model): DebertaV2Model(\n",
      "    (embeddings): DebertaV2Embeddings(\n",
      "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "      (dropout): StableDropout()\n",
      "    )\n",
      "    (encoder): DebertaV2Encoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rel_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (pool): MeanPooling()\n",
      "  (fc): Linear(in_features=768, out_features=6, bias=True)\n",
      ")\n",
      "/home/mcq/GitHub/aes2/kaggle/input/fb3models/0913-deberta-v3-base-FGM/microsoft-deberta-v3-base_fold0_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d3bd17933745d9abf9a610fdd5f808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Exception ignored in: <function _ConnectionBase.__del__ at 0x7fd794122a70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/connection.py\", line 132, in __del__\n",
      "QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "    reader_close()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n",
      "    self._close()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "    self.run()\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mcq/anaconda3/envs/torch/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10cb432fb2e4270b678170f6336d0ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features number:  21966\n",
      "   deberta_oof_0  deberta_oof_5  deberta_oof_2  deberta_oof_4  deberta_oof_1  \\\n",
      "0       0.021534       0.000785       0.529225       0.002071       0.379466   \n",
      "1       0.001421       0.000288       0.839511       0.000765       0.071248   \n",
      "2       0.001564       0.013603       0.033057       0.433214       0.001929   \n",
      "\n",
      "   deberta_oof_3  tfid_3108  tfid_cnt_1807  tfid_cnt_263  tfid_cnt_1805  ...  \\\n",
      "0       0.066919   0.000000              0             0              3  ...   \n",
      "1       0.086768   0.012754              1             1              0  ...   \n",
      "2       0.516632   0.009019              0             4              2  ...   \n",
      "\n",
      "   tfid_8803  tfid_8804  tfid_8805  tfid_8806  tfid_8807  tfid_8809  \\\n",
      "0        0.0   0.019419   0.000000   0.013999        0.0   0.013413   \n",
      "1        0.0   0.019464   0.000000   0.000000        0.0   0.016664   \n",
      "2        0.0   0.013765   0.015706   0.012300        0.0   0.000000   \n",
      "\n",
      "   tfid_8811  tfid_8812  tfid_12853  tfid_12857  \n",
      "0    0.00000   0.000000         0.0    0.009600  \n",
      "1    0.00000   0.000000         0.0    0.014782  \n",
      "2    0.01215   0.012325         0.0    0.017359  \n",
      "\n",
      "[3 rows x 13000 columns]\n"
     ]
    }
   ],
   "source": [
    "# if ENABLE_DONT_WASTE_YOUR_RUN_TIME:\n",
    "#     import shutil\n",
    "\n",
    "#     shutil.copyfile(\"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/sample_submission.csv\", \"submission.csv\")\n",
    "def preprocess_test(test: pl.DataFrame| None = None) -> pd.DataFrame:\n",
    "    # import sys\n",
    "    # import os\n",
    "    # sys.path.append('/kaggle/input/argument-classifier')\n",
    "    import argument_classifier\n",
    "    \n",
    "    if test is None:\n",
    "        test = pl.read_csv(PATH + \"test.csv\").with_columns(columns)\n",
    "    tmp = Paragraph_Preprocess(test)\n",
    "    test_feats = Paragraph_Eng(tmp)\n",
    "    # Sentence\n",
    "    tmp = Sentence_Preprocess(test)\n",
    "    test_feats = test_feats.merge(Sentence_Eng(tmp), on='essay_id', how='left')\n",
    "    # Word\n",
    "    tmp = Word_Preprocess(test)\n",
    "    test_feats = test_feats.merge(Word_Eng(tmp), on='essay_id', how='left')\n",
    "\n",
    "    # TfidfVectorizer\n",
    "    test_tfid = vectorizer.transform([i for i in test['full_text']])\n",
    "    dense_matrix = test_tfid.toarray()\n",
    "    df = pd.DataFrame(dense_matrix)\n",
    "    tfid_columns = [ f'tfid_{i}' for i in range(len(df.columns))]\n",
    "    df.columns = tfid_columns\n",
    "    df['essay_id'] = test_feats['essay_id']\n",
    "    test_feats = test_feats.merge(df, on='essay_id', how='left')\n",
    "\n",
    "    # CountVectorizer\n",
    "    test_tfid = vectorizer_cnt.transform([i for i in test['full_text']])\n",
    "    dense_matrix = test_tfid.toarray()\n",
    "    df = pd.DataFrame(dense_matrix)\n",
    "    tfid_columns = [ f'tfid_cnt_{i}' for i in range(len(df.columns))]\n",
    "    df.columns = tfid_columns\n",
    "    df['essay_id'] = test_feats['essay_id']\n",
    "    test_feats = test_feats.merge(df, on='essay_id', how='left')\n",
    "\n",
    "    # HashingVectorizer\n",
    "    # test_tfid = vectorizer_hash.transform([i for i in test['full_text']])\n",
    "    # dense_matrix = test_tfid.toarray()\n",
    "    # df = pd.DataFrame(dense_matrix)\n",
    "    # tfid_columns = [ f'tfid_cnt_{i}' for i in range(len(df.columns))]\n",
    "    # df.columns = tfid_columns\n",
    "    # df['essay_id'] = test_feats['essay_id']\n",
    "    # test_feats = test_feats.merge(df, on='essay_id', how='left')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    predicted_score = get_deberta_predicted_score()\n",
    "    \n",
    "    for i in range(6):\n",
    "        test_feats[f'deberta_oof_{i}'] = predicted_score[:, i]\n",
    "    fb3_predicted = get_fb3_predicted()\n",
    "    fb3_predicted.shape\n",
    "\n",
    "    argument_predicted = argument_classifier.predict_chunk(train = pd.read_csv(TEST_DATA_PATH))\n",
    "    for i in range(2):\n",
    "        test_feats[f'argument_{i}'] = argument_predicted.iloc[:, i]\n",
    "        \n",
    "    \n",
    "    test_feats = pd.merge(\n",
    "        test_feats,\n",
    "        fb3_predicted,\n",
    "        left_on=\"essay_id\",\n",
    "        right_on=\"text_id\"\n",
    "    ).drop(\"text_id\", axis=1)\n",
    "    \n",
    "    # Features number\n",
    "    feature_names = list(filter(lambda x: x not in ['essay_id','score'], test_feats.columns))\n",
    "    print('Features number: ',len(feature_names))\n",
    "    test_feats.head(3)\n",
    "    return test_feats[feature_select]\n",
    "\n",
    "def infer(test_feats, models):\n",
    "    probabilities = []\n",
    "    for model in models:\n",
    "        proba = model.predict(test_feats) + a\n",
    "        probabilities.append(proba)\n",
    "\n",
    "    # Compute the average probabilities across all models\n",
    "    predictions = np.mean(probabilities, axis=0)\n",
    "    predictions = np.round(predictions.clip(1, 6))\n",
    "\n",
    "    # Print the predictions\n",
    "    print(predictions)\n",
    "\n",
    "    submission = pd.read_csv(\"/home/mcq/GitHub/aes2/kaggle/input/learning-agency-lab-automated-essay-scoring-2/sample_submission.csv\")\n",
    "    submission['score'] = predictions\n",
    "    submission['score'] = submission['score'].astype(int)\n",
    "    submission.to_csv(\"submission.csv\", index=None)\n",
    "    display(submission.head())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_feats = preprocess_test()\n",
    "    print(test_feats.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f225f7cd",
   "metadata": {
    "_cell_guid": "4dfeca93-4ea1-457d-9de7-cbd39085766f",
    "_uuid": "4dbbba64-1037-48fa-8007-263839e65581",
    "papermill": {
     "duration": 0.019295,
     "end_time": "2024-06-12T20:57:21.920034",
     "exception": false,
     "start_time": "2024-06-12T20:57:21.900739",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"color:white;display:fill;border-radius:5px;background-color:seaGreen;text-align:center;letter-spacing:0.1px;overflow:hidden;padding:20px;color:white;overflow:hidden;margin:0;font-size:100%\">▶️ Deberta Ensemble ◀️</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdffce14",
   "metadata": {
    "_cell_guid": "4bbf5d0f-b8f9-4dc0-9ea7-f306211891a7",
    "_uuid": "c3bbcfe8-260c-4957-8590-260be067680a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T20:57:21.961409Z",
     "iopub.status.busy": "2024-06-12T20:57:21.960985Z",
     "iopub.status.idle": "2024-06-12T20:57:21.965364Z",
     "shell.execute_reply": "2024-06-12T20:57:21.964481Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.027546,
     "end_time": "2024-06-12T20:57:21.967244",
     "exception": false,
     "start_time": "2024-06-12T20:57:21.939698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !cat submission.csv\n",
    "# df1 = pd.read_csv('/kaggle/working/submission_1.csv')\n",
    "# df2 = pd.read_csv('/kaggle/working/submission_2.csv')\n",
    "\n",
    "# # Merging the dataframes on 'essay_id'\n",
    "# df = pd.merge(left=df1, right=df2, on='essay_id', suffixes=('_1', '_2'))\n",
    "\n",
    "# # Calculating the average score directly without apply()\n",
    "# df['score'] = ((df['score_1'] + df['score_2']) / 2).round().astype(int)\n",
    "\n",
    "# # Saving the desired columns to a new csv file\n",
    "# df[['essay_id', 'score']].to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8059942,
     "sourceId": 71485,
     "sourceType": "competition"
    },
    {
     "datasetId": 2453564,
     "sourceId": 4155787,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2508107,
     "sourceId": 4256323,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4813598,
     "sourceId": 8141507,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4832208,
     "sourceId": 8166166,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4791897,
     "sourceId": 8339744,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5096910,
     "sourceId": 8675591,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5200263,
     "sourceId": 8676457,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 175940118,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 176861104,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2873.61578,
   "end_time": "2024-06-12T20:57:25.116471",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-12T20:09:31.500691",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "017e2494fe60403399c8d68950f3d4f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_26c4648cfcc640f79bd26cd646b0ef1d",
       "max": 3,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_515082cdcc0044a483c3ee2414196b73",
       "value": 3
      }
     },
     "036d18ec92a04f9abbdba1a8b2b01e77": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "03adc3e9a1c24358b67e2c039ecf9f5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fcb410027b3d400385b579f4d5e57eff",
        "IPY_MODEL_017e2494fe60403399c8d68950f3d4f3",
        "IPY_MODEL_3070af8848cd4c32950083147e22ccd3"
       ],
       "layout": "IPY_MODEL_27edde76b12b45c4b272e5051a2d82d3"
      }
     },
     "073f772467b24a67b4f815fbb7d48da9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "08a376be3dfd465c980f8750b7a6ff9c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1699b89440ad46ed9eaef32baf210610",
        "IPY_MODEL_de946c7dad384fbdb656bb1be59241f6",
        "IPY_MODEL_48aaed6854524d14926d280cb8160ec1"
       ],
       "layout": "IPY_MODEL_30730003d6644164b7b13de957f302dd"
      }
     },
     "1699b89440ad46ed9eaef32baf210610": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_867898dbf5054ae8a47f6502ec3bd2ac",
       "placeholder": "​",
       "style": "IPY_MODEL_f7829be24dc94fddac29d45fcc62722d",
       "value": "100%"
      }
     },
     "219a538155cf4ac8974ca649133815f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2476dfbe67c045bab943e060c3cc8400": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "26c4648cfcc640f79bd26cd646b0ef1d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "27edde76b12b45c4b272e5051a2d82d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3070af8848cd4c32950083147e22ccd3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_036d18ec92a04f9abbdba1a8b2b01e77",
       "placeholder": "​",
       "style": "IPY_MODEL_219a538155cf4ac8974ca649133815f4",
       "value": " 3/3 [00:00&lt;00:00, 114.84ex/s]"
      }
     },
     "30730003d6644164b7b13de957f302dd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "48aaed6854524d14926d280cb8160ec1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a7b9b81daa59409290118217bd15ef21",
       "placeholder": "​",
       "style": "IPY_MODEL_72924e047d7b4b5ab82947d09dc5c2b8",
       "value": " 3/3 [00:00&lt;00:00, 158.09ex/s]"
      }
     },
     "515082cdcc0044a483c3ee2414196b73": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5216e9c081944cb7bc2505d57626dbfd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "72924e047d7b4b5ab82947d09dc5c2b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "72f2b055cc7245bba08c42a6799d9d94": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "867898dbf5054ae8a47f6502ec3bd2ac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "983f75b4301848108b86c060d5510249": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9ac8ff0e7f6b42e0bb83181653216a9b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a6f9945e651544a4977d7a6073ec59e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a7b9b81daa59409290118217bd15ef21": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "befc63db1ac84675be5f9bf68725c53a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c4787c86262e4071b583bc97566bdc02": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9ac8ff0e7f6b42e0bb83181653216a9b",
       "placeholder": "​",
       "style": "IPY_MODEL_073f772467b24a67b4f815fbb7d48da9",
       "value": " 1/1 [00:01&lt;00:00,  1.32s/it]"
      }
     },
     "c975fa39641d49b0b79390d938ae0138": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cd1267ebd3344bcf8a44bf4fb27e333f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f18f1b3c4af1485f947a0bd6c715535e",
        "IPY_MODEL_fdbb0059be3a4c729f14c07cba249ea3",
        "IPY_MODEL_c4787c86262e4071b583bc97566bdc02"
       ],
       "layout": "IPY_MODEL_a6f9945e651544a4977d7a6073ec59e3"
      }
     },
     "cd8dd9d721e24d0395b8b68774360371": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "de946c7dad384fbdb656bb1be59241f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_983f75b4301848108b86c060d5510249",
       "max": 3,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_72f2b055cc7245bba08c42a6799d9d94",
       "value": 3
      }
     },
     "f179b9300d484361b18e22880e5639a9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f18f1b3c4af1485f947a0bd6c715535e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c975fa39641d49b0b79390d938ae0138",
       "placeholder": "​",
       "style": "IPY_MODEL_befc63db1ac84675be5f9bf68725c53a",
       "value": "100%"
      }
     },
     "f7829be24dc94fddac29d45fcc62722d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "fcb410027b3d400385b579f4d5e57eff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cd8dd9d721e24d0395b8b68774360371",
       "placeholder": "​",
       "style": "IPY_MODEL_f179b9300d484361b18e22880e5639a9",
       "value": "100%"
      }
     },
     "fdbb0059be3a4c729f14c07cba249ea3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2476dfbe67c045bab943e060c3cc8400",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5216e9c081944cb7bc2505d57626dbfd",
       "value": 1
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
